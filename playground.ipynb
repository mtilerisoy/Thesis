{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground Notebook For Quantizing VLP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Distributed Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.distributed as dist\n",
    "import copy\n",
    "\n",
    "# Limit the number of CPUs\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"  # Set this to the number of CPUs you want to use\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"  # Set this to the number of CPUs you want to use\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "# Initialize the process group\n",
    "dist.init_process_group(backend='gloo', init_method='env://', world_size=1, rank=0)\n",
    "\n",
    "# Verify initialization\n",
    "print(f\"Initialized: {dist.is_initialized()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"promote has been superseded by promote_options='default'\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Importing from timm.models.helpers is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Importing from timm.models.layers is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Importing from timm.models.registry is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_small_patch16_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch16_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch32_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch16_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch32_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch16_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch32_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch16_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch32_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch16_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch32_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch16_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch32_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_huge_patch14_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet50_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet50_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_small_resnet26d_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet26d_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet50d_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"You are using `torch.load` with `weights_only=False`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    \"\"\"\n",
    "    Function to print the size of the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to get the size\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "def get_accuracy(pl_module, logits, target, device=\"cpu\"):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        logits, target = (\n",
    "            logits.detach().to(device),\n",
    "            target.detach().to(device),\n",
    "        )\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        preds = preds[target != -100]\n",
    "        target = target[target != -100]\n",
    "        if target.numel() == 0:\n",
    "            return 1\n",
    "\n",
    "        assert preds.shape == target.shape\n",
    "\n",
    "        correct += torch.sum(preds == target)\n",
    "        total += target.numel()\n",
    "\n",
    "        return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Configuration to Initialize the Datamodule and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
      "  warnings.warn(\n",
      "WARNING:root:Found CUDA without GPU_NUM_DEVICES. Defaulting to PJRT_DEVICE=CUDA with GPU_NUM_DEVICES=2\n",
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import configs\n",
    "\n",
    "# Set the configuration\n",
    "_config = configs.vilt_config_nlvr2\n",
    "_config[\"batch_size\"] = 32\n",
    "\n",
    "\n",
    "pl.seed_everything(_config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a child datamodule that constructs a smaller version of the full datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 06:10:29.235887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736485829.253185 2955685 cuda_dnn.cc:8498] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736485829.258449 2955685 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from vilt.datamodules.multitask_datamodule import MTDataModule as MTDataModuleVILT\n",
    "from meter.datamodules.multitask_datamodule import MTDataModule as MTDataModuleMeter\n",
    "\n",
    "class SmallMTDataModuleVILT(MTDataModuleVILT):\n",
    "    def __init__(self, _config, dist=False, num_samples=5, start_idx=100):\n",
    "        super().__init__(_config, dist)\n",
    "        self.num_samples = num_samples\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def setup(self, stage):\n",
    "        super().setup(stage)\n",
    "        \n",
    "        # Limit the number of samples in the datasets\n",
    "        self.train_dataset = Subset(self.train_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.val_dataset = Subset(self.val_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.test_dataset = Subset(self.test_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "\n",
    "class SmallMTDataModuleMETER(MTDataModuleMeter):\n",
    "    def __init__(self, _config, dist=False, num_samples=10, start_idx=100):\n",
    "        super().__init__(_config, dist)\n",
    "        self.num_samples = num_samples\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def setup(self, stage):\n",
    "        super().setup(stage)\n",
    "        \n",
    "        # Limit the number of samples in the datasets\n",
    "        self.train_dataset = Subset(self.train_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.val_dataset = Subset(self.val_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.test_dataset = Subset(self.test_dataset, range(self.start_idx, self.start_idx+self.num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the configuration and initialize the test and full datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded names: ['nlvr2_vlue_test']\n",
      "Loaded names: ['nlvr2_vlue_test']\n",
      "Loaded names: ['nlvr2_vlue_test']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ========= Create full datamodule =========\n",
    "# ==========================================\n",
    "if \"meter\" in _config[\"model\"]:\n",
    "    full_dm = MTDataModuleMeter(_config, dist=False)\n",
    "    \n",
    "    calibrarte_dm = SmallMTDataModuleMETER(_config, dist=False, num_samples=5, start_idx=100)\n",
    "    \n",
    "    infer_dm = SmallMTDataModuleMETER(_config, dist=False, num_samples=5, start_idx=0)\n",
    "    infer_dm.setup(\"test\")\n",
    "    infer_dataloader = infer_dm.test_dataloader()\n",
    "\n",
    "elif \"vilt\" in _config[\"model\"]:\n",
    "    full_dm = MTDataModuleVILT(_config, dist=False)\n",
    "\n",
    "    calibrarte_dm = SmallMTDataModuleVILT(_config, dist=False, num_samples=5, start_idx=100)\n",
    "    \n",
    "    infer_dm = SmallMTDataModuleVILT(_config, dist=False, num_samples=5, start_idx=0)\n",
    "    infer_dm.setup(\"test\")\n",
    "    infer_dataloader = infer_dm.test_dataloader()\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Model not supported: \", _config[\"model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ViLT model\n"
     ]
    }
   ],
   "source": [
    "from vilt.modules import ViLTransformerSS\n",
    "from meter.modules import METERTransformerSS\n",
    "\n",
    "if _config[\"model\"] == \"vilt\":\n",
    "    model = ViLTransformerSS(_config)\n",
    "    print(\"Initialized ViLT model\")\n",
    "\n",
    "elif _config[\"model\"] == \"meter\":\n",
    "    model = METERTransformerSS(_config)\n",
    "    print(\"Initialized METER model\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Model not supported: \", _config[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize The Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "# ========== Initialize the trainer for full precision ==========\n",
    "exp_name = f'{_config[\"exp_name\"]}'\n",
    "\n",
    "os.makedirs(_config[\"log_dir\"], exist_ok=True)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val/the_metric\",\n",
    "    mode=\"max\",\n",
    "    save_last=True,\n",
    ")\n",
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    _config[\"log_dir\"],\n",
    "    name=f'{exp_name}_seed{_config[\"seed\"]}_from_{_config[\"load_path\"].split(\"/\")[-1][:-5]}',\n",
    ")\n",
    "\n",
    "lr_callback = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
    "callbacks = [checkpoint_callback, lr_callback]\n",
    "\n",
    "num_gpus = (\n",
    "    _config[\"num_gpus\"]\n",
    "    if isinstance(_config[\"num_gpus\"], int)\n",
    "    else len(_config[\"num_gpus\"])\n",
    ")\n",
    "\n",
    "grad_steps = _config[\"batch_size\"] // (\n",
    "    _config[\"per_gpu_batchsize\"] * num_gpus * _config[\"num_nodes\"]\n",
    ")\n",
    "\n",
    "max_steps = _config[\"max_steps\"] if _config[\"max_steps\"] is not None else None\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        devices=1,\n",
    "        num_nodes=_config[\"num_nodes\"],\n",
    "        precision=_config[\"precision\"],\n",
    "        # strategy=\"ddp\",\n",
    "        benchmark=True,\n",
    "        deterministic=False,\n",
    "        max_epochs=_config[\"max_epoch\"] if max_steps is None else 1000,\n",
    "        max_steps=max_steps,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        # accumulate_grad_batches=grad_steps,\n",
    "        log_every_n_steps=10,\n",
    "        fast_dev_run=_config[\"fast_dev_run\"],\n",
    "        val_check_interval=_config[\"val_check_interval\"],\n",
    "    )\n",
    "\n",
    "# trainer.test(model, datamodule=calibrarte_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization | PTQ to 8-bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_static = copy.deepcopy(model)\n",
    "\n",
    "# quantization_config = torch.quantization.QConfig(\n",
    "#             activation=torch.quantization.HistogramObserver.with_args(\n",
    "#                                                 dtype=torch.quint8,\n",
    "#                                                 quant_min=0,\n",
    "#                                                 quant_max=255,\n",
    "#                                                 reduce_range=False,\n",
    "#                                             ),\n",
    "#             weight=torch.quantization.MinMaxObserver.with_args(\n",
    "#                                             dtype=torch.qint8,\n",
    "#                                             qscheme=torch.per_tensor_symmetric,\n",
    "#                                             quant_min=-128,\n",
    "#                                             quant_max=127,\n",
    "#                                         ),\n",
    "#     )\n",
    "\n",
    "# embedding_qconfig = torch.quantization.QConfig(\n",
    "#     activation=torch.quantization.HistogramObserver.with_args(\n",
    "#                                             dtype=torch.quint8,\n",
    "#                                             quant_min=0,\n",
    "#                                             quant_max=255,\n",
    "#                                             reduce_range=False,\n",
    "#                                         ),\n",
    "#     weight=torch.quantization.PerChannelMinMaxObserver.with_args(\n",
    "#                                         dtype=torch.quint8,\n",
    "#                                         qscheme=torch.per_channel_affine_float_qparams,\n",
    "#                                         ch_axis=0,\n",
    "#                                         quant_min=0,\n",
    "#                                         quant_max=255,\n",
    "#                                     ),\n",
    "#     )\n",
    "\n",
    "# # Assign the quantization configurations to the model\n",
    "# # model_static.vit_model.visual.transformer.qconfig = quantization_config\n",
    "# model_static.vit_model.visual.transformer.resblocks[0].attn.qconfig = quantization_config\n",
    "# model_static.vit_model.visual.transformer.resblocks[0].attn.qconfig = quantization_config\n",
    "# model_static.vit_model.visual.transformer.resblocks[0].attn.qconfig = quantization_config\n",
    "# model_static.vit_model.visual.transformer.resblocks[0].attn.qconfig = quantization_config\n",
    "\n",
    "# # Perform static quantization\n",
    "# torch.quantization.prepare(model_static, inplace=True)\n",
    "# trainer.test(model_static, datamodule=calibrarte_dm)\n",
    "# torch.quantization.convert(model_static, inplace=True)\n",
    "\n",
    "# print(\"Size after quantization:\")\n",
    "# print_size_of_model(model_static)\n",
    "\n",
    "# trainer.test(model_static, datamodule=calibrarte_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_static)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Precision Model:\n",
      "Size of the model (MB): 455.900978\n",
      "Fully Quantized Model:\n",
      "Size of the model (MB): 122.099212\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.quantization import PlaceholderObserver, MinMaxObserver, QConfig, PerChannelMinMaxObserver\n",
    "from sensitivity_utils import init_trainer, get_quantization_config, print_size_of_model\n",
    "import copy\n",
    "\n",
    "bit8_linear, bit8_embedding = get_quantization_config(8)\n",
    "bit4_linear, bit4_embedding = get_quantization_config(4)\n",
    "bit2_linear, bit2_embedding = get_quantization_config(2)\n",
    "bit1_linear, bit1_embedding = get_quantization_config(1)\n",
    "\n",
    "\n",
    "print(\"Full Precision Model:\")\n",
    "print_size_of_model(model)\n",
    "\n",
    "model_8 = copy.deepcopy(model)\n",
    "model_4 = copy.deepcopy(model)\n",
    "model_2 = copy.deepcopy(model)\n",
    "model_1 = copy.deepcopy(model)\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_8, {torch.nn.Embedding: bit8_embedding}, dtype=torch.quint8, inplace=True\n",
    ")\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_8, {torch.nn.Linear: bit8_linear, torch.nn.LayerNorm: bit8_linear}, dtype=torch.qint8, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_4, {torch.nn.Embedding: bit4_embedding}, dtype=torch.quint8, inplace=True\n",
    ")\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_4, {torch.nn.Linear: bit4_linear, torch.nn.LayerNorm: bit2_linear}, dtype=torch.qint8, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_2, {torch.nn.Embedding: bit2_embedding}, dtype=torch.quint8, inplace=True\n",
    ")\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_2, {torch.nn.Linear: bit2_linear, torch.nn.LayerNorm: bit2_linear}, dtype=torch.qint8, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_1, {torch.nn.Embedding: bit1_embedding}, dtype=torch.quint8, inplace=True\n",
    ")\n",
    "torch.quantization.quantize_dynamic(\n",
    "    model_1, {torch.nn.Linear: bit1_linear, torch.nn.LayerNorm: bit1_linear}, dtype=torch.qint8, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Fully Quantized Model:\")\n",
    "print_size_of_model(model_8)\n",
    "\n",
    "# print(f\"Quantized Model with only the {layer_to_quantize} layer:\")\n",
    "# print_size_of_model(_model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-bit Relative Change (Mean): 0.1676570475101471\n",
      "4-bit Relative Change (Mean): 0.925999104976654\n",
      "2-bit Relative Change (Mean): 0.9999205470085144\n",
      "8-bit Relative Change (Max): 1.0\n",
      "4-bit Relative Change (Max): 1.0\n",
      "2-bit Relative Change (Max): 1.0\n",
      "8-bit Relative Change Percentage (Mean): 16.765705108642578\n",
      "4-bit Relative Change Percentage (Mean): 92.59990692138672\n",
      "2-bit Relative Change Percentage (Mean): 99.9920425415039\n",
      "Top 8-bit weights with largest relative changes: tensor([ 78,  44,  72,  38,  15, 132, 155, 172, 144,  64])\n",
      "Top 4-bit weights with largest relative changes: tensor([ 8,  9,  4,  3,  5,  1,  0, 10,  2,  6])\n",
      "Top 2-bit weights with largest relative changes: tensor([8, 9, 4, 7, 5, 3, 1, 0, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the block selection\n",
    "block_selection = 'transformer.blocks[0].mlp.fc1'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get the blocks from each model\n",
    "    block_full_precision = get_block(model, block_selection)\n",
    "    block_8bit = get_block(model_8, block_selection)\n",
    "    block_4bit = get_block(model_4, block_selection)\n",
    "    block_2bit = get_block(model_2, block_selection)\n",
    "\n",
    "    # Dequantize the quantized weights before performing the operation\n",
    "    weight_full_precision = block_full_precision.weight\n",
    "    weight_8bit = block_8bit.weight().dequantize()  # Dequantize 8-bit weights\n",
    "    weight_4bit = block_4bit.weight().dequantize()  # Dequantize 4-bit weights\n",
    "    weight_2bit = block_2bit.weight().dequantize()  # Dequantize 2-bit weights\n",
    "\n",
    "    # Compute relative changes\n",
    "    relative_change_8bit = torch.abs(weight_full_precision - weight_8bit) / torch.abs(weight_full_precision)\n",
    "    relative_change_4bit = torch.abs(weight_full_precision - weight_4bit) / torch.abs(weight_full_precision)\n",
    "    relative_change_2bit = torch.abs(weight_full_precision - weight_2bit) / torch.abs(weight_full_precision)\n",
    "\n",
    "    # Handle division by zero (if any original weight is zero)\n",
    "    relative_change_8bit[torch.isnan(relative_change_8bit)] = 0  # Set NaN to 0\n",
    "    relative_change_4bit[torch.isnan(relative_change_4bit)] = 0  # Set NaN to 0\n",
    "    relative_change_2bit[torch.isnan(relative_change_2bit)] = 0  # Set NaN to 0\n",
    "\n",
    "    # Convert to percentage (optional)\n",
    "    relative_change_8bit_percent = relative_change_8bit * 100\n",
    "    relative_change_4bit_percent = relative_change_4bit * 100\n",
    "    relative_change_2bit_percent = relative_change_2bit * 100\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"8-bit Relative Change (Mean):\", torch.mean(relative_change_8bit).item())\n",
    "    print(\"4-bit Relative Change (Mean):\", torch.mean(relative_change_4bit).item())\n",
    "    print(\"2-bit Relative Change (Mean):\", torch.mean(relative_change_2bit).item())\n",
    "\n",
    "    print(\"8-bit Relative Change (Max):\", torch.max(relative_change_8bit).item())\n",
    "    print(\"4-bit Relative Change (Max):\", torch.max(relative_change_4bit).item())\n",
    "    print(\"2-bit Relative Change (Max):\", torch.max(relative_change_2bit).item())\n",
    "\n",
    "    print(\"8-bit Relative Change Percentage (Mean):\", torch.mean(relative_change_8bit_percent).item())\n",
    "    print(\"4-bit Relative Change Percentage (Mean):\", torch.mean(relative_change_4bit_percent).item())\n",
    "    print(\"2-bit Relative Change Percentage (Mean):\", torch.mean(relative_change_2bit_percent).item())\n",
    "\n",
    "    # Identify weights with the largest relative changes\n",
    "    top_k = 10  # Number of top weights to identify\n",
    "    top_8bit_indices = torch.topk(relative_change_8bit.flatten(), k=top_k).indices\n",
    "    top_4bit_indices = torch.topk(relative_change_4bit.flatten(), k=top_k).indices\n",
    "    top_2bit_indices = torch.topk(relative_change_2bit.flatten(), k=top_k).indices\n",
    "\n",
    "    print(\"Top 8-bit weights with largest relative changes:\", top_8bit_indices)\n",
    "    print(\"Top 4-bit weights with largest relative changes:\", top_4bit_indices)\n",
    "    print(\"Top 2-bit weights with largest relative changes:\", top_2bit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get the block from the model\n",
    "def get_block(model, block_selection):\n",
    "    attrs = block_selection.split('.')\n",
    "    block = model\n",
    "    for attr in attrs:\n",
    "        if '[' in attr and ']' in attr:\n",
    "            attr_name, index = attr[:-1].split('[')\n",
    "            block = getattr(block, attr_name)[int(index)]\n",
    "        else:\n",
    "            block = getattr(block, attr)\n",
    "    return block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the block selection\n",
    "block_selection = 'transformer.blocks[0].mlp.fc1'\n",
    "with torch.no_grad():\n",
    "    # Get the blocks from each model\n",
    "    block_full_precision = get_block(model, block_selection)\n",
    "    block_8bit = get_block(model_8, block_selection)\n",
    "    block_4bit = get_block(model_4, block_selection)\n",
    "    block_2bit = get_block(model_2, block_selection)\n",
    "\n",
    "    # Dequantize the quantized weights before performing the operation\n",
    "    weight_full_precision = block_full_precision.weight\n",
    "    weight_8bit = block_8bit.weight().dequantize() # .int_repr().float()\n",
    "    weight_4bit = block_4bit.weight().dequantize() # .int_repr().float()\n",
    "    weight_2bit = block_2bit.weight().dequantize() # .int_repr().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.006750397456343222\n",
      "KL Divergence: 17.704822635573848\n",
      "KL Divergence: 24.204427696510965\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Example: Plot histograms\n",
    "plt.hist(weight_full_precision.flatten().detach().numpy(), bins=50, alpha=0.5, label=\"Original\")\n",
    "# plt.hist(weight_8bit.flatten().detach().numpy(), bins=50, alpha=0.5, label=\"8-bit\")\n",
    "# plt.hist(weight_4bit.flatten().detach().numpy(), bins=50, alpha=0.5, label=\"4-bit\")\n",
    "plt.hist(weight_2bit.flatten().detach().numpy(), bins=50, alpha=0.5, label=\"2-bit\")\n",
    "plt.legend()\n",
    "plt.xlim(-1, 1)\n",
    "plt.show()\n",
    "\n",
    "def compute_kl_divergence(original, quantized, bins=50, epsilon=1e-10):\n",
    "    hist_original, _ = np.histogram(original, bins=bins, density=True)\n",
    "    hist_quantized, _ = np.histogram(quantized, bins=bins, density=True)\n",
    "    \n",
    "    # Add epsilon to avoid zero probabilities\n",
    "    hist_original = hist_original + epsilon\n",
    "    hist_quantized = hist_quantized + epsilon\n",
    "    \n",
    "    # Normalize to ensure valid probability distributions\n",
    "    hist_original = hist_original / np.sum(hist_original)\n",
    "    hist_quantized = hist_quantized / np.sum(hist_quantized)\n",
    "    \n",
    "    return entropy(hist_original, hist_quantized)\n",
    "\n",
    "kl_divergence = compute_kl_divergence(weight_full_precision.flatten().detach().numpy(), weight_8bit.flatten().detach().numpy())\n",
    "print(\"KL Divergence:\", kl_divergence)\n",
    "\n",
    "kl_divergence = compute_kl_divergence(weight_full_precision.flatten().detach().numpy(), weight_4bit.flatten().detach().numpy())\n",
    "print(\"KL Divergence:\", kl_divergence)\n",
    "\n",
    "kl_divergence = compute_kl_divergence(weight_full_precision.flatten().detach().numpy(), weight_2bit.flatten().detach().numpy())\n",
    "print(\"KL Divergence:\", kl_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of the first layer of the transformer blocks:\n",
      "2.4307639598846436\n",
      "\n",
      "Min value of the first layer of the transformer blocks:\n",
      "-3.06199312210083\n",
      "\n",
      "Average of the first layer of the transformer blocks:\n",
      "3.992090205429122e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value of the first layer of the transformer blocks:\")\n",
    "print(weight_full_precision.max().item())\n",
    "print()\n",
    "\n",
    "print(f\"Min value of the first layer of the transformer blocks:\")\n",
    "print(weight_full_precision.min().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average of the first layer of the transformer blocks:\")\n",
    "print(weight_full_precision.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of the first layer of the transformer blocks:\n",
      "2.4255788326263428\n",
      "\n",
      "Min value of the first layer of the transformer blocks:\n",
      "-3.074000835418701\n",
      "\n",
      "Average of the first layer of the transformer blocks:\n",
      "3.338760870974511e-05\n",
      "\n",
      "Average difference between 8-bit version and full precision:\n",
      "0.005997746717184782\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value of the first layer of the transformer blocks:\")\n",
    "print(weight_8bit.max().item())\n",
    "print()\n",
    "\n",
    "print(f\"Min value of the first layer of the transformer blocks:\")\n",
    "print(weight_8bit.min().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average of the first layer of the transformer blocks:\")\n",
    "print(weight_8bit.mean().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average difference between 8-bit version and full precision:\")\n",
    "print(torch.abs(block_8bit.weight().dequantize() - weight_full_precision).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of the first layer of the transformer blocks:\n",
      "2.449594497680664\n",
      "\n",
      "Min value of the first layer of the transformer blocks:\n",
      "-3.2661259174346924\n",
      "\n",
      "Average of the first layer of the transformer blocks:\n",
      "1.4881919923936948e-05\n",
      "\n",
      "Average difference between 4-bit version and full precision:\n",
      "0.04256489500403404\n",
      "\n",
      "Average difference between 4-bit version and 8-bit version:\n",
      "0.042156487703323364\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value of the first layer of the transformer blocks:\")\n",
    "print(weight_4bit.max().item())\n",
    "print()\n",
    "\n",
    "print(f\"Min value of the first layer of the transformer blocks:\")\n",
    "print(weight_4bit.min().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average of the first layer of the transformer blocks:\")\n",
    "print(weight_4bit.mean().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average difference between 4-bit version and full precision:\")\n",
    "print(torch.abs(weight_4bit - weight_full_precision).mean().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average difference between 4-bit version and 8-bit version:\")\n",
    "print(torch.abs(weight_4bit - weight_8bit).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of the first layer of the transformer blocks:\n",
      "2.0413286685943604\n",
      "\n",
      "Min value of the first layer of the transformer blocks:\n",
      "-4.082657337188721\n",
      "\n",
      "Average of the first layer of the transformer blocks:\n",
      "-1.7304555512964725e-06\n",
      "\n",
      "Average difference between 2-bit version and full precision:\n",
      "0.0428580567240715\n",
      "\n",
      "Average difference between 2-bit version and 8-bit version:\n",
      "0.042456429451704025\n",
      "\n",
      "Average difference between 2-bit version and 4-bit version:\n",
      "0.001149368821643293\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value of the first layer of the transformer blocks:\")\n",
    "print(weight_2bit.max().item())\n",
    "print()\n",
    "\n",
    "print(f\"Min value of the first layer of the transformer blocks:\")\n",
    "print(weight_2bit.min().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average of the first layer of the transformer blocks:\")\n",
    "print(weight_2bit.mean().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average difference between 2-bit version and full precision:\")\n",
    "print(torch.abs(weight_2bit - weight_full_precision).mean().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average difference between 2-bit version and 8-bit version:\")\n",
    "print(torch.abs(weight_2bit - weight_8bit).mean().item())\n",
    "print()\n",
    "\n",
    "print(f\"Average difference between 2-bit version and 4-bit version:\")\n",
    "print(torch.abs(weight_2bit - weight_4bit).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model submodules\n",
      "('', 'cross_modal_text_transform', 'cross_modal_image_transform', 'token_type_embeddings', 'vit_model', 'vit_model.visual', 'vit_model.visual.conv1', 'vit_model.visual.ln_pre', 'vit_model.visual.transformer', 'vit_model.visual.transformer.resblocks', 'vit_model.visual.transformer.resblocks.0', 'vit_model.visual.transformer.resblocks.0.attn', 'vit_model.visual.transformer.resblocks.0.attn.out_proj', 'vit_model.visual.transformer.resblocks.0.ln_1', 'vit_model.visual.transformer.resblocks.0.mlp', 'vit_model.visual.transformer.resblocks.0.mlp.c_fc', 'vit_model.visual.transformer.resblocks.0.mlp.gelu', 'vit_model.visual.transformer.resblocks.0.mlp.c_proj', 'vit_model.visual.transformer.resblocks.0.ln_2', 'vit_model.visual.transformer.resblocks.1', 'vit_model.visual.transformer.resblocks.1.attn', 'vit_model.visual.transformer.resblocks.1.attn.out_proj', 'vit_model.visual.transformer.resblocks.1.ln_1', 'vit_model.visual.transformer.resblocks.1.mlp', 'vit_model.visual.transformer.resblocks.1.mlp.c_fc', 'vit_model.visual.transformer.resblocks.1.mlp.gelu', 'vit_model.visual.transformer.resblocks.1.mlp.c_proj', 'vit_model.visual.transformer.resblocks.1.ln_2', 'vit_model.visual.transformer.resblocks.2', 'vit_model.visual.transformer.resblocks.2.attn', 'vit_model.visual.transformer.resblocks.2.attn.out_proj', 'vit_model.visual.transformer.resblocks.2.ln_1', 'vit_model.visual.transformer.resblocks.2.mlp', 'vit_model.visual.transformer.resblocks.2.mlp.c_fc', 'vit_model.visual.transformer.resblocks.2.mlp.gelu', 'vit_model.visual.transformer.resblocks.2.mlp.c_proj', 'vit_model.visual.transformer.resblocks.2.ln_2', 'vit_model.visual.transformer.resblocks.3', 'vit_model.visual.transformer.resblocks.3.attn', 'vit_model.visual.transformer.resblocks.3.attn.out_proj', 'vit_model.visual.transformer.resblocks.3.ln_1', 'vit_model.visual.transformer.resblocks.3.mlp', 'vit_model.visual.transformer.resblocks.3.mlp.c_fc', 'vit_model.visual.transformer.resblocks.3.mlp.gelu', 'vit_model.visual.transformer.resblocks.3.mlp.c_proj', 'vit_model.visual.transformer.resblocks.3.ln_2', 'vit_model.visual.transformer.resblocks.4', 'vit_model.visual.transformer.resblocks.4.attn', 'vit_model.visual.transformer.resblocks.4.attn.out_proj', 'vit_model.visual.transformer.resblocks.4.ln_1', 'vit_model.visual.transformer.resblocks.4.mlp', 'vit_model.visual.transformer.resblocks.4.mlp.c_fc', 'vit_model.visual.transformer.resblocks.4.mlp.gelu', 'vit_model.visual.transformer.resblocks.4.mlp.c_proj', 'vit_model.visual.transformer.resblocks.4.ln_2', 'vit_model.visual.transformer.resblocks.5', 'vit_model.visual.transformer.resblocks.5.attn', 'vit_model.visual.transformer.resblocks.5.attn.out_proj', 'vit_model.visual.transformer.resblocks.5.ln_1', 'vit_model.visual.transformer.resblocks.5.mlp', 'vit_model.visual.transformer.resblocks.5.mlp.c_fc', 'vit_model.visual.transformer.resblocks.5.mlp.gelu', 'vit_model.visual.transformer.resblocks.5.mlp.c_proj', 'vit_model.visual.transformer.resblocks.5.ln_2', 'vit_model.visual.transformer.resblocks.6', 'vit_model.visual.transformer.resblocks.6.attn', 'vit_model.visual.transformer.resblocks.6.attn.out_proj', 'vit_model.visual.transformer.resblocks.6.ln_1', 'vit_model.visual.transformer.resblocks.6.mlp', 'vit_model.visual.transformer.resblocks.6.mlp.c_fc', 'vit_model.visual.transformer.resblocks.6.mlp.gelu', 'vit_model.visual.transformer.resblocks.6.mlp.c_proj', 'vit_model.visual.transformer.resblocks.6.ln_2', 'vit_model.visual.transformer.resblocks.7', 'vit_model.visual.transformer.resblocks.7.attn', 'vit_model.visual.transformer.resblocks.7.attn.out_proj', 'vit_model.visual.transformer.resblocks.7.ln_1', 'vit_model.visual.transformer.resblocks.7.mlp', 'vit_model.visual.transformer.resblocks.7.mlp.c_fc', 'vit_model.visual.transformer.resblocks.7.mlp.gelu', 'vit_model.visual.transformer.resblocks.7.mlp.c_proj', 'vit_model.visual.transformer.resblocks.7.ln_2', 'vit_model.visual.transformer.resblocks.8', 'vit_model.visual.transformer.resblocks.8.attn', 'vit_model.visual.transformer.resblocks.8.attn.out_proj', 'vit_model.visual.transformer.resblocks.8.ln_1', 'vit_model.visual.transformer.resblocks.8.mlp', 'vit_model.visual.transformer.resblocks.8.mlp.c_fc', 'vit_model.visual.transformer.resblocks.8.mlp.gelu', 'vit_model.visual.transformer.resblocks.8.mlp.c_proj', 'vit_model.visual.transformer.resblocks.8.ln_2', 'vit_model.visual.transformer.resblocks.9', 'vit_model.visual.transformer.resblocks.9.attn', 'vit_model.visual.transformer.resblocks.9.attn.out_proj', 'vit_model.visual.transformer.resblocks.9.ln_1', 'vit_model.visual.transformer.resblocks.9.mlp', 'vit_model.visual.transformer.resblocks.9.mlp.c_fc', 'vit_model.visual.transformer.resblocks.9.mlp.gelu', 'vit_model.visual.transformer.resblocks.9.mlp.c_proj', 'vit_model.visual.transformer.resblocks.9.ln_2', 'vit_model.visual.transformer.resblocks.10', 'vit_model.visual.transformer.resblocks.10.attn', 'vit_model.visual.transformer.resblocks.10.attn.out_proj', 'vit_model.visual.transformer.resblocks.10.ln_1', 'vit_model.visual.transformer.resblocks.10.mlp', 'vit_model.visual.transformer.resblocks.10.mlp.c_fc', 'vit_model.visual.transformer.resblocks.10.mlp.gelu', 'vit_model.visual.transformer.resblocks.10.mlp.c_proj', 'vit_model.visual.transformer.resblocks.10.ln_2', 'vit_model.visual.ln_post', 'vit_model.ln_final', 'text_transformer', 'text_transformer.embeddings', 'text_transformer.embeddings.word_embeddings', 'text_transformer.embeddings.position_embeddings', 'text_transformer.embeddings.token_type_embeddings', 'text_transformer.embeddings.LayerNorm', 'text_transformer.embeddings.dropout', 'text_transformer.embeddings.quant', 'text_transformer.embeddings.dequant', 'text_transformer.encoder', 'text_transformer.encoder.layer', 'text_transformer.encoder.layer.0', 'text_transformer.encoder.layer.0.attention', 'text_transformer.encoder.layer.0.attention.self', 'text_transformer.encoder.layer.0.attention.self.query', 'text_transformer.encoder.layer.0.attention.self.key', 'text_transformer.encoder.layer.0.attention.self.value', 'text_transformer.encoder.layer.0.attention.self.dropout', 'text_transformer.encoder.layer.0.attention.self.quant', 'text_transformer.encoder.layer.0.attention.self.dequant', 'text_transformer.encoder.layer.0.attention.output', 'text_transformer.encoder.layer.0.attention.output.dense', 'text_transformer.encoder.layer.0.attention.output.LayerNorm', 'text_transformer.encoder.layer.0.attention.output.dropout', 'text_transformer.encoder.layer.0.attention.output.quant', 'text_transformer.encoder.layer.0.attention.output.dequant', 'text_transformer.encoder.layer.0.intermediate', 'text_transformer.encoder.layer.0.intermediate.dense', 'text_transformer.encoder.layer.0.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.0.output', 'text_transformer.encoder.layer.0.output.dense', 'text_transformer.encoder.layer.0.output.LayerNorm', 'text_transformer.encoder.layer.0.output.dropout', 'text_transformer.encoder.layer.0.output.quant', 'text_transformer.encoder.layer.0.output.dequant', 'text_transformer.encoder.layer.1', 'text_transformer.encoder.layer.1.attention', 'text_transformer.encoder.layer.1.attention.self', 'text_transformer.encoder.layer.1.attention.self.query', 'text_transformer.encoder.layer.1.attention.self.key', 'text_transformer.encoder.layer.1.attention.self.value', 'text_transformer.encoder.layer.1.attention.self.dropout', 'text_transformer.encoder.layer.1.attention.self.quant', 'text_transformer.encoder.layer.1.attention.self.dequant', 'text_transformer.encoder.layer.1.attention.output', 'text_transformer.encoder.layer.1.attention.output.dense', 'text_transformer.encoder.layer.1.attention.output.LayerNorm', 'text_transformer.encoder.layer.1.attention.output.dropout', 'text_transformer.encoder.layer.1.attention.output.quant', 'text_transformer.encoder.layer.1.attention.output.dequant', 'text_transformer.encoder.layer.1.intermediate', 'text_transformer.encoder.layer.1.intermediate.dense', 'text_transformer.encoder.layer.1.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.1.output', 'text_transformer.encoder.layer.1.output.dense', 'text_transformer.encoder.layer.1.output.LayerNorm', 'text_transformer.encoder.layer.1.output.dropout', 'text_transformer.encoder.layer.1.output.quant', 'text_transformer.encoder.layer.1.output.dequant', 'text_transformer.encoder.layer.2', 'text_transformer.encoder.layer.2.attention', 'text_transformer.encoder.layer.2.attention.self', 'text_transformer.encoder.layer.2.attention.self.query', 'text_transformer.encoder.layer.2.attention.self.key', 'text_transformer.encoder.layer.2.attention.self.value', 'text_transformer.encoder.layer.2.attention.self.dropout', 'text_transformer.encoder.layer.2.attention.self.quant', 'text_transformer.encoder.layer.2.attention.self.dequant', 'text_transformer.encoder.layer.2.attention.output', 'text_transformer.encoder.layer.2.attention.output.dense', 'text_transformer.encoder.layer.2.attention.output.LayerNorm', 'text_transformer.encoder.layer.2.attention.output.dropout', 'text_transformer.encoder.layer.2.attention.output.quant', 'text_transformer.encoder.layer.2.attention.output.dequant', 'text_transformer.encoder.layer.2.intermediate', 'text_transformer.encoder.layer.2.intermediate.dense', 'text_transformer.encoder.layer.2.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.2.output', 'text_transformer.encoder.layer.2.output.dense', 'text_transformer.encoder.layer.2.output.LayerNorm', 'text_transformer.encoder.layer.2.output.dropout', 'text_transformer.encoder.layer.2.output.quant', 'text_transformer.encoder.layer.2.output.dequant', 'text_transformer.encoder.layer.3', 'text_transformer.encoder.layer.3.attention', 'text_transformer.encoder.layer.3.attention.self', 'text_transformer.encoder.layer.3.attention.self.query', 'text_transformer.encoder.layer.3.attention.self.key', 'text_transformer.encoder.layer.3.attention.self.value', 'text_transformer.encoder.layer.3.attention.self.dropout', 'text_transformer.encoder.layer.3.attention.self.quant', 'text_transformer.encoder.layer.3.attention.self.dequant', 'text_transformer.encoder.layer.3.attention.output', 'text_transformer.encoder.layer.3.attention.output.dense', 'text_transformer.encoder.layer.3.attention.output.LayerNorm', 'text_transformer.encoder.layer.3.attention.output.dropout', 'text_transformer.encoder.layer.3.attention.output.quant', 'text_transformer.encoder.layer.3.attention.output.dequant', 'text_transformer.encoder.layer.3.intermediate', 'text_transformer.encoder.layer.3.intermediate.dense', 'text_transformer.encoder.layer.3.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.3.output', 'text_transformer.encoder.layer.3.output.dense', 'text_transformer.encoder.layer.3.output.LayerNorm', 'text_transformer.encoder.layer.3.output.dropout', 'text_transformer.encoder.layer.3.output.quant', 'text_transformer.encoder.layer.3.output.dequant', 'text_transformer.encoder.layer.4', 'text_transformer.encoder.layer.4.attention', 'text_transformer.encoder.layer.4.attention.self', 'text_transformer.encoder.layer.4.attention.self.query', 'text_transformer.encoder.layer.4.attention.self.key', 'text_transformer.encoder.layer.4.attention.self.value', 'text_transformer.encoder.layer.4.attention.self.dropout', 'text_transformer.encoder.layer.4.attention.self.quant', 'text_transformer.encoder.layer.4.attention.self.dequant', 'text_transformer.encoder.layer.4.attention.output', 'text_transformer.encoder.layer.4.attention.output.dense', 'text_transformer.encoder.layer.4.attention.output.LayerNorm', 'text_transformer.encoder.layer.4.attention.output.dropout', 'text_transformer.encoder.layer.4.attention.output.quant', 'text_transformer.encoder.layer.4.attention.output.dequant', 'text_transformer.encoder.layer.4.intermediate', 'text_transformer.encoder.layer.4.intermediate.dense', 'text_transformer.encoder.layer.4.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.4.output', 'text_transformer.encoder.layer.4.output.dense', 'text_transformer.encoder.layer.4.output.LayerNorm', 'text_transformer.encoder.layer.4.output.dropout', 'text_transformer.encoder.layer.4.output.quant', 'text_transformer.encoder.layer.4.output.dequant', 'text_transformer.encoder.layer.5', 'text_transformer.encoder.layer.5.attention', 'text_transformer.encoder.layer.5.attention.self', 'text_transformer.encoder.layer.5.attention.self.query', 'text_transformer.encoder.layer.5.attention.self.key', 'text_transformer.encoder.layer.5.attention.self.value', 'text_transformer.encoder.layer.5.attention.self.dropout', 'text_transformer.encoder.layer.5.attention.self.quant', 'text_transformer.encoder.layer.5.attention.self.dequant', 'text_transformer.encoder.layer.5.attention.output', 'text_transformer.encoder.layer.5.attention.output.dense', 'text_transformer.encoder.layer.5.attention.output.LayerNorm', 'text_transformer.encoder.layer.5.attention.output.dropout', 'text_transformer.encoder.layer.5.attention.output.quant', 'text_transformer.encoder.layer.5.attention.output.dequant', 'text_transformer.encoder.layer.5.intermediate', 'text_transformer.encoder.layer.5.intermediate.dense', 'text_transformer.encoder.layer.5.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.5.output', 'text_transformer.encoder.layer.5.output.dense', 'text_transformer.encoder.layer.5.output.LayerNorm', 'text_transformer.encoder.layer.5.output.dropout', 'text_transformer.encoder.layer.5.output.quant', 'text_transformer.encoder.layer.5.output.dequant', 'text_transformer.encoder.layer.6', 'text_transformer.encoder.layer.6.attention', 'text_transformer.encoder.layer.6.attention.self', 'text_transformer.encoder.layer.6.attention.self.query', 'text_transformer.encoder.layer.6.attention.self.key', 'text_transformer.encoder.layer.6.attention.self.value', 'text_transformer.encoder.layer.6.attention.self.dropout', 'text_transformer.encoder.layer.6.attention.self.quant', 'text_transformer.encoder.layer.6.attention.self.dequant', 'text_transformer.encoder.layer.6.attention.output', 'text_transformer.encoder.layer.6.attention.output.dense', 'text_transformer.encoder.layer.6.attention.output.LayerNorm', 'text_transformer.encoder.layer.6.attention.output.dropout', 'text_transformer.encoder.layer.6.attention.output.quant', 'text_transformer.encoder.layer.6.attention.output.dequant', 'text_transformer.encoder.layer.6.intermediate', 'text_transformer.encoder.layer.6.intermediate.dense', 'text_transformer.encoder.layer.6.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.6.output', 'text_transformer.encoder.layer.6.output.dense', 'text_transformer.encoder.layer.6.output.LayerNorm', 'text_transformer.encoder.layer.6.output.dropout', 'text_transformer.encoder.layer.6.output.quant', 'text_transformer.encoder.layer.6.output.dequant', 'text_transformer.encoder.layer.7', 'text_transformer.encoder.layer.7.attention', 'text_transformer.encoder.layer.7.attention.self', 'text_transformer.encoder.layer.7.attention.self.query', 'text_transformer.encoder.layer.7.attention.self.key', 'text_transformer.encoder.layer.7.attention.self.value', 'text_transformer.encoder.layer.7.attention.self.dropout', 'text_transformer.encoder.layer.7.attention.self.quant', 'text_transformer.encoder.layer.7.attention.self.dequant', 'text_transformer.encoder.layer.7.attention.output', 'text_transformer.encoder.layer.7.attention.output.dense', 'text_transformer.encoder.layer.7.attention.output.LayerNorm', 'text_transformer.encoder.layer.7.attention.output.dropout', 'text_transformer.encoder.layer.7.attention.output.quant', 'text_transformer.encoder.layer.7.attention.output.dequant', 'text_transformer.encoder.layer.7.intermediate', 'text_transformer.encoder.layer.7.intermediate.dense', 'text_transformer.encoder.layer.7.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.7.output', 'text_transformer.encoder.layer.7.output.dense', 'text_transformer.encoder.layer.7.output.LayerNorm', 'text_transformer.encoder.layer.7.output.dropout', 'text_transformer.encoder.layer.7.output.quant', 'text_transformer.encoder.layer.7.output.dequant', 'text_transformer.encoder.layer.8', 'text_transformer.encoder.layer.8.attention', 'text_transformer.encoder.layer.8.attention.self', 'text_transformer.encoder.layer.8.attention.self.query', 'text_transformer.encoder.layer.8.attention.self.key', 'text_transformer.encoder.layer.8.attention.self.value', 'text_transformer.encoder.layer.8.attention.self.dropout', 'text_transformer.encoder.layer.8.attention.self.quant', 'text_transformer.encoder.layer.8.attention.self.dequant', 'text_transformer.encoder.layer.8.attention.output', 'text_transformer.encoder.layer.8.attention.output.dense', 'text_transformer.encoder.layer.8.attention.output.LayerNorm', 'text_transformer.encoder.layer.8.attention.output.dropout', 'text_transformer.encoder.layer.8.attention.output.quant', 'text_transformer.encoder.layer.8.attention.output.dequant', 'text_transformer.encoder.layer.8.intermediate', 'text_transformer.encoder.layer.8.intermediate.dense', 'text_transformer.encoder.layer.8.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.8.output', 'text_transformer.encoder.layer.8.output.dense', 'text_transformer.encoder.layer.8.output.LayerNorm', 'text_transformer.encoder.layer.8.output.dropout', 'text_transformer.encoder.layer.8.output.quant', 'text_transformer.encoder.layer.8.output.dequant', 'text_transformer.encoder.layer.9', 'text_transformer.encoder.layer.9.attention', 'text_transformer.encoder.layer.9.attention.self', 'text_transformer.encoder.layer.9.attention.self.query', 'text_transformer.encoder.layer.9.attention.self.key', 'text_transformer.encoder.layer.9.attention.self.value', 'text_transformer.encoder.layer.9.attention.self.dropout', 'text_transformer.encoder.layer.9.attention.self.quant', 'text_transformer.encoder.layer.9.attention.self.dequant', 'text_transformer.encoder.layer.9.attention.output', 'text_transformer.encoder.layer.9.attention.output.dense', 'text_transformer.encoder.layer.9.attention.output.LayerNorm', 'text_transformer.encoder.layer.9.attention.output.dropout', 'text_transformer.encoder.layer.9.attention.output.quant', 'text_transformer.encoder.layer.9.attention.output.dequant', 'text_transformer.encoder.layer.9.intermediate', 'text_transformer.encoder.layer.9.intermediate.dense', 'text_transformer.encoder.layer.9.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.9.output', 'text_transformer.encoder.layer.9.output.dense', 'text_transformer.encoder.layer.9.output.LayerNorm', 'text_transformer.encoder.layer.9.output.dropout', 'text_transformer.encoder.layer.9.output.quant', 'text_transformer.encoder.layer.9.output.dequant', 'text_transformer.encoder.layer.10', 'text_transformer.encoder.layer.10.attention', 'text_transformer.encoder.layer.10.attention.self', 'text_transformer.encoder.layer.10.attention.self.query', 'text_transformer.encoder.layer.10.attention.self.key', 'text_transformer.encoder.layer.10.attention.self.value', 'text_transformer.encoder.layer.10.attention.self.dropout', 'text_transformer.encoder.layer.10.attention.self.quant', 'text_transformer.encoder.layer.10.attention.self.dequant', 'text_transformer.encoder.layer.10.attention.output', 'text_transformer.encoder.layer.10.attention.output.dense', 'text_transformer.encoder.layer.10.attention.output.LayerNorm', 'text_transformer.encoder.layer.10.attention.output.dropout', 'text_transformer.encoder.layer.10.attention.output.quant', 'text_transformer.encoder.layer.10.attention.output.dequant', 'text_transformer.encoder.layer.10.intermediate', 'text_transformer.encoder.layer.10.intermediate.dense', 'text_transformer.encoder.layer.10.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.10.output', 'text_transformer.encoder.layer.10.output.dense', 'text_transformer.encoder.layer.10.output.LayerNorm', 'text_transformer.encoder.layer.10.output.dropout', 'text_transformer.encoder.layer.10.output.quant', 'text_transformer.encoder.layer.10.output.dequant', 'text_transformer.encoder.layer.11', 'text_transformer.encoder.layer.11.attention', 'text_transformer.encoder.layer.11.attention.self', 'text_transformer.encoder.layer.11.attention.self.query', 'text_transformer.encoder.layer.11.attention.self.key', 'text_transformer.encoder.layer.11.attention.self.value', 'text_transformer.encoder.layer.11.attention.self.dropout', 'text_transformer.encoder.layer.11.attention.self.quant', 'text_transformer.encoder.layer.11.attention.self.dequant', 'text_transformer.encoder.layer.11.attention.output', 'text_transformer.encoder.layer.11.attention.output.dense', 'text_transformer.encoder.layer.11.attention.output.LayerNorm', 'text_transformer.encoder.layer.11.attention.output.dropout', 'text_transformer.encoder.layer.11.attention.output.quant', 'text_transformer.encoder.layer.11.attention.output.dequant', 'text_transformer.encoder.layer.11.intermediate', 'text_transformer.encoder.layer.11.intermediate.dense', 'text_transformer.encoder.layer.11.intermediate.intermediate_act_fn', 'text_transformer.encoder.layer.11.output', 'text_transformer.encoder.layer.11.output.dense', 'text_transformer.encoder.layer.11.output.LayerNorm', 'text_transformer.encoder.layer.11.output.dropout', 'text_transformer.encoder.layer.11.output.quant', 'text_transformer.encoder.layer.11.output.dequant', 'text_transformer.pooler', 'text_transformer.pooler.dense', 'text_transformer.pooler.activation', 'cross_modal_image_layers', 'cross_modal_image_layers.0', 'cross_modal_image_layers.0.attention', 'cross_modal_image_layers.0.attention.self', 'cross_modal_image_layers.0.attention.self.query', 'cross_modal_image_layers.0.attention.self.key', 'cross_modal_image_layers.0.attention.self.value', 'cross_modal_image_layers.0.attention.self.dropout', 'cross_modal_image_layers.0.attention.output', 'cross_modal_image_layers.0.attention.output.dense', 'cross_modal_image_layers.0.attention.output.LayerNorm', 'cross_modal_image_layers.0.attention.output.dropout', 'cross_modal_image_layers.0.crossattention', 'cross_modal_image_layers.0.crossattention.self', 'cross_modal_image_layers.0.crossattention.self.query', 'cross_modal_image_layers.0.crossattention.self.key', 'cross_modal_image_layers.0.crossattention.self.value', 'cross_modal_image_layers.0.crossattention.self.dropout', 'cross_modal_image_layers.0.crossattention.output', 'cross_modal_image_layers.0.crossattention.output.dense', 'cross_modal_image_layers.0.crossattention.output.LayerNorm', 'cross_modal_image_layers.0.crossattention.output.dropout', 'cross_modal_image_layers.0.intermediate', 'cross_modal_image_layers.0.intermediate.dense', 'cross_modal_image_layers.0.intermediate.intermediate_act_fn', 'cross_modal_image_layers.0.output', 'cross_modal_image_layers.0.output.dense', 'cross_modal_image_layers.0.output.LayerNorm', 'cross_modal_image_layers.0.output.dropout', 'cross_modal_image_layers.1', 'cross_modal_image_layers.1.attention', 'cross_modal_image_layers.1.attention.self', 'cross_modal_image_layers.1.attention.self.query', 'cross_modal_image_layers.1.attention.self.key', 'cross_modal_image_layers.1.attention.self.value', 'cross_modal_image_layers.1.attention.self.dropout', 'cross_modal_image_layers.1.attention.output', 'cross_modal_image_layers.1.attention.output.dense', 'cross_modal_image_layers.1.attention.output.LayerNorm', 'cross_modal_image_layers.1.attention.output.dropout', 'cross_modal_image_layers.1.crossattention', 'cross_modal_image_layers.1.crossattention.self', 'cross_modal_image_layers.1.crossattention.self.query', 'cross_modal_image_layers.1.crossattention.self.key', 'cross_modal_image_layers.1.crossattention.self.value', 'cross_modal_image_layers.1.crossattention.self.dropout', 'cross_modal_image_layers.1.crossattention.output', 'cross_modal_image_layers.1.crossattention.output.dense', 'cross_modal_image_layers.1.crossattention.output.LayerNorm', 'cross_modal_image_layers.1.crossattention.output.dropout', 'cross_modal_image_layers.1.intermediate', 'cross_modal_image_layers.1.intermediate.dense', 'cross_modal_image_layers.1.intermediate.intermediate_act_fn', 'cross_modal_image_layers.1.output', 'cross_modal_image_layers.1.output.dense', 'cross_modal_image_layers.1.output.LayerNorm', 'cross_modal_image_layers.1.output.dropout', 'cross_modal_image_layers.2', 'cross_modal_image_layers.2.attention', 'cross_modal_image_layers.2.attention.self', 'cross_modal_image_layers.2.attention.self.query', 'cross_modal_image_layers.2.attention.self.key', 'cross_modal_image_layers.2.attention.self.value', 'cross_modal_image_layers.2.attention.self.dropout', 'cross_modal_image_layers.2.attention.output', 'cross_modal_image_layers.2.attention.output.dense', 'cross_modal_image_layers.2.attention.output.LayerNorm', 'cross_modal_image_layers.2.attention.output.dropout', 'cross_modal_image_layers.2.crossattention', 'cross_modal_image_layers.2.crossattention.self', 'cross_modal_image_layers.2.crossattention.self.query', 'cross_modal_image_layers.2.crossattention.self.key', 'cross_modal_image_layers.2.crossattention.self.value', 'cross_modal_image_layers.2.crossattention.self.dropout', 'cross_modal_image_layers.2.crossattention.output', 'cross_modal_image_layers.2.crossattention.output.dense', 'cross_modal_image_layers.2.crossattention.output.LayerNorm', 'cross_modal_image_layers.2.crossattention.output.dropout', 'cross_modal_image_layers.2.intermediate', 'cross_modal_image_layers.2.intermediate.dense', 'cross_modal_image_layers.2.intermediate.intermediate_act_fn', 'cross_modal_image_layers.2.output', 'cross_modal_image_layers.2.output.dense', 'cross_modal_image_layers.2.output.LayerNorm', 'cross_modal_image_layers.2.output.dropout', 'cross_modal_image_layers.3', 'cross_modal_image_layers.3.attention', 'cross_modal_image_layers.3.attention.self', 'cross_modal_image_layers.3.attention.self.query', 'cross_modal_image_layers.3.attention.self.key', 'cross_modal_image_layers.3.attention.self.value', 'cross_modal_image_layers.3.attention.self.dropout', 'cross_modal_image_layers.3.attention.output', 'cross_modal_image_layers.3.attention.output.dense', 'cross_modal_image_layers.3.attention.output.LayerNorm', 'cross_modal_image_layers.3.attention.output.dropout', 'cross_modal_image_layers.3.crossattention', 'cross_modal_image_layers.3.crossattention.self', 'cross_modal_image_layers.3.crossattention.self.query', 'cross_modal_image_layers.3.crossattention.self.key', 'cross_modal_image_layers.3.crossattention.self.value', 'cross_modal_image_layers.3.crossattention.self.dropout', 'cross_modal_image_layers.3.crossattention.output', 'cross_modal_image_layers.3.crossattention.output.dense', 'cross_modal_image_layers.3.crossattention.output.LayerNorm', 'cross_modal_image_layers.3.crossattention.output.dropout', 'cross_modal_image_layers.3.intermediate', 'cross_modal_image_layers.3.intermediate.dense', 'cross_modal_image_layers.3.intermediate.intermediate_act_fn', 'cross_modal_image_layers.3.output', 'cross_modal_image_layers.3.output.dense', 'cross_modal_image_layers.3.output.LayerNorm', 'cross_modal_image_layers.3.output.dropout', 'cross_modal_image_layers.4', 'cross_modal_image_layers.4.attention', 'cross_modal_image_layers.4.attention.self', 'cross_modal_image_layers.4.attention.self.query', 'cross_modal_image_layers.4.attention.self.key', 'cross_modal_image_layers.4.attention.self.value', 'cross_modal_image_layers.4.attention.self.dropout', 'cross_modal_image_layers.4.attention.output', 'cross_modal_image_layers.4.attention.output.dense', 'cross_modal_image_layers.4.attention.output.LayerNorm', 'cross_modal_image_layers.4.attention.output.dropout', 'cross_modal_image_layers.4.crossattention', 'cross_modal_image_layers.4.crossattention.self', 'cross_modal_image_layers.4.crossattention.self.query', 'cross_modal_image_layers.4.crossattention.self.key', 'cross_modal_image_layers.4.crossattention.self.value', 'cross_modal_image_layers.4.crossattention.self.dropout', 'cross_modal_image_layers.4.crossattention.output', 'cross_modal_image_layers.4.crossattention.output.dense', 'cross_modal_image_layers.4.crossattention.output.LayerNorm', 'cross_modal_image_layers.4.crossattention.output.dropout', 'cross_modal_image_layers.4.intermediate', 'cross_modal_image_layers.4.intermediate.dense', 'cross_modal_image_layers.4.intermediate.intermediate_act_fn', 'cross_modal_image_layers.4.output', 'cross_modal_image_layers.4.output.dense', 'cross_modal_image_layers.4.output.LayerNorm', 'cross_modal_image_layers.4.output.dropout', 'cross_modal_image_layers.5', 'cross_modal_image_layers.5.attention', 'cross_modal_image_layers.5.attention.self', 'cross_modal_image_layers.5.attention.self.query', 'cross_modal_image_layers.5.attention.self.key', 'cross_modal_image_layers.5.attention.self.value', 'cross_modal_image_layers.5.attention.self.dropout', 'cross_modal_image_layers.5.attention.output', 'cross_modal_image_layers.5.attention.output.dense', 'cross_modal_image_layers.5.attention.output.LayerNorm', 'cross_modal_image_layers.5.attention.output.dropout', 'cross_modal_image_layers.5.crossattention', 'cross_modal_image_layers.5.crossattention.self', 'cross_modal_image_layers.5.crossattention.self.query', 'cross_modal_image_layers.5.crossattention.self.key', 'cross_modal_image_layers.5.crossattention.self.value', 'cross_modal_image_layers.5.crossattention.self.dropout', 'cross_modal_image_layers.5.crossattention.output', 'cross_modal_image_layers.5.crossattention.output.dense', 'cross_modal_image_layers.5.crossattention.output.LayerNorm', 'cross_modal_image_layers.5.crossattention.output.dropout', 'cross_modal_image_layers.5.intermediate', 'cross_modal_image_layers.5.intermediate.dense', 'cross_modal_image_layers.5.intermediate.intermediate_act_fn', 'cross_modal_image_layers.5.output', 'cross_modal_image_layers.5.output.dense', 'cross_modal_image_layers.5.output.LayerNorm', 'cross_modal_image_layers.5.output.dropout', 'cross_modal_text_layers', 'cross_modal_text_layers.0', 'cross_modal_text_layers.0.attention', 'cross_modal_text_layers.0.attention.self', 'cross_modal_text_layers.0.attention.self.query', 'cross_modal_text_layers.0.attention.self.key', 'cross_modal_text_layers.0.attention.self.value', 'cross_modal_text_layers.0.attention.self.dropout', 'cross_modal_text_layers.0.attention.output', 'cross_modal_text_layers.0.attention.output.dense', 'cross_modal_text_layers.0.attention.output.LayerNorm', 'cross_modal_text_layers.0.attention.output.dropout', 'cross_modal_text_layers.0.crossattention', 'cross_modal_text_layers.0.crossattention.self', 'cross_modal_text_layers.0.crossattention.self.query', 'cross_modal_text_layers.0.crossattention.self.key', 'cross_modal_text_layers.0.crossattention.self.value', 'cross_modal_text_layers.0.crossattention.self.dropout', 'cross_modal_text_layers.0.crossattention.output', 'cross_modal_text_layers.0.crossattention.output.dense', 'cross_modal_text_layers.0.crossattention.output.LayerNorm', 'cross_modal_text_layers.0.crossattention.output.dropout', 'cross_modal_text_layers.0.intermediate', 'cross_modal_text_layers.0.intermediate.dense', 'cross_modal_text_layers.0.intermediate.intermediate_act_fn', 'cross_modal_text_layers.0.output', 'cross_modal_text_layers.0.output.dense', 'cross_modal_text_layers.0.output.LayerNorm', 'cross_modal_text_layers.0.output.dropout', 'cross_modal_text_layers.1', 'cross_modal_text_layers.1.attention', 'cross_modal_text_layers.1.attention.self', 'cross_modal_text_layers.1.attention.self.query', 'cross_modal_text_layers.1.attention.self.key', 'cross_modal_text_layers.1.attention.self.value', 'cross_modal_text_layers.1.attention.self.dropout', 'cross_modal_text_layers.1.attention.output', 'cross_modal_text_layers.1.attention.output.dense', 'cross_modal_text_layers.1.attention.output.LayerNorm', 'cross_modal_text_layers.1.attention.output.dropout', 'cross_modal_text_layers.1.crossattention', 'cross_modal_text_layers.1.crossattention.self', 'cross_modal_text_layers.1.crossattention.self.query', 'cross_modal_text_layers.1.crossattention.self.key', 'cross_modal_text_layers.1.crossattention.self.value', 'cross_modal_text_layers.1.crossattention.self.dropout', 'cross_modal_text_layers.1.crossattention.output', 'cross_modal_text_layers.1.crossattention.output.dense', 'cross_modal_text_layers.1.crossattention.output.LayerNorm', 'cross_modal_text_layers.1.crossattention.output.dropout', 'cross_modal_text_layers.1.intermediate', 'cross_modal_text_layers.1.intermediate.dense', 'cross_modal_text_layers.1.intermediate.intermediate_act_fn', 'cross_modal_text_layers.1.output', 'cross_modal_text_layers.1.output.dense', 'cross_modal_text_layers.1.output.LayerNorm', 'cross_modal_text_layers.1.output.dropout', 'cross_modal_text_layers.2', 'cross_modal_text_layers.2.attention', 'cross_modal_text_layers.2.attention.self', 'cross_modal_text_layers.2.attention.self.query', 'cross_modal_text_layers.2.attention.self.key', 'cross_modal_text_layers.2.attention.self.value', 'cross_modal_text_layers.2.attention.self.dropout', 'cross_modal_text_layers.2.attention.output', 'cross_modal_text_layers.2.attention.output.dense', 'cross_modal_text_layers.2.attention.output.LayerNorm', 'cross_modal_text_layers.2.attention.output.dropout', 'cross_modal_text_layers.2.crossattention', 'cross_modal_text_layers.2.crossattention.self', 'cross_modal_text_layers.2.crossattention.self.query', 'cross_modal_text_layers.2.crossattention.self.key', 'cross_modal_text_layers.2.crossattention.self.value', 'cross_modal_text_layers.2.crossattention.self.dropout', 'cross_modal_text_layers.2.crossattention.output', 'cross_modal_text_layers.2.crossattention.output.dense', 'cross_modal_text_layers.2.crossattention.output.LayerNorm', 'cross_modal_text_layers.2.crossattention.output.dropout', 'cross_modal_text_layers.2.intermediate', 'cross_modal_text_layers.2.intermediate.dense', 'cross_modal_text_layers.2.intermediate.intermediate_act_fn', 'cross_modal_text_layers.2.output', 'cross_modal_text_layers.2.output.dense', 'cross_modal_text_layers.2.output.LayerNorm', 'cross_modal_text_layers.2.output.dropout', 'cross_modal_text_layers.3', 'cross_modal_text_layers.3.attention', 'cross_modal_text_layers.3.attention.self', 'cross_modal_text_layers.3.attention.self.query', 'cross_modal_text_layers.3.attention.self.key', 'cross_modal_text_layers.3.attention.self.value', 'cross_modal_text_layers.3.attention.self.dropout', 'cross_modal_text_layers.3.attention.output', 'cross_modal_text_layers.3.attention.output.dense', 'cross_modal_text_layers.3.attention.output.LayerNorm', 'cross_modal_text_layers.3.attention.output.dropout', 'cross_modal_text_layers.3.crossattention', 'cross_modal_text_layers.3.crossattention.self', 'cross_modal_text_layers.3.crossattention.self.query', 'cross_modal_text_layers.3.crossattention.self.key', 'cross_modal_text_layers.3.crossattention.self.value', 'cross_modal_text_layers.3.crossattention.self.dropout', 'cross_modal_text_layers.3.crossattention.output', 'cross_modal_text_layers.3.crossattention.output.dense', 'cross_modal_text_layers.3.crossattention.output.LayerNorm', 'cross_modal_text_layers.3.crossattention.output.dropout', 'cross_modal_text_layers.3.intermediate', 'cross_modal_text_layers.3.intermediate.dense', 'cross_modal_text_layers.3.intermediate.intermediate_act_fn', 'cross_modal_text_layers.3.output', 'cross_modal_text_layers.3.output.dense', 'cross_modal_text_layers.3.output.LayerNorm', 'cross_modal_text_layers.3.output.dropout', 'cross_modal_text_layers.4', 'cross_modal_text_layers.4.attention', 'cross_modal_text_layers.4.attention.self', 'cross_modal_text_layers.4.attention.self.query', 'cross_modal_text_layers.4.attention.self.key', 'cross_modal_text_layers.4.attention.self.value', 'cross_modal_text_layers.4.attention.self.dropout', 'cross_modal_text_layers.4.attention.output', 'cross_modal_text_layers.4.attention.output.dense', 'cross_modal_text_layers.4.attention.output.LayerNorm', 'cross_modal_text_layers.4.attention.output.dropout', 'cross_modal_text_layers.4.crossattention', 'cross_modal_text_layers.4.crossattention.self', 'cross_modal_text_layers.4.crossattention.self.query', 'cross_modal_text_layers.4.crossattention.self.key', 'cross_modal_text_layers.4.crossattention.self.value', 'cross_modal_text_layers.4.crossattention.self.dropout', 'cross_modal_text_layers.4.crossattention.output', 'cross_modal_text_layers.4.crossattention.output.dense', 'cross_modal_text_layers.4.crossattention.output.LayerNorm', 'cross_modal_text_layers.4.crossattention.output.dropout', 'cross_modal_text_layers.4.intermediate', 'cross_modal_text_layers.4.intermediate.dense', 'cross_modal_text_layers.4.intermediate.intermediate_act_fn', 'cross_modal_text_layers.4.output', 'cross_modal_text_layers.4.output.dense', 'cross_modal_text_layers.4.output.LayerNorm', 'cross_modal_text_layers.4.output.dropout', 'cross_modal_text_layers.5', 'cross_modal_text_layers.5.attention', 'cross_modal_text_layers.5.attention.self', 'cross_modal_text_layers.5.attention.self.query', 'cross_modal_text_layers.5.attention.self.key', 'cross_modal_text_layers.5.attention.self.value', 'cross_modal_text_layers.5.attention.self.dropout', 'cross_modal_text_layers.5.attention.output', 'cross_modal_text_layers.5.attention.output.dense', 'cross_modal_text_layers.5.attention.output.LayerNorm', 'cross_modal_text_layers.5.attention.output.dropout', 'cross_modal_text_layers.5.crossattention', 'cross_modal_text_layers.5.crossattention.self', 'cross_modal_text_layers.5.crossattention.self.query', 'cross_modal_text_layers.5.crossattention.self.key', 'cross_modal_text_layers.5.crossattention.self.value', 'cross_modal_text_layers.5.crossattention.self.dropout', 'cross_modal_text_layers.5.crossattention.output', 'cross_modal_text_layers.5.crossattention.output.dense', 'cross_modal_text_layers.5.crossattention.output.LayerNorm', 'cross_modal_text_layers.5.crossattention.output.dropout', 'cross_modal_text_layers.5.intermediate', 'cross_modal_text_layers.5.intermediate.dense', 'cross_modal_text_layers.5.intermediate.intermediate_act_fn', 'cross_modal_text_layers.5.output', 'cross_modal_text_layers.5.output.dense', 'cross_modal_text_layers.5.output.LayerNorm', 'cross_modal_text_layers.5.output.dropout', 'cross_modal_image_pooler', 'cross_modal_image_pooler.dense', 'cross_modal_image_pooler.activation', 'cross_modal_text_pooler', 'cross_modal_text_pooler.dense', 'cross_modal_text_pooler.activation', 'vqa_classifier', 'vqa_classifier.0', 'vqa_classifier.1', 'vqa_classifier.2', 'vqa_classifier.3', 'train_vqa_score', 'train_vqa_loss', 'val_vqa_score', 'val_vqa_loss')\n"
     ]
    }
   ],
   "source": [
    "# Print the submodules of the model\n",
    "print(\"Model submodules\")\n",
    "names, modules = zip(*list(model.named_modules()))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after quantization:\n",
      "Size (MB): 122.099212\n",
      "ViLTransformerSS(\n",
      "  (text_embeddings): BertEmbeddings(\n",
      "    (word_embeddings): QuantizedEmbedding(num_embeddings=30522, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (position_embeddings): QuantizedEmbedding(num_embeddings=40, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (token_type_embeddings): QuantizedEmbedding(num_embeddings=2, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "  )\n",
      "  (token_type_embeddings): QuantizedEmbedding(num_embeddings=3, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): DynamicQuantizedLinear(in_features=768, out_features=2304, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (pooler): Pooler(\n",
      "    (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (nlvr2_classifier): Sequential(\n",
      "    (0): DynamicQuantizedLinear(in_features=1536, out_features=1536, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): DynamicQuantizedLinear(in_features=1536, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (train_nlvr2_accuracy): Accuracy()\n",
      "  (train_nlvr2_loss): Scalar()\n",
      "  (dev_nlvr2_accuracy): Accuracy()\n",
      "  (dev_nlvr2_loss): Scalar()\n",
      "  (test_nlvr2_accuracy): Accuracy()\n",
      "  (test_nlvr2_loss): Scalar()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import dynamic_quantization as dq\n",
    "\n",
    "default_dynamic = copy.deepcopy(model)\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "        default_dynamic, {torch.nn.Embedding, torch.nn.Conv2d}, dtype=torch.quint8, inplace=True\n",
    "    )\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "        default_dynamic, {torch.nn.Linear, torch.nn.LayerNorm, torch.nn.Conv2d}, dtype=torch.qint8, inplace=True\n",
    "    )\n",
    "\n",
    "print(\"Size after quantization:\")\n",
    "print_size_of_model(default_dynamic)\n",
    "print(default_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Quantizing the model DYNAMIC =========\n",
      "Size after quantization:\n",
      "Size of the model (MB): 122.099212\n"
     ]
    }
   ],
   "source": [
    "import dynamic_quantization as dq\n",
    "\n",
    "custom_8bit = copy.deepcopy(model)\n",
    "custom_8bit = dq.quantize_model_dynamic(custom_8bit, 8)\n",
    "\n",
    "print(\"Size after quantization:\")\n",
    "print_size_of_model(custom_8bit)\n",
    "# print(model_dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Suite Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization._numeric_suite as ns\n",
    "\n",
    "def compute_error(x, y):\n",
    "    \"\"\"\n",
    "    Signal to Noise Ratio (SNR)    \n",
    "    \"\"\"\n",
    "    Ps = torch.norm(x)\n",
    "    Pn = torch.norm(x-y)\n",
    "    return 20*torch.log10(Ps/Pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.weight\n",
      "0 - inf\n",
      "1 - transformer.patch_embed.proj.weight\n",
      "1 - inf\n",
      "2 - transformer.blocks.0.norm1.weight\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.attn.qkv._packed_params._packed_params\n",
      "3 - 27.66\n",
      "4 - transformer.blocks.0.attn.proj._packed_params._packed_params\n",
      "4 - 21.96\n",
      "5 - transformer.blocks.0.norm2.weight\n",
      "5 - inf\n",
      "6 - transformer.blocks.0.mlp.fc1._packed_params._packed_params\n",
      "6 - 26.82\n",
      "7 - transformer.blocks.0.mlp.fc2._packed_params._packed_params\n",
      "7 - 18.22\n",
      "8 - transformer.blocks.1.norm1.weight\n",
      "8 - inf\n",
      "9 - transformer.blocks.1.attn.qkv._packed_params._packed_params\n",
      "9 - 32.16\n",
      "10 - transformer.blocks.1.attn.proj._packed_params._packed_params\n",
      "10 - 29.15\n",
      "11 - transformer.blocks.1.norm2.weight\n",
      "11 - inf\n",
      "12 - transformer.blocks.1.mlp.fc1._packed_params._packed_params\n",
      "12 - 27.63\n",
      "13 - transformer.blocks.1.mlp.fc2._packed_params._packed_params\n",
      "13 - 16.82\n",
      "14 - transformer.blocks.2.norm1.weight\n",
      "14 - inf\n",
      "15 - transformer.blocks.2.attn.qkv._packed_params._packed_params\n",
      "15 - 33.97\n",
      "16 - transformer.blocks.2.attn.proj._packed_params._packed_params\n",
      "16 - 36.37\n",
      "17 - transformer.blocks.2.norm2.weight\n",
      "17 - inf\n",
      "18 - transformer.blocks.2.mlp.fc1._packed_params._packed_params\n",
      "18 - 32.58\n",
      "19 - transformer.blocks.2.mlp.fc2._packed_params._packed_params\n",
      "19 - 16.36\n",
      "20 - transformer.blocks.3.norm1.weight\n",
      "20 - inf\n",
      "21 - transformer.blocks.3.attn.qkv._packed_params._packed_params\n",
      "21 - 33.17\n",
      "22 - transformer.blocks.3.attn.proj._packed_params._packed_params\n",
      "22 - 36.98\n",
      "23 - transformer.blocks.3.norm2.weight\n",
      "23 - inf\n",
      "24 - transformer.blocks.3.mlp.fc1._packed_params._packed_params\n",
      "24 - 31.92\n",
      "25 - transformer.blocks.3.mlp.fc2._packed_params._packed_params\n",
      "25 - 30.59\n",
      "26 - transformer.blocks.4.norm1.weight\n",
      "26 - inf\n",
      "27 - transformer.blocks.4.attn.qkv._packed_params._packed_params\n",
      "27 - 34.69\n",
      "28 - transformer.blocks.4.attn.proj._packed_params._packed_params\n",
      "28 - 38.77\n",
      "29 - transformer.blocks.4.norm2.weight\n",
      "29 - inf\n",
      "30 - transformer.blocks.4.mlp.fc1._packed_params._packed_params\n",
      "30 - 31.58\n",
      "31 - transformer.blocks.4.mlp.fc2._packed_params._packed_params\n",
      "31 - 27.02\n",
      "32 - transformer.blocks.5.norm1.weight\n",
      "32 - inf\n",
      "33 - transformer.blocks.5.attn.qkv._packed_params._packed_params\n",
      "33 - 33.92\n",
      "34 - transformer.blocks.5.attn.proj._packed_params._packed_params\n",
      "34 - 38.16\n",
      "35 - transformer.blocks.5.norm2.weight\n",
      "35 - inf\n",
      "36 - transformer.blocks.5.mlp.fc1._packed_params._packed_params\n",
      "36 - 35.53\n",
      "37 - transformer.blocks.5.mlp.fc2._packed_params._packed_params\n",
      "37 - 29.81\n",
      "38 - transformer.blocks.6.norm1.weight\n",
      "38 - inf\n",
      "39 - transformer.blocks.6.attn.qkv._packed_params._packed_params\n",
      "39 - 35.89\n",
      "40 - transformer.blocks.6.attn.proj._packed_params._packed_params\n",
      "40 - 33.90\n",
      "41 - transformer.blocks.6.norm2.weight\n",
      "41 - inf\n",
      "42 - transformer.blocks.6.mlp.fc1._packed_params._packed_params\n",
      "42 - 31.89\n",
      "43 - transformer.blocks.6.mlp.fc2._packed_params._packed_params\n",
      "43 - 16.10\n",
      "44 - transformer.blocks.7.norm1.weight\n",
      "44 - inf\n",
      "45 - transformer.blocks.7.attn.qkv._packed_params._packed_params\n",
      "45 - 33.92\n",
      "46 - transformer.blocks.7.attn.proj._packed_params._packed_params\n",
      "46 - 37.94\n",
      "47 - transformer.blocks.7.norm2.weight\n",
      "47 - inf\n",
      "48 - transformer.blocks.7.mlp.fc1._packed_params._packed_params\n",
      "48 - 23.23\n",
      "49 - transformer.blocks.7.mlp.fc2._packed_params._packed_params\n",
      "49 - 15.11\n",
      "50 - transformer.blocks.8.norm1.weight\n",
      "50 - inf\n",
      "51 - transformer.blocks.8.attn.qkv._packed_params._packed_params\n",
      "51 - 35.26\n",
      "52 - transformer.blocks.8.attn.proj._packed_params._packed_params\n",
      "52 - 36.08\n",
      "53 - transformer.blocks.8.norm2.weight\n",
      "53 - inf\n",
      "54 - transformer.blocks.8.mlp.fc1._packed_params._packed_params\n",
      "54 - 18.87\n",
      "55 - transformer.blocks.8.mlp.fc2._packed_params._packed_params\n",
      "55 - 18.36\n",
      "56 - transformer.blocks.9.norm1.weight\n",
      "56 - inf\n",
      "57 - transformer.blocks.9.attn.qkv._packed_params._packed_params\n",
      "57 - 33.13\n",
      "58 - transformer.blocks.9.attn.proj._packed_params._packed_params\n",
      "58 - 30.52\n",
      "59 - transformer.blocks.9.norm2.weight\n",
      "59 - inf\n",
      "60 - transformer.blocks.9.mlp.fc1._packed_params._packed_params\n",
      "60 - 22.55\n",
      "61 - transformer.blocks.9.mlp.fc2._packed_params._packed_params\n",
      "61 - 21.04\n",
      "62 - transformer.blocks.10.norm1.weight\n",
      "62 - inf\n",
      "63 - transformer.blocks.10.attn.qkv._packed_params._packed_params\n",
      "63 - 30.75\n",
      "64 - transformer.blocks.10.attn.proj._packed_params._packed_params\n",
      "64 - 34.32\n",
      "65 - transformer.blocks.10.norm2.weight\n",
      "65 - inf\n",
      "66 - transformer.blocks.10.mlp.fc1._packed_params._packed_params\n",
      "66 - 33.32\n",
      "67 - transformer.blocks.10.mlp.fc2._packed_params._packed_params\n",
      "67 - 29.17\n",
      "68 - transformer.blocks.11.norm1.weight\n",
      "68 - inf\n",
      "69 - transformer.blocks.11.attn.qkv._packed_params._packed_params\n",
      "69 - 30.99\n",
      "70 - transformer.blocks.11.attn.proj._packed_params._packed_params\n",
      "70 - 26.40\n",
      "71 - transformer.blocks.11.norm2.weight\n",
      "71 - inf\n",
      "72 - transformer.blocks.11.mlp.fc1._packed_params._packed_params\n",
      "72 - 28.97\n",
      "73 - transformer.blocks.11.mlp.fc2._packed_params._packed_params\n",
      "73 - 19.50\n",
      "74 - transformer.norm.weight\n",
      "74 - inf\n",
      "75 - pooler.dense._packed_params._packed_params\n",
      "75 - 36.56\n",
      "76 - nlvr2_classifier.0._packed_params._packed_params\n",
      "76 - 38.95\n",
      "77 - nlvr2_classifier.1.weight\n",
      "77 - inf\n",
      "78 - nlvr2_classifier.3._packed_params._packed_params\n",
      "78 - 40.77\n",
      "Total error: 1515.32\n",
      "Total inf: 28\n",
      "Max error: 40.76809310913086\n"
     ]
    }
   ],
   "source": [
    "# ======== Dynamic quantization comparison ========\n",
    "wt_compare_dict_dynamic = ns.compare_weights(model.state_dict(), custom_8bit.state_dict())\n",
    "\n",
    "# print('keys of wt_compare_dict:')\n",
    "# print(wt_compare_dict_dynamic.keys())\n",
    "\n",
    "# key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "total_error = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for i, key in enumerate(wt_compare_dict_dynamic):\n",
    "    if wt_compare_dict_dynamic[key]['quantized'].is_quantized:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'].dequantize())\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "        \n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "    else:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'])\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "\n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "\n",
    "print(f\"Total error: {total_error:.2f}\")\n",
    "print(f\"Total inf: {inf_count}\")\n",
    "print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_batch = next(iter(infer_dataloader))\n",
    "# calibration_batch = next(iter(calibrarte_dm.val_dataloader()))\n",
    "# full_batch = next(iter(full_dm.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.norm.stats', 'pooler.dense.stats'])\n"
     ]
    }
   ],
   "source": [
    "# act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), full_batch)\n",
    "act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(custom_8bit), infer_batch)\n",
    "print(act_compare_dict_dynamic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 38.81\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - 38.69\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.norm1.stats\n",
      "3 - -1.60\n",
      "4 - transformer.blocks.0.attn.qkv.stats\n",
      "4 - 3.39\n",
      "5 - transformer.blocks.0.attn.proj.stats\n",
      "5 - -2.19\n",
      "6 - transformer.blocks.0.norm2.stats\n",
      "6 - -1.20\n",
      "7 - transformer.blocks.0.mlp.fc1.stats\n",
      "7 - 3.85\n",
      "8 - transformer.blocks.0.mlp.fc2.stats\n",
      "8 - -2.46\n",
      "9 - transformer.blocks.1.norm1.stats\n",
      "9 - -1.73\n",
      "10 - transformer.blocks.1.attn.qkv.stats\n",
      "10 - 3.21\n",
      "11 - transformer.blocks.1.attn.proj.stats\n",
      "11 - -1.97\n",
      "12 - transformer.blocks.1.norm2.stats\n",
      "12 - -0.67\n",
      "13 - transformer.blocks.1.mlp.fc1.stats\n",
      "13 - 3.16\n",
      "14 - transformer.blocks.1.mlp.fc2.stats\n",
      "14 - -2.50\n",
      "15 - transformer.blocks.2.norm1.stats\n",
      "15 - -1.57\n",
      "16 - transformer.blocks.2.attn.qkv.stats\n",
      "16 - 0.13\n",
      "17 - transformer.blocks.2.attn.proj.stats\n",
      "17 - -2.05\n",
      "18 - transformer.blocks.2.norm2.stats\n",
      "18 - -0.66\n",
      "19 - transformer.blocks.2.mlp.fc1.stats\n",
      "19 - 3.54\n",
      "20 - transformer.blocks.2.mlp.fc2.stats\n",
      "20 - -2.46\n",
      "21 - transformer.blocks.3.norm1.stats\n",
      "21 - -1.65\n",
      "22 - transformer.blocks.3.attn.qkv.stats\n",
      "22 - 0.45\n",
      "23 - transformer.blocks.3.attn.proj.stats\n",
      "23 - -1.99\n",
      "24 - transformer.blocks.3.norm2.stats\n",
      "24 - -0.67\n",
      "25 - transformer.blocks.3.mlp.fc1.stats\n",
      "25 - 3.90\n",
      "26 - transformer.blocks.3.mlp.fc2.stats\n",
      "26 - -2.23\n",
      "27 - transformer.blocks.4.norm1.stats\n",
      "27 - -1.68\n",
      "28 - transformer.blocks.4.attn.qkv.stats\n",
      "28 - 0.99\n",
      "29 - transformer.blocks.4.attn.proj.stats\n",
      "29 - -1.25\n",
      "30 - transformer.blocks.4.norm2.stats\n",
      "30 - -0.83\n",
      "31 - transformer.blocks.4.mlp.fc1.stats\n",
      "31 - 4.14\n",
      "32 - transformer.blocks.4.mlp.fc2.stats\n",
      "32 - -2.07\n",
      "33 - transformer.blocks.5.norm1.stats\n",
      "33 - -1.69\n",
      "34 - transformer.blocks.5.attn.qkv.stats\n",
      "34 - 1.50\n",
      "35 - transformer.blocks.5.attn.proj.stats\n",
      "35 - -1.40\n",
      "36 - transformer.blocks.5.norm2.stats\n",
      "36 - -0.87\n",
      "37 - transformer.blocks.5.mlp.fc1.stats\n",
      "37 - 4.58\n",
      "38 - transformer.blocks.5.mlp.fc2.stats\n",
      "38 - -1.89\n",
      "39 - transformer.blocks.6.norm1.stats\n",
      "39 - -1.64\n",
      "40 - transformer.blocks.6.attn.qkv.stats\n",
      "40 - 2.44\n",
      "41 - transformer.blocks.6.attn.proj.stats\n",
      "41 - -1.32\n",
      "42 - transformer.blocks.6.norm2.stats\n",
      "42 - -0.91\n",
      "43 - transformer.blocks.6.mlp.fc1.stats\n",
      "43 - 4.66\n",
      "44 - transformer.blocks.6.mlp.fc2.stats\n",
      "44 - -2.15\n",
      "45 - transformer.blocks.7.norm1.stats\n",
      "45 - -1.52\n",
      "46 - transformer.blocks.7.attn.qkv.stats\n",
      "46 - 6.07\n",
      "47 - transformer.blocks.7.attn.proj.stats\n",
      "47 - -0.54\n",
      "48 - transformer.blocks.7.norm2.stats\n",
      "48 - -0.87\n",
      "49 - transformer.blocks.7.mlp.fc1.stats\n",
      "49 - 4.99\n",
      "50 - transformer.blocks.7.mlp.fc2.stats\n",
      "50 - -1.42\n",
      "51 - transformer.blocks.8.norm1.stats\n",
      "51 - -1.36\n",
      "52 - transformer.blocks.8.attn.qkv.stats\n",
      "52 - 8.05\n",
      "53 - transformer.blocks.8.attn.proj.stats\n",
      "53 - -0.38\n",
      "54 - transformer.blocks.8.norm2.stats\n",
      "54 - -0.91\n",
      "55 - transformer.blocks.8.mlp.fc1.stats\n",
      "55 - 4.71\n",
      "56 - transformer.blocks.8.mlp.fc2.stats\n",
      "56 - -2.26\n",
      "57 - transformer.blocks.9.norm1.stats\n",
      "57 - -1.24\n",
      "58 - transformer.blocks.9.attn.qkv.stats\n",
      "58 - 9.07\n",
      "59 - transformer.blocks.9.attn.proj.stats\n",
      "59 - -0.18\n",
      "60 - transformer.blocks.9.norm2.stats\n",
      "60 - -0.76\n",
      "61 - transformer.blocks.9.mlp.fc1.stats\n",
      "61 - 6.01\n",
      "62 - transformer.blocks.9.mlp.fc2.stats\n",
      "62 - -0.98\n",
      "63 - transformer.blocks.10.norm1.stats\n",
      "63 - -0.34\n",
      "64 - transformer.blocks.10.attn.qkv.stats\n",
      "64 - 9.05\n",
      "65 - transformer.blocks.10.attn.proj.stats\n",
      "65 - 3.20\n",
      "66 - transformer.blocks.10.norm2.stats\n",
      "66 - 0.71\n",
      "67 - transformer.blocks.10.mlp.fc1.stats\n",
      "67 - 8.63\n",
      "68 - transformer.blocks.10.mlp.fc2.stats\n",
      "68 - 0.76\n",
      "69 - transformer.blocks.11.norm1.stats\n",
      "69 - 0.41\n",
      "70 - transformer.blocks.11.attn.qkv.stats\n",
      "70 - 10.08\n",
      "71 - transformer.blocks.11.attn.proj.stats\n",
      "71 - 10.70\n",
      "72 - transformer.blocks.11.norm2.stats\n",
      "72 - 1.52\n",
      "73 - transformer.blocks.11.mlp.fc1.stats\n",
      "73 - 8.40\n",
      "74 - transformer.blocks.11.mlp.fc2.stats\n",
      "74 - 6.50\n",
      "75 - transformer.norm.stats\n",
      "75 - 9.95\n",
      "76 - pooler.dense.stats\n",
      "76 - 11.90\n",
      "Total error: 180.13\n"
     ]
    }
   ],
   "source": [
    "total_err = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for idx, key in enumerate(act_compare_dict_dynamic):\n",
    "    err = compute_error(act_compare_dict_dynamic[key]['float'][0][0], act_compare_dict_dynamic[key]['quantized'][0][0])\n",
    "    # print(type(err))\n",
    "    if torch.isinf(err):\n",
    "        inf_count += 1\n",
    "    else:\n",
    "        total_err += err\n",
    "        if err > max_err:\n",
    "            max_err = err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err:.2f}\")\n",
    "\n",
    "print(f\"Total error: {total_err:.2f}\")\n",
    "# print(f\"Total inf: {inf_count}\")\n",
    "# print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.weight\n",
      "0 - inf\n",
      "1 - transformer.patch_embed.proj.weight\n",
      "1 - inf\n",
      "2 - transformer.blocks.0.norm1.weight\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.attn.qkv._packed_params._packed_params\n",
      "3 - 27.66\n",
      "4 - transformer.blocks.0.attn.proj._packed_params._packed_params\n",
      "4 - 21.96\n",
      "5 - transformer.blocks.0.norm2.weight\n",
      "5 - inf\n",
      "6 - transformer.blocks.0.mlp.fc1._packed_params._packed_params\n",
      "6 - 26.82\n",
      "7 - transformer.blocks.0.mlp.fc2._packed_params._packed_params\n",
      "7 - 18.22\n",
      "8 - transformer.blocks.1.norm1.weight\n",
      "8 - inf\n",
      "9 - transformer.blocks.1.attn.qkv._packed_params._packed_params\n",
      "9 - 32.16\n",
      "10 - transformer.blocks.1.attn.proj._packed_params._packed_params\n",
      "10 - 29.15\n",
      "11 - transformer.blocks.1.norm2.weight\n",
      "11 - inf\n",
      "12 - transformer.blocks.1.mlp.fc1._packed_params._packed_params\n",
      "12 - 27.63\n",
      "13 - transformer.blocks.1.mlp.fc2._packed_params._packed_params\n",
      "13 - 16.82\n",
      "14 - transformer.blocks.2.norm1.weight\n",
      "14 - inf\n",
      "15 - transformer.blocks.2.attn.qkv._packed_params._packed_params\n",
      "15 - 33.97\n",
      "16 - transformer.blocks.2.attn.proj._packed_params._packed_params\n",
      "16 - 36.37\n",
      "17 - transformer.blocks.2.norm2.weight\n",
      "17 - inf\n",
      "18 - transformer.blocks.2.mlp.fc1._packed_params._packed_params\n",
      "18 - 32.58\n",
      "19 - transformer.blocks.2.mlp.fc2._packed_params._packed_params\n",
      "19 - 16.36\n",
      "20 - transformer.blocks.3.norm1.weight\n",
      "20 - inf\n",
      "21 - transformer.blocks.3.attn.qkv._packed_params._packed_params\n",
      "21 - 33.17\n",
      "22 - transformer.blocks.3.attn.proj._packed_params._packed_params\n",
      "22 - 36.98\n",
      "23 - transformer.blocks.3.norm2.weight\n",
      "23 - inf\n",
      "24 - transformer.blocks.3.mlp.fc1._packed_params._packed_params\n",
      "24 - 31.92\n",
      "25 - transformer.blocks.3.mlp.fc2._packed_params._packed_params\n",
      "25 - 30.59\n",
      "26 - transformer.blocks.4.norm1.weight\n",
      "26 - inf\n",
      "27 - transformer.blocks.4.attn.qkv._packed_params._packed_params\n",
      "27 - 34.69\n",
      "28 - transformer.blocks.4.attn.proj._packed_params._packed_params\n",
      "28 - 38.77\n",
      "29 - transformer.blocks.4.norm2.weight\n",
      "29 - inf\n",
      "30 - transformer.blocks.4.mlp.fc1._packed_params._packed_params\n",
      "30 - 31.58\n",
      "31 - transformer.blocks.4.mlp.fc2._packed_params._packed_params\n",
      "31 - 27.02\n",
      "32 - transformer.blocks.5.norm1.weight\n",
      "32 - inf\n",
      "33 - transformer.blocks.5.attn.qkv._packed_params._packed_params\n",
      "33 - 33.92\n",
      "34 - transformer.blocks.5.attn.proj._packed_params._packed_params\n",
      "34 - 38.16\n",
      "35 - transformer.blocks.5.norm2.weight\n",
      "35 - inf\n",
      "36 - transformer.blocks.5.mlp.fc1._packed_params._packed_params\n",
      "36 - 35.53\n",
      "37 - transformer.blocks.5.mlp.fc2._packed_params._packed_params\n",
      "37 - 29.81\n",
      "38 - transformer.blocks.6.norm1.weight\n",
      "38 - inf\n",
      "39 - transformer.blocks.6.attn.qkv._packed_params._packed_params\n",
      "39 - 35.89\n",
      "40 - transformer.blocks.6.attn.proj._packed_params._packed_params\n",
      "40 - 33.90\n",
      "41 - transformer.blocks.6.norm2.weight\n",
      "41 - inf\n",
      "42 - transformer.blocks.6.mlp.fc1._packed_params._packed_params\n",
      "42 - 31.89\n",
      "43 - transformer.blocks.6.mlp.fc2._packed_params._packed_params\n",
      "43 - 16.10\n",
      "44 - transformer.blocks.7.norm1.weight\n",
      "44 - inf\n",
      "45 - transformer.blocks.7.attn.qkv._packed_params._packed_params\n",
      "45 - 33.92\n",
      "46 - transformer.blocks.7.attn.proj._packed_params._packed_params\n",
      "46 - 37.94\n",
      "47 - transformer.blocks.7.norm2.weight\n",
      "47 - inf\n",
      "48 - transformer.blocks.7.mlp.fc1._packed_params._packed_params\n",
      "48 - 23.23\n",
      "49 - transformer.blocks.7.mlp.fc2._packed_params._packed_params\n",
      "49 - 15.11\n",
      "50 - transformer.blocks.8.norm1.weight\n",
      "50 - inf\n",
      "51 - transformer.blocks.8.attn.qkv._packed_params._packed_params\n",
      "51 - 35.26\n",
      "52 - transformer.blocks.8.attn.proj._packed_params._packed_params\n",
      "52 - 36.08\n",
      "53 - transformer.blocks.8.norm2.weight\n",
      "53 - inf\n",
      "54 - transformer.blocks.8.mlp.fc1._packed_params._packed_params\n",
      "54 - 18.87\n",
      "55 - transformer.blocks.8.mlp.fc2._packed_params._packed_params\n",
      "55 - 18.36\n",
      "56 - transformer.blocks.9.norm1.weight\n",
      "56 - inf\n",
      "57 - transformer.blocks.9.attn.qkv._packed_params._packed_params\n",
      "57 - 33.13\n",
      "58 - transformer.blocks.9.attn.proj._packed_params._packed_params\n",
      "58 - 30.52\n",
      "59 - transformer.blocks.9.norm2.weight\n",
      "59 - inf\n",
      "60 - transformer.blocks.9.mlp.fc1._packed_params._packed_params\n",
      "60 - 22.55\n",
      "61 - transformer.blocks.9.mlp.fc2._packed_params._packed_params\n",
      "61 - 21.04\n",
      "62 - transformer.blocks.10.norm1.weight\n",
      "62 - inf\n",
      "63 - transformer.blocks.10.attn.qkv._packed_params._packed_params\n",
      "63 - 30.75\n",
      "64 - transformer.blocks.10.attn.proj._packed_params._packed_params\n",
      "64 - 34.32\n",
      "65 - transformer.blocks.10.norm2.weight\n",
      "65 - inf\n",
      "66 - transformer.blocks.10.mlp.fc1._packed_params._packed_params\n",
      "66 - 33.32\n",
      "67 - transformer.blocks.10.mlp.fc2._packed_params._packed_params\n",
      "67 - 29.17\n",
      "68 - transformer.blocks.11.norm1.weight\n",
      "68 - inf\n",
      "69 - transformer.blocks.11.attn.qkv._packed_params._packed_params\n",
      "69 - 30.99\n",
      "70 - transformer.blocks.11.attn.proj._packed_params._packed_params\n",
      "70 - 26.40\n",
      "71 - transformer.blocks.11.norm2.weight\n",
      "71 - inf\n",
      "72 - transformer.blocks.11.mlp.fc1._packed_params._packed_params\n",
      "72 - 28.97\n",
      "73 - transformer.blocks.11.mlp.fc2._packed_params._packed_params\n",
      "73 - 19.50\n",
      "74 - transformer.norm.weight\n",
      "74 - inf\n",
      "75 - pooler.dense._packed_params._packed_params\n",
      "75 - 36.56\n",
      "76 - nlvr2_classifier.0._packed_params._packed_params\n",
      "76 - 38.95\n",
      "77 - nlvr2_classifier.1.weight\n",
      "77 - inf\n",
      "78 - nlvr2_classifier.3._packed_params._packed_params\n",
      "78 - 40.77\n",
      "Total error: 1515.32\n",
      "Total inf: 28\n",
      "Max error: 40.76809310913086\n"
     ]
    }
   ],
   "source": [
    "# ======== Dynamic quantization comparison ========\n",
    "wt_compare_dict_dynamic = ns.compare_weights(model.state_dict(), model_8.state_dict())\n",
    "\n",
    "# print('keys of wt_compare_dict:')\n",
    "# print(wt_compare_dict_dynamic.keys())\n",
    "\n",
    "# key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "total_error = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for i, key in enumerate(wt_compare_dict_dynamic):\n",
    "    if wt_compare_dict_dynamic[key]['quantized'].is_quantized:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'].dequantize())\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "        \n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "    else:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'])\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "\n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "\n",
    "print(f\"Total error: {total_error:.2f}\")\n",
    "print(f\"Total inf: {inf_count}\")\n",
    "print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.norm.stats', 'pooler.dense.stats'])\n"
     ]
    }
   ],
   "source": [
    "# act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), full_batch)\n",
    "act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_8), infer_batch)\n",
    "print(act_compare_dict_dynamic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 38.81\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - 38.69\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.norm1.stats\n",
      "3 - -1.87\n",
      "4 - transformer.blocks.0.attn.qkv.stats\n",
      "4 - 3.13\n",
      "5 - transformer.blocks.0.attn.proj.stats\n",
      "5 - -2.44\n",
      "6 - transformer.blocks.0.norm2.stats\n",
      "6 - -1.42\n",
      "7 - transformer.blocks.0.mlp.fc1.stats\n",
      "7 - 3.71\n",
      "8 - transformer.blocks.0.mlp.fc2.stats\n",
      "8 - -2.41\n",
      "9 - transformer.blocks.1.norm1.stats\n",
      "9 - -1.86\n",
      "10 - transformer.blocks.1.attn.qkv.stats\n",
      "10 - 3.06\n",
      "11 - transformer.blocks.1.attn.proj.stats\n",
      "11 - -2.14\n",
      "12 - transformer.blocks.1.norm2.stats\n",
      "12 - -0.78\n",
      "13 - transformer.blocks.1.mlp.fc1.stats\n",
      "13 - 3.07\n",
      "14 - transformer.blocks.1.mlp.fc2.stats\n",
      "14 - -2.50\n",
      "15 - transformer.blocks.2.norm1.stats\n",
      "15 - -1.65\n",
      "16 - transformer.blocks.2.attn.qkv.stats\n",
      "16 - 0.03\n",
      "17 - transformer.blocks.2.attn.proj.stats\n",
      "17 - -2.07\n",
      "18 - transformer.blocks.2.norm2.stats\n",
      "18 - -0.73\n",
      "19 - transformer.blocks.2.mlp.fc1.stats\n",
      "19 - 3.47\n",
      "20 - transformer.blocks.2.mlp.fc2.stats\n",
      "20 - -2.55\n",
      "21 - transformer.blocks.3.norm1.stats\n",
      "21 - -1.74\n",
      "22 - transformer.blocks.3.attn.qkv.stats\n",
      "22 - 0.31\n",
      "23 - transformer.blocks.3.attn.proj.stats\n",
      "23 - -2.06\n",
      "24 - transformer.blocks.3.norm2.stats\n",
      "24 - -0.78\n",
      "25 - transformer.blocks.3.mlp.fc1.stats\n",
      "25 - 3.71\n",
      "26 - transformer.blocks.3.mlp.fc2.stats\n",
      "26 - -2.34\n",
      "27 - transformer.blocks.4.norm1.stats\n",
      "27 - -1.78\n",
      "28 - transformer.blocks.4.attn.qkv.stats\n",
      "28 - 0.85\n",
      "29 - transformer.blocks.4.attn.proj.stats\n",
      "29 - -1.29\n",
      "30 - transformer.blocks.4.norm2.stats\n",
      "30 - -0.95\n",
      "31 - transformer.blocks.4.mlp.fc1.stats\n",
      "31 - 3.95\n",
      "32 - transformer.blocks.4.mlp.fc2.stats\n",
      "32 - -2.10\n",
      "33 - transformer.blocks.5.norm1.stats\n",
      "33 - -1.77\n",
      "34 - transformer.blocks.5.attn.qkv.stats\n",
      "34 - 1.38\n",
      "35 - transformer.blocks.5.attn.proj.stats\n",
      "35 - -1.42\n",
      "36 - transformer.blocks.5.norm2.stats\n",
      "36 - -0.97\n",
      "37 - transformer.blocks.5.mlp.fc1.stats\n",
      "37 - 4.47\n",
      "38 - transformer.blocks.5.mlp.fc2.stats\n",
      "38 - -1.92\n",
      "39 - transformer.blocks.6.norm1.stats\n",
      "39 - -1.72\n",
      "40 - transformer.blocks.6.attn.qkv.stats\n",
      "40 - 2.34\n",
      "41 - transformer.blocks.6.attn.proj.stats\n",
      "41 - -1.42\n",
      "42 - transformer.blocks.6.norm2.stats\n",
      "42 - -1.01\n",
      "43 - transformer.blocks.6.mlp.fc1.stats\n",
      "43 - 4.62\n",
      "44 - transformer.blocks.6.mlp.fc2.stats\n",
      "44 - -4.56\n",
      "45 - transformer.blocks.7.norm1.stats\n",
      "45 - -1.62\n",
      "46 - transformer.blocks.7.attn.qkv.stats\n",
      "46 - 5.93\n",
      "47 - transformer.blocks.7.attn.proj.stats\n",
      "47 - -0.88\n",
      "48 - transformer.blocks.7.norm2.stats\n",
      "48 - -0.98\n",
      "49 - transformer.blocks.7.mlp.fc1.stats\n",
      "49 - 4.90\n",
      "50 - transformer.blocks.7.mlp.fc2.stats\n",
      "50 - -0.90\n",
      "51 - transformer.blocks.8.norm1.stats\n",
      "51 - -1.46\n",
      "52 - transformer.blocks.8.attn.qkv.stats\n",
      "52 - 7.89\n",
      "53 - transformer.blocks.8.attn.proj.stats\n",
      "53 - -0.44\n",
      "54 - transformer.blocks.8.norm2.stats\n",
      "54 - -1.01\n",
      "55 - transformer.blocks.8.mlp.fc1.stats\n",
      "55 - 4.61\n",
      "56 - transformer.blocks.8.mlp.fc2.stats\n",
      "56 - -1.31\n",
      "57 - transformer.blocks.9.norm1.stats\n",
      "57 - -1.34\n",
      "58 - transformer.blocks.9.attn.qkv.stats\n",
      "58 - 8.92\n",
      "59 - transformer.blocks.9.attn.proj.stats\n",
      "59 - 0.01\n",
      "60 - transformer.blocks.9.norm2.stats\n",
      "60 - -0.83\n",
      "61 - transformer.blocks.9.mlp.fc1.stats\n",
      "61 - 6.02\n",
      "62 - transformer.blocks.9.mlp.fc2.stats\n",
      "62 - -0.62\n",
      "63 - transformer.blocks.10.norm1.stats\n",
      "63 - -0.39\n",
      "64 - transformer.blocks.10.attn.qkv.stats\n",
      "64 - 8.98\n",
      "65 - transformer.blocks.10.attn.proj.stats\n",
      "65 - 1.76\n",
      "66 - transformer.blocks.10.norm2.stats\n",
      "66 - 0.46\n",
      "67 - transformer.blocks.10.mlp.fc1.stats\n",
      "67 - 8.36\n",
      "68 - transformer.blocks.10.mlp.fc2.stats\n",
      "68 - 0.35\n",
      "69 - transformer.blocks.11.norm1.stats\n",
      "69 - 0.15\n",
      "70 - transformer.blocks.11.attn.qkv.stats\n",
      "70 - 9.63\n",
      "71 - transformer.blocks.11.attn.proj.stats\n",
      "71 - 2.55\n",
      "72 - transformer.blocks.11.norm2.stats\n",
      "72 - 1.39\n",
      "73 - transformer.blocks.11.mlp.fc1.stats\n",
      "73 - 6.98\n",
      "74 - transformer.blocks.11.mlp.fc2.stats\n",
      "74 - 4.02\n",
      "75 - transformer.norm.stats\n",
      "75 - 6.09\n",
      "76 - pooler.dense.stats\n",
      "76 - -3.00\n",
      "Total error: 139.56\n"
     ]
    }
   ],
   "source": [
    "total_err = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for idx, key in enumerate(act_compare_dict_dynamic):\n",
    "    err = compute_error(act_compare_dict_dynamic[key]['float'][0][0], act_compare_dict_dynamic[key]['quantized'][0][0])\n",
    "    # print(type(err))\n",
    "    if torch.isinf(err):\n",
    "        inf_count += 1\n",
    "    else:\n",
    "        total_err += err\n",
    "        if err > max_err:\n",
    "            max_err = err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err:.2f}\")\n",
    "\n",
    "print(f\"Total error: {total_err:.2f}\")\n",
    "# print(f\"Total inf: {inf_count}\")\n",
    "# print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-bit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.weight\n",
      "0 - inf\n",
      "1 - transformer.patch_embed.proj.weight\n",
      "1 - inf\n",
      "2 - transformer.blocks.0.norm1.weight\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.attn.qkv._packed_params._packed_params\n",
      "3 - 4.57\n",
      "4 - transformer.blocks.0.attn.proj._packed_params._packed_params\n",
      "4 - 0.87\n",
      "5 - transformer.blocks.0.norm2.weight\n",
      "5 - inf\n",
      "6 - transformer.blocks.0.mlp.fc1._packed_params._packed_params\n",
      "6 - 3.18\n",
      "7 - transformer.blocks.0.mlp.fc2._packed_params._packed_params\n",
      "7 - 0.22\n",
      "8 - transformer.blocks.1.norm1.weight\n",
      "8 - inf\n",
      "9 - transformer.blocks.1.attn.qkv._packed_params._packed_params\n",
      "9 - 7.66\n",
      "10 - transformer.blocks.1.attn.proj._packed_params._packed_params\n",
      "10 - 4.76\n",
      "11 - transformer.blocks.1.norm2.weight\n",
      "11 - inf\n",
      "12 - transformer.blocks.1.mlp.fc1._packed_params._packed_params\n",
      "12 - 3.51\n",
      "13 - transformer.blocks.1.mlp.fc2._packed_params._packed_params\n",
      "13 - 0.10\n",
      "14 - transformer.blocks.2.norm1.weight\n",
      "14 - inf\n",
      "15 - transformer.blocks.2.attn.qkv._packed_params._packed_params\n",
      "15 - 9.37\n",
      "16 - transformer.blocks.2.attn.proj._packed_params._packed_params\n",
      "16 - 11.76\n",
      "17 - transformer.blocks.2.norm2.weight\n",
      "17 - inf\n",
      "18 - transformer.blocks.2.mlp.fc1._packed_params._packed_params\n",
      "18 - 7.98\n",
      "19 - transformer.blocks.2.mlp.fc2._packed_params._packed_params\n",
      "19 - 0.05\n",
      "20 - transformer.blocks.3.norm1.weight\n",
      "20 - inf\n",
      "21 - transformer.blocks.3.attn.qkv._packed_params._packed_params\n",
      "21 - 8.57\n",
      "22 - transformer.blocks.3.attn.proj._packed_params._packed_params\n",
      "22 - 12.35\n",
      "23 - transformer.blocks.3.norm2.weight\n",
      "23 - inf\n",
      "24 - transformer.blocks.3.mlp.fc1._packed_params._packed_params\n",
      "24 - 7.33\n",
      "25 - transformer.blocks.3.mlp.fc2._packed_params._packed_params\n",
      "25 - 6.00\n",
      "26 - transformer.blocks.4.norm1.weight\n",
      "26 - inf\n",
      "27 - transformer.blocks.4.attn.qkv._packed_params._packed_params\n",
      "27 - 10.08\n",
      "28 - transformer.blocks.4.attn.proj._packed_params._packed_params\n",
      "28 - 14.17\n",
      "29 - transformer.blocks.4.norm2.weight\n",
      "29 - inf\n",
      "30 - transformer.blocks.4.mlp.fc1._packed_params._packed_params\n",
      "30 - 6.98\n",
      "31 - transformer.blocks.4.mlp.fc2._packed_params._packed_params\n",
      "31 - 2.84\n",
      "32 - transformer.blocks.5.norm1.weight\n",
      "32 - inf\n",
      "33 - transformer.blocks.5.attn.qkv._packed_params._packed_params\n",
      "33 - 9.31\n",
      "34 - transformer.blocks.5.attn.proj._packed_params._packed_params\n",
      "34 - 13.54\n",
      "35 - transformer.blocks.5.norm2.weight\n",
      "35 - inf\n",
      "36 - transformer.blocks.5.mlp.fc1._packed_params._packed_params\n",
      "36 - 10.93\n",
      "37 - transformer.blocks.5.mlp.fc2._packed_params._packed_params\n",
      "37 - 5.26\n",
      "38 - transformer.blocks.6.norm1.weight\n",
      "38 - inf\n",
      "39 - transformer.blocks.6.attn.qkv._packed_params._packed_params\n",
      "39 - 11.29\n",
      "40 - transformer.blocks.6.attn.proj._packed_params._packed_params\n",
      "40 - 9.31\n",
      "41 - transformer.blocks.6.norm2.weight\n",
      "41 - inf\n",
      "42 - transformer.blocks.6.mlp.fc1._packed_params._packed_params\n",
      "42 - 7.29\n",
      "43 - transformer.blocks.6.mlp.fc2._packed_params._packed_params\n",
      "43 - 0.17\n",
      "44 - transformer.blocks.7.norm1.weight\n",
      "44 - inf\n",
      "45 - transformer.blocks.7.attn.qkv._packed_params._packed_params\n",
      "45 - 9.30\n",
      "46 - transformer.blocks.7.attn.proj._packed_params._packed_params\n",
      "46 - 13.32\n",
      "47 - transformer.blocks.7.norm2.weight\n",
      "47 - inf\n",
      "48 - transformer.blocks.7.mlp.fc1._packed_params._packed_params\n",
      "48 - 0.78\n",
      "49 - transformer.blocks.7.mlp.fc2._packed_params._packed_params\n",
      "49 - 0.09\n",
      "50 - transformer.blocks.8.norm1.weight\n",
      "50 - inf\n",
      "51 - transformer.blocks.8.attn.qkv._packed_params._packed_params\n",
      "51 - 10.64\n",
      "52 - transformer.blocks.8.attn.proj._packed_params._packed_params\n",
      "52 - 11.48\n",
      "53 - transformer.blocks.8.norm2.weight\n",
      "53 - inf\n",
      "54 - transformer.blocks.8.mlp.fc1._packed_params._packed_params\n",
      "54 - 0.12\n",
      "55 - transformer.blocks.8.mlp.fc2._packed_params._packed_params\n",
      "55 - 0.10\n",
      "56 - transformer.blocks.9.norm1.weight\n",
      "56 - inf\n",
      "57 - transformer.blocks.9.attn.qkv._packed_params._packed_params\n",
      "57 - 8.53\n",
      "58 - transformer.blocks.9.attn.proj._packed_params._packed_params\n",
      "58 - 5.93\n",
      "59 - transformer.blocks.9.norm2.weight\n",
      "59 - inf\n",
      "60 - transformer.blocks.9.mlp.fc1._packed_params._packed_params\n",
      "60 - 0.53\n",
      "61 - transformer.blocks.9.mlp.fc2._packed_params._packed_params\n",
      "61 - 0.38\n",
      "62 - transformer.blocks.10.norm1.weight\n",
      "62 - inf\n",
      "63 - transformer.blocks.10.attn.qkv._packed_params._packed_params\n",
      "63 - 6.15\n",
      "64 - transformer.blocks.10.attn.proj._packed_params._packed_params\n",
      "64 - 9.72\n",
      "65 - transformer.blocks.10.norm2.weight\n",
      "65 - inf\n",
      "66 - transformer.blocks.10.mlp.fc1._packed_params._packed_params\n",
      "66 - 8.71\n",
      "67 - transformer.blocks.10.mlp.fc2._packed_params._packed_params\n",
      "67 - 4.98\n",
      "68 - transformer.blocks.11.norm1.weight\n",
      "68 - inf\n",
      "69 - transformer.blocks.11.attn.qkv._packed_params._packed_params\n",
      "69 - 6.48\n",
      "70 - transformer.blocks.11.attn.proj._packed_params._packed_params\n",
      "70 - 2.43\n",
      "71 - transformer.blocks.11.norm2.weight\n",
      "71 - inf\n",
      "72 - transformer.blocks.11.mlp.fc1._packed_params._packed_params\n",
      "72 - 4.49\n",
      "73 - transformer.blocks.11.mlp.fc2._packed_params._packed_params\n",
      "73 - 0.62\n",
      "74 - transformer.norm.weight\n",
      "74 - inf\n",
      "75 - pooler.dense._packed_params._packed_params\n",
      "75 - 11.96\n",
      "76 - nlvr2_classifier.0._packed_params._packed_params\n",
      "76 - 14.34\n",
      "77 - nlvr2_classifier.1.weight\n",
      "77 - inf\n",
      "78 - nlvr2_classifier.3._packed_params._packed_params\n",
      "78 - 16.09\n",
      "Total error: 336.60\n",
      "Total inf: 28\n",
      "Max error: 16.087890625\n"
     ]
    }
   ],
   "source": [
    "# ======== Dynamic quantization comparison ========\n",
    "wt_compare_dict_dynamic = ns.compare_weights(model.state_dict(), model_4.state_dict())\n",
    "\n",
    "# print('keys of wt_compare_dict:')\n",
    "# print(wt_compare_dict_dynamic.keys())\n",
    "\n",
    "# key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "total_error = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for i, key in enumerate(wt_compare_dict_dynamic):\n",
    "    if wt_compare_dict_dynamic[key]['quantized'].is_quantized:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'].dequantize())\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "        \n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "    else:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'])\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "\n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "\n",
    "print(f\"Total error: {total_error:.2f}\")\n",
    "print(f\"Total inf: {inf_count}\")\n",
    "print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_batch = next(iter(infer_dataloader))\n",
    "# calibration_batch = next(iter(calibrarte_dm.val_dataloader()))\n",
    "# full_batch = next(iter(full_dm.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.norm.stats', 'pooler.dense.stats'])\n"
     ]
    }
   ],
   "source": [
    "# act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), full_batch)\n",
    "act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_4), infer_batch)\n",
    "print(act_compare_dict_dynamic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 14.32\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - 14.07\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.norm1.stats\n",
      "3 - -1.89\n",
      "4 - transformer.blocks.0.attn.qkv.stats\n",
      "4 - 3.17\n",
      "5 - transformer.blocks.0.attn.proj.stats\n",
      "5 - -0.62\n",
      "6 - transformer.blocks.0.norm2.stats\n",
      "6 - -1.70\n",
      "7 - transformer.blocks.0.mlp.fc1.stats\n",
      "7 - 2.84\n",
      "8 - transformer.blocks.0.mlp.fc2.stats\n",
      "8 - -0.42\n",
      "9 - transformer.blocks.1.norm1.stats\n",
      "9 - -2.18\n",
      "10 - transformer.blocks.1.attn.qkv.stats\n",
      "10 - 3.19\n",
      "11 - transformer.blocks.1.attn.proj.stats\n",
      "11 - -3.70\n",
      "12 - transformer.blocks.1.norm2.stats\n",
      "12 - -1.32\n",
      "13 - transformer.blocks.1.mlp.fc1.stats\n",
      "13 - 2.90\n",
      "14 - transformer.blocks.1.mlp.fc2.stats\n",
      "14 - -0.18\n",
      "15 - transformer.blocks.2.norm1.stats\n",
      "15 - -2.15\n",
      "16 - transformer.blocks.2.attn.qkv.stats\n",
      "16 - 0.48\n",
      "17 - transformer.blocks.2.attn.proj.stats\n",
      "17 - -1.89\n",
      "18 - transformer.blocks.2.norm2.stats\n",
      "18 - -1.27\n",
      "19 - transformer.blocks.2.mlp.fc1.stats\n",
      "19 - 3.55\n",
      "20 - transformer.blocks.2.mlp.fc2.stats\n",
      "20 - -0.07\n",
      "21 - transformer.blocks.3.norm1.stats\n",
      "21 - -2.28\n",
      "22 - transformer.blocks.3.attn.qkv.stats\n",
      "22 - 0.64\n",
      "23 - transformer.blocks.3.attn.proj.stats\n",
      "23 - -2.12\n",
      "24 - transformer.blocks.3.norm2.stats\n",
      "24 - -1.36\n",
      "25 - transformer.blocks.3.mlp.fc1.stats\n",
      "25 - 3.62\n",
      "26 - transformer.blocks.3.mlp.fc2.stats\n",
      "26 - -2.47\n",
      "27 - transformer.blocks.4.norm1.stats\n",
      "27 - -2.39\n",
      "28 - transformer.blocks.4.attn.qkv.stats\n",
      "28 - 1.03\n",
      "29 - transformer.blocks.4.attn.proj.stats\n",
      "29 - -2.84\n",
      "30 - transformer.blocks.4.norm2.stats\n",
      "30 - -1.66\n",
      "31 - transformer.blocks.4.mlp.fc1.stats\n",
      "31 - 3.35\n",
      "32 - transformer.blocks.4.mlp.fc2.stats\n",
      "32 - -3.62\n",
      "33 - transformer.blocks.5.norm1.stats\n",
      "33 - -2.55\n",
      "34 - transformer.blocks.5.attn.qkv.stats\n",
      "34 - 1.45\n",
      "35 - transformer.blocks.5.attn.proj.stats\n",
      "35 - -2.82\n",
      "36 - transformer.blocks.5.norm2.stats\n",
      "36 - -1.95\n",
      "37 - transformer.blocks.5.mlp.fc1.stats\n",
      "37 - 3.00\n",
      "38 - transformer.blocks.5.mlp.fc2.stats\n",
      "38 - -4.29\n",
      "39 - transformer.blocks.6.norm1.stats\n",
      "39 - -2.63\n",
      "40 - transformer.blocks.6.attn.qkv.stats\n",
      "40 - 2.43\n",
      "41 - transformer.blocks.6.attn.proj.stats\n",
      "41 - -2.55\n",
      "42 - transformer.blocks.6.norm2.stats\n",
      "42 - -2.13\n",
      "43 - transformer.blocks.6.mlp.fc1.stats\n",
      "43 - 3.03\n",
      "44 - transformer.blocks.6.mlp.fc2.stats\n",
      "44 - -0.59\n",
      "45 - transformer.blocks.7.norm1.stats\n",
      "45 - -2.59\n",
      "46 - transformer.blocks.7.attn.qkv.stats\n",
      "46 - 5.74\n",
      "47 - transformer.blocks.7.attn.proj.stats\n",
      "47 - -2.11\n",
      "48 - transformer.blocks.7.norm2.stats\n",
      "48 - -2.20\n",
      "49 - transformer.blocks.7.mlp.fc1.stats\n",
      "49 - 2.01\n",
      "50 - transformer.blocks.7.mlp.fc2.stats\n",
      "50 - 0.53\n",
      "51 - transformer.blocks.8.norm1.stats\n",
      "51 - -2.59\n",
      "52 - transformer.blocks.8.attn.qkv.stats\n",
      "52 - 7.28\n",
      "53 - transformer.blocks.8.attn.proj.stats\n",
      "53 - -2.04\n",
      "54 - transformer.blocks.8.norm2.stats\n",
      "54 - -2.34\n",
      "55 - transformer.blocks.8.mlp.fc1.stats\n",
      "55 - 0.48\n",
      "56 - transformer.blocks.8.mlp.fc2.stats\n",
      "56 - -2.11\n",
      "57 - transformer.blocks.9.norm1.stats\n",
      "57 - -2.61\n",
      "58 - transformer.blocks.9.attn.qkv.stats\n",
      "58 - 7.78\n",
      "59 - transformer.blocks.9.attn.proj.stats\n",
      "59 - -2.57\n",
      "60 - transformer.blocks.9.norm2.stats\n",
      "60 - -2.36\n",
      "61 - transformer.blocks.9.mlp.fc1.stats\n",
      "61 - 2.87\n",
      "62 - transformer.blocks.9.mlp.fc2.stats\n",
      "62 - -1.64\n",
      "63 - transformer.blocks.10.norm1.stats\n",
      "63 - -2.42\n",
      "64 - transformer.blocks.10.attn.qkv.stats\n",
      "64 - 7.05\n",
      "65 - transformer.blocks.10.attn.proj.stats\n",
      "65 - -1.44\n",
      "66 - transformer.blocks.10.norm2.stats\n",
      "66 - -2.54\n",
      "67 - transformer.blocks.10.mlp.fc1.stats\n",
      "67 - 3.15\n",
      "68 - transformer.blocks.10.mlp.fc2.stats\n",
      "68 - -0.11\n",
      "69 - transformer.blocks.11.norm1.stats\n",
      "69 - -2.66\n",
      "70 - transformer.blocks.11.attn.qkv.stats\n",
      "70 - 6.56\n",
      "71 - transformer.blocks.11.attn.proj.stats\n",
      "71 - 3.69\n",
      "72 - transformer.blocks.11.norm2.stats\n",
      "72 - -2.45\n",
      "73 - transformer.blocks.11.mlp.fc1.stats\n",
      "73 - 2.79\n",
      "74 - transformer.blocks.11.mlp.fc2.stats\n",
      "74 - -0.90\n",
      "75 - transformer.norm.stats\n",
      "75 - -0.89\n",
      "76 - pooler.dense.stats\n",
      "76 - -1.28\n",
      "Total error: 17.57\n"
     ]
    }
   ],
   "source": [
    "total_err = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for idx, key in enumerate(act_compare_dict_dynamic):\n",
    "    err = compute_error(act_compare_dict_dynamic[key]['float'][0][0], act_compare_dict_dynamic[key]['quantized'][0][0])\n",
    "    # print(type(err))\n",
    "    if torch.isinf(err):\n",
    "        inf_count += 1\n",
    "    else:\n",
    "        total_err += err\n",
    "        if err > max_err:\n",
    "            max_err = err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err:.2f}\")\n",
    "\n",
    "print(f\"Total error: {total_err:.2f}\")\n",
    "# print(f\"Total inf: {inf_count}\")\n",
    "# print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.weight\n",
      "0 - inf\n",
      "1 - transformer.patch_embed.proj.weight\n",
      "1 - inf\n",
      "2 - transformer.blocks.0.norm1.weight\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.attn.qkv._packed_params._packed_params\n",
      "3 - 0.39\n",
      "4 - transformer.blocks.0.attn.proj._packed_params._packed_params\n",
      "4 - 0.07\n",
      "5 - transformer.blocks.0.norm2.weight\n",
      "5 - inf\n",
      "6 - transformer.blocks.0.mlp.fc1._packed_params._packed_params\n",
      "6 - 0.04\n",
      "7 - transformer.blocks.0.mlp.fc2._packed_params._packed_params\n",
      "7 - 0.03\n",
      "8 - transformer.blocks.1.norm1.weight\n",
      "8 - inf\n",
      "9 - transformer.blocks.1.attn.qkv._packed_params._packed_params\n",
      "9 - 0.32\n",
      "10 - transformer.blocks.1.attn.proj._packed_params._packed_params\n",
      "10 - 0.03\n",
      "11 - transformer.blocks.1.norm2.weight\n",
      "11 - inf\n",
      "12 - transformer.blocks.1.mlp.fc1._packed_params._packed_params\n",
      "12 - 0.04\n",
      "13 - transformer.blocks.1.mlp.fc2._packed_params._packed_params\n",
      "13 - 0.03\n",
      "14 - transformer.blocks.2.norm1.weight\n",
      "14 - inf\n",
      "15 - transformer.blocks.2.attn.qkv._packed_params._packed_params\n",
      "15 - 0.27\n",
      "16 - transformer.blocks.2.attn.proj._packed_params._packed_params\n",
      "16 - 0.47\n",
      "17 - transformer.blocks.2.norm2.weight\n",
      "17 - inf\n",
      "18 - transformer.blocks.2.mlp.fc1._packed_params._packed_params\n",
      "18 - 0.07\n",
      "19 - transformer.blocks.2.mlp.fc2._packed_params._packed_params\n",
      "19 - 0.02\n",
      "20 - transformer.blocks.3.norm1.weight\n",
      "20 - inf\n",
      "21 - transformer.blocks.3.attn.qkv._packed_params._packed_params\n",
      "21 - 0.08\n",
      "22 - transformer.blocks.3.attn.proj._packed_params._packed_params\n",
      "22 - 0.59\n",
      "23 - transformer.blocks.3.norm2.weight\n",
      "23 - inf\n",
      "24 - transformer.blocks.3.mlp.fc1._packed_params._packed_params\n",
      "24 - 0.02\n",
      "25 - transformer.blocks.3.mlp.fc2._packed_params._packed_params\n",
      "25 - 0.01\n",
      "26 - transformer.blocks.4.norm1.weight\n",
      "26 - inf\n",
      "27 - transformer.blocks.4.attn.qkv._packed_params._packed_params\n",
      "27 - 0.19\n",
      "28 - transformer.blocks.4.attn.proj._packed_params._packed_params\n",
      "28 - 1.32\n",
      "29 - transformer.blocks.4.norm2.weight\n",
      "29 - inf\n",
      "30 - transformer.blocks.4.mlp.fc1._packed_params._packed_params\n",
      "30 - 0.01\n",
      "31 - transformer.blocks.4.mlp.fc2._packed_params._packed_params\n",
      "31 - 0.00\n",
      "32 - transformer.blocks.5.norm1.weight\n",
      "32 - inf\n",
      "33 - transformer.blocks.5.attn.qkv._packed_params._packed_params\n",
      "33 - 0.09\n",
      "34 - transformer.blocks.5.attn.proj._packed_params._packed_params\n",
      "34 - 0.99\n",
      "35 - transformer.blocks.5.norm2.weight\n",
      "35 - inf\n",
      "36 - transformer.blocks.5.mlp.fc1._packed_params._packed_params\n",
      "36 - 0.26\n",
      "37 - transformer.blocks.5.mlp.fc2._packed_params._packed_params\n",
      "37 - 0.02\n",
      "38 - transformer.blocks.6.norm1.weight\n",
      "38 - inf\n",
      "39 - transformer.blocks.6.attn.qkv._packed_params._packed_params\n",
      "39 - 0.32\n",
      "40 - transformer.blocks.6.attn.proj._packed_params._packed_params\n",
      "40 - 0.06\n",
      "41 - transformer.blocks.6.norm2.weight\n",
      "41 - inf\n",
      "42 - transformer.blocks.6.mlp.fc1._packed_params._packed_params\n",
      "42 - 0.02\n",
      "43 - transformer.blocks.6.mlp.fc2._packed_params._packed_params\n",
      "43 - 0.11\n",
      "44 - transformer.blocks.7.norm1.weight\n",
      "44 - inf\n",
      "45 - transformer.blocks.7.attn.qkv._packed_params._packed_params\n",
      "45 - 0.06\n",
      "46 - transformer.blocks.7.attn.proj._packed_params._packed_params\n",
      "46 - 0.88\n",
      "47 - transformer.blocks.7.norm2.weight\n",
      "47 - inf\n",
      "48 - transformer.blocks.7.mlp.fc1._packed_params._packed_params\n",
      "48 - 0.05\n",
      "49 - transformer.blocks.7.mlp.fc2._packed_params._packed_params\n",
      "49 - 0.07\n",
      "50 - transformer.blocks.8.norm1.weight\n",
      "50 - inf\n",
      "51 - transformer.blocks.8.attn.qkv._packed_params._packed_params\n",
      "51 - 0.19\n",
      "52 - transformer.blocks.8.attn.proj._packed_params._packed_params\n",
      "52 - 0.31\n",
      "53 - transformer.blocks.8.norm2.weight\n",
      "53 - inf\n",
      "54 - transformer.blocks.8.mlp.fc1._packed_params._packed_params\n",
      "54 - 0.03\n",
      "55 - transformer.blocks.8.mlp.fc2._packed_params._packed_params\n",
      "55 - 0.03\n",
      "56 - transformer.blocks.9.norm1.weight\n",
      "56 - inf\n",
      "57 - transformer.blocks.9.attn.qkv._packed_params._packed_params\n",
      "57 - 0.04\n",
      "58 - transformer.blocks.9.attn.proj._packed_params._packed_params\n",
      "58 - 0.02\n",
      "59 - transformer.blocks.9.norm2.weight\n",
      "59 - inf\n",
      "60 - transformer.blocks.9.mlp.fc1._packed_params._packed_params\n",
      "60 - 0.00\n",
      "61 - transformer.blocks.9.mlp.fc2._packed_params._packed_params\n",
      "61 - 0.01\n",
      "62 - transformer.blocks.10.norm1.weight\n",
      "62 - inf\n",
      "63 - transformer.blocks.10.attn.qkv._packed_params._packed_params\n",
      "63 - 0.02\n",
      "64 - transformer.blocks.10.attn.proj._packed_params._packed_params\n",
      "64 - 0.13\n",
      "65 - transformer.blocks.10.norm2.weight\n",
      "65 - inf\n",
      "66 - transformer.blocks.10.mlp.fc1._packed_params._packed_params\n",
      "66 - 0.05\n",
      "67 - transformer.blocks.10.mlp.fc2._packed_params._packed_params\n",
      "67 - 0.00\n",
      "68 - transformer.blocks.11.norm1.weight\n",
      "68 - inf\n",
      "69 - transformer.blocks.11.attn.qkv._packed_params._packed_params\n",
      "69 - 0.04\n",
      "70 - transformer.blocks.11.attn.proj._packed_params._packed_params\n",
      "70 - 0.23\n",
      "71 - transformer.blocks.11.norm2.weight\n",
      "71 - inf\n",
      "72 - transformer.blocks.11.mlp.fc1._packed_params._packed_params\n",
      "72 - 0.01\n",
      "73 - transformer.blocks.11.mlp.fc2._packed_params._packed_params\n",
      "73 - 0.07\n",
      "74 - transformer.norm.weight\n",
      "74 - inf\n",
      "75 - pooler.dense._packed_params._packed_params\n",
      "75 - 1.10\n",
      "76 - nlvr2_classifier.0._packed_params._packed_params\n",
      "76 - 1.35\n",
      "77 - nlvr2_classifier.1.weight\n",
      "77 - inf\n",
      "78 - nlvr2_classifier.3._packed_params._packed_params\n",
      "78 - 2.87\n",
      "Total error: 13.46\n",
      "Total inf: 28\n",
      "Max error: 2.8716225624084473\n"
     ]
    }
   ],
   "source": [
    "# ======== Dynamic quantization comparison ========\n",
    "wt_compare_dict_dynamic = ns.compare_weights(model.state_dict(), model_2.state_dict())\n",
    "\n",
    "# print('keys of wt_compare_dict:')\n",
    "# print(wt_compare_dict_dynamic.keys())\n",
    "\n",
    "# key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "total_error = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for i, key in enumerate(wt_compare_dict_dynamic):\n",
    "    if wt_compare_dict_dynamic[key]['quantized'].is_quantized:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'].dequantize())\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "        \n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "    else:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'])\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "\n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "\n",
    "print(f\"Total error: {total_error:.2f}\")\n",
    "print(f\"Total inf: {inf_count}\")\n",
    "print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.norm.stats', 'pooler.dense.stats'])\n"
     ]
    }
   ],
   "source": [
    "# act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), full_batch)\n",
    "act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_2), infer_batch)\n",
    "print(act_compare_dict_dynamic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 3.22\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - -0.85\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.norm1.stats\n",
      "3 - -2.04\n",
      "4 - transformer.blocks.0.attn.qkv.stats\n",
      "4 - 4.84\n",
      "5 - transformer.blocks.0.attn.proj.stats\n",
      "5 - 0.19\n",
      "6 - transformer.blocks.0.norm2.stats\n",
      "6 - -1.89\n",
      "7 - transformer.blocks.0.mlp.fc1.stats\n",
      "7 - 0.47\n",
      "8 - transformer.blocks.0.mlp.fc2.stats\n",
      "8 - 0.06\n",
      "9 - transformer.blocks.1.norm1.stats\n",
      "9 - -2.27\n",
      "10 - transformer.blocks.1.attn.qkv.stats\n",
      "10 - 4.57\n",
      "11 - transformer.blocks.1.attn.proj.stats\n",
      "11 - 0.09\n",
      "12 - transformer.blocks.1.norm2.stats\n",
      "12 - -1.63\n",
      "13 - transformer.blocks.1.mlp.fc1.stats\n",
      "13 - 0.43\n",
      "14 - transformer.blocks.1.mlp.fc2.stats\n",
      "14 - 0.00\n",
      "15 - transformer.blocks.2.norm1.stats\n",
      "15 - -2.29\n",
      "16 - transformer.blocks.2.attn.qkv.stats\n",
      "16 - 1.54\n",
      "17 - transformer.blocks.2.attn.proj.stats\n",
      "17 - -0.06\n",
      "18 - transformer.blocks.2.norm2.stats\n",
      "18 - -1.64\n",
      "19 - transformer.blocks.2.mlp.fc1.stats\n",
      "19 - 0.72\n",
      "20 - transformer.blocks.2.mlp.fc2.stats\n",
      "20 - 0.03\n",
      "21 - transformer.blocks.3.norm1.stats\n",
      "21 - -2.42\n",
      "22 - transformer.blocks.3.attn.qkv.stats\n",
      "22 - 2.12\n",
      "23 - transformer.blocks.3.attn.proj.stats\n",
      "23 - -0.07\n",
      "24 - transformer.blocks.3.norm2.stats\n",
      "24 - -1.65\n",
      "25 - transformer.blocks.3.mlp.fc1.stats\n",
      "25 - 0.55\n",
      "26 - transformer.blocks.3.mlp.fc2.stats\n",
      "26 - -0.06\n",
      "27 - transformer.blocks.4.norm1.stats\n",
      "27 - -2.51\n",
      "28 - transformer.blocks.4.attn.qkv.stats\n",
      "28 - 2.25\n",
      "29 - transformer.blocks.4.attn.proj.stats\n",
      "29 - -0.42\n",
      "30 - transformer.blocks.4.norm2.stats\n",
      "30 - -1.86\n",
      "31 - transformer.blocks.4.mlp.fc1.stats\n",
      "31 - 0.45\n",
      "32 - transformer.blocks.4.mlp.fc2.stats\n",
      "32 - -0.06\n",
      "33 - transformer.blocks.5.norm1.stats\n",
      "33 - -2.58\n",
      "34 - transformer.blocks.5.attn.qkv.stats\n",
      "34 - 3.01\n",
      "35 - transformer.blocks.5.attn.proj.stats\n",
      "35 - -0.18\n",
      "36 - transformer.blocks.5.norm2.stats\n",
      "36 - -1.97\n",
      "37 - transformer.blocks.5.mlp.fc1.stats\n",
      "37 - 1.75\n",
      "38 - transformer.blocks.5.mlp.fc2.stats\n",
      "38 - -0.05\n",
      "39 - transformer.blocks.6.norm1.stats\n",
      "39 - -2.68\n",
      "40 - transformer.blocks.6.attn.qkv.stats\n",
      "40 - 3.46\n",
      "41 - transformer.blocks.6.attn.proj.stats\n",
      "41 - -0.01\n",
      "42 - transformer.blocks.6.norm2.stats\n",
      "42 - -2.09\n",
      "43 - transformer.blocks.6.mlp.fc1.stats\n",
      "43 - 0.51\n",
      "44 - transformer.blocks.6.mlp.fc2.stats\n",
      "44 - -0.02\n",
      "45 - transformer.blocks.7.norm1.stats\n",
      "45 - -2.72\n",
      "46 - transformer.blocks.7.attn.qkv.stats\n",
      "46 - 7.11\n",
      "47 - transformer.blocks.7.attn.proj.stats\n",
      "47 - -0.26\n",
      "48 - transformer.blocks.7.norm2.stats\n",
      "48 - -2.21\n",
      "49 - transformer.blocks.7.mlp.fc1.stats\n",
      "49 - 0.25\n",
      "50 - transformer.blocks.7.mlp.fc2.stats\n",
      "50 - -0.34\n",
      "51 - transformer.blocks.8.norm1.stats\n",
      "51 - -1.79\n",
      "52 - transformer.blocks.8.attn.qkv.stats\n",
      "52 - 8.48\n",
      "53 - transformer.blocks.8.attn.proj.stats\n",
      "53 - -0.07\n",
      "54 - transformer.blocks.8.norm2.stats\n",
      "54 - -1.66\n",
      "55 - transformer.blocks.8.mlp.fc1.stats\n",
      "55 - -0.37\n",
      "56 - transformer.blocks.8.mlp.fc2.stats\n",
      "56 - -12.75\n",
      "57 - transformer.blocks.9.norm1.stats\n",
      "57 - -0.56\n",
      "58 - transformer.blocks.9.attn.qkv.stats\n",
      "58 - 9.11\n",
      "59 - transformer.blocks.9.attn.proj.stats\n",
      "59 - 0.21\n",
      "60 - transformer.blocks.9.norm2.stats\n",
      "60 - -0.85\n",
      "61 - transformer.blocks.9.mlp.fc1.stats\n",
      "61 - -0.09\n",
      "62 - transformer.blocks.9.mlp.fc2.stats\n",
      "62 - -12.50\n",
      "63 - transformer.blocks.10.norm1.stats\n",
      "63 - -0.30\n",
      "64 - transformer.blocks.10.attn.qkv.stats\n",
      "64 - 6.60\n",
      "65 - transformer.blocks.10.attn.proj.stats\n",
      "65 - -0.01\n",
      "66 - transformer.blocks.10.norm2.stats\n",
      "66 - -0.34\n",
      "67 - transformer.blocks.10.mlp.fc1.stats\n",
      "67 - 0.34\n",
      "68 - transformer.blocks.10.mlp.fc2.stats\n",
      "68 - 0.26\n",
      "69 - transformer.blocks.11.norm1.stats\n",
      "69 - -0.49\n",
      "70 - transformer.blocks.11.attn.qkv.stats\n",
      "70 - 6.93\n",
      "71 - transformer.blocks.11.attn.proj.stats\n",
      "71 - -2.09\n",
      "72 - transformer.blocks.11.norm2.stats\n",
      "72 - -1.66\n",
      "73 - transformer.blocks.11.mlp.fc1.stats\n",
      "73 - 0.11\n",
      "74 - transformer.blocks.11.mlp.fc2.stats\n",
      "74 - 0.05\n",
      "75 - transformer.norm.stats\n",
      "75 - -0.41\n",
      "76 - pooler.dense.stats\n",
      "76 - -0.39\n",
      "Total error: -3.45\n"
     ]
    }
   ],
   "source": [
    "total_err = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for idx, key in enumerate(act_compare_dict_dynamic):\n",
    "    err = compute_error(act_compare_dict_dynamic[key]['float'][0][0], act_compare_dict_dynamic[key]['quantized'][0][0])\n",
    "    # print(type(err))\n",
    "    if torch.isinf(err):\n",
    "        inf_count += 1\n",
    "    else:\n",
    "        total_err += err\n",
    "        if err > max_err:\n",
    "            max_err = err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err:.2f}\")\n",
    "\n",
    "print(f\"Total error: {total_err:.2f}\")\n",
    "# print(f\"Total inf: {inf_count}\")\n",
    "# print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.weight\n",
      "0 - inf\n",
      "1 - transformer.patch_embed.proj.weight\n",
      "1 - inf\n",
      "2 - transformer.blocks.0.norm1.weight\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.attn.qkv._packed_params._packed_params\n",
      "3 - 0.00\n",
      "4 - transformer.blocks.0.attn.proj._packed_params._packed_params\n",
      "4 - 0.00\n",
      "5 - transformer.blocks.0.norm2.weight\n",
      "5 - inf\n",
      "6 - transformer.blocks.0.mlp.fc1._packed_params._packed_params\n",
      "6 - 0.00\n",
      "7 - transformer.blocks.0.mlp.fc2._packed_params._packed_params\n",
      "7 - 0.00\n",
      "8 - transformer.blocks.1.norm1.weight\n",
      "8 - inf\n",
      "9 - transformer.blocks.1.attn.qkv._packed_params._packed_params\n",
      "9 - 0.00\n",
      "10 - transformer.blocks.1.attn.proj._packed_params._packed_params\n",
      "10 - 0.00\n",
      "11 - transformer.blocks.1.norm2.weight\n",
      "11 - inf\n",
      "12 - transformer.blocks.1.mlp.fc1._packed_params._packed_params\n",
      "12 - 0.00\n",
      "13 - transformer.blocks.1.mlp.fc2._packed_params._packed_params\n",
      "13 - 0.00\n",
      "14 - transformer.blocks.2.norm1.weight\n",
      "14 - inf\n",
      "15 - transformer.blocks.2.attn.qkv._packed_params._packed_params\n",
      "15 - 0.00\n",
      "16 - transformer.blocks.2.attn.proj._packed_params._packed_params\n",
      "16 - 0.00\n",
      "17 - transformer.blocks.2.norm2.weight\n",
      "17 - inf\n",
      "18 - transformer.blocks.2.mlp.fc1._packed_params._packed_params\n",
      "18 - 0.00\n",
      "19 - transformer.blocks.2.mlp.fc2._packed_params._packed_params\n",
      "19 - 0.00\n",
      "20 - transformer.blocks.3.norm1.weight\n",
      "20 - inf\n",
      "21 - transformer.blocks.3.attn.qkv._packed_params._packed_params\n",
      "21 - 0.00\n",
      "22 - transformer.blocks.3.attn.proj._packed_params._packed_params\n",
      "22 - 0.00\n",
      "23 - transformer.blocks.3.norm2.weight\n",
      "23 - inf\n",
      "24 - transformer.blocks.3.mlp.fc1._packed_params._packed_params\n",
      "24 - 0.00\n",
      "25 - transformer.blocks.3.mlp.fc2._packed_params._packed_params\n",
      "25 - 0.00\n",
      "26 - transformer.blocks.4.norm1.weight\n",
      "26 - inf\n",
      "27 - transformer.blocks.4.attn.qkv._packed_params._packed_params\n",
      "27 - 0.00\n",
      "28 - transformer.blocks.4.attn.proj._packed_params._packed_params\n",
      "28 - 0.00\n",
      "29 - transformer.blocks.4.norm2.weight\n",
      "29 - inf\n",
      "30 - transformer.blocks.4.mlp.fc1._packed_params._packed_params\n",
      "30 - 0.00\n",
      "31 - transformer.blocks.4.mlp.fc2._packed_params._packed_params\n",
      "31 - 0.00\n",
      "32 - transformer.blocks.5.norm1.weight\n",
      "32 - inf\n",
      "33 - transformer.blocks.5.attn.qkv._packed_params._packed_params\n",
      "33 - 0.00\n",
      "34 - transformer.blocks.5.attn.proj._packed_params._packed_params\n",
      "34 - 0.00\n",
      "35 - transformer.blocks.5.norm2.weight\n",
      "35 - inf\n",
      "36 - transformer.blocks.5.mlp.fc1._packed_params._packed_params\n",
      "36 - 0.00\n",
      "37 - transformer.blocks.5.mlp.fc2._packed_params._packed_params\n",
      "37 - 0.00\n",
      "38 - transformer.blocks.6.norm1.weight\n",
      "38 - inf\n",
      "39 - transformer.blocks.6.attn.qkv._packed_params._packed_params\n",
      "39 - 0.00\n",
      "40 - transformer.blocks.6.attn.proj._packed_params._packed_params\n",
      "40 - 0.00\n",
      "41 - transformer.blocks.6.norm2.weight\n",
      "41 - inf\n",
      "42 - transformer.blocks.6.mlp.fc1._packed_params._packed_params\n",
      "42 - 0.00\n",
      "43 - transformer.blocks.6.mlp.fc2._packed_params._packed_params\n",
      "43 - 0.00\n",
      "44 - transformer.blocks.7.norm1.weight\n",
      "44 - inf\n",
      "45 - transformer.blocks.7.attn.qkv._packed_params._packed_params\n",
      "45 - 0.00\n",
      "46 - transformer.blocks.7.attn.proj._packed_params._packed_params\n",
      "46 - 0.00\n",
      "47 - transformer.blocks.7.norm2.weight\n",
      "47 - inf\n",
      "48 - transformer.blocks.7.mlp.fc1._packed_params._packed_params\n",
      "48 - 0.00\n",
      "49 - transformer.blocks.7.mlp.fc2._packed_params._packed_params\n",
      "49 - 0.00\n",
      "50 - transformer.blocks.8.norm1.weight\n",
      "50 - inf\n",
      "51 - transformer.blocks.8.attn.qkv._packed_params._packed_params\n",
      "51 - 0.00\n",
      "52 - transformer.blocks.8.attn.proj._packed_params._packed_params\n",
      "52 - 0.00\n",
      "53 - transformer.blocks.8.norm2.weight\n",
      "53 - inf\n",
      "54 - transformer.blocks.8.mlp.fc1._packed_params._packed_params\n",
      "54 - 0.00\n",
      "55 - transformer.blocks.8.mlp.fc2._packed_params._packed_params\n",
      "55 - 0.00\n",
      "56 - transformer.blocks.9.norm1.weight\n",
      "56 - inf\n",
      "57 - transformer.blocks.9.attn.qkv._packed_params._packed_params\n",
      "57 - 0.00\n",
      "58 - transformer.blocks.9.attn.proj._packed_params._packed_params\n",
      "58 - 0.00\n",
      "59 - transformer.blocks.9.norm2.weight\n",
      "59 - inf\n",
      "60 - transformer.blocks.9.mlp.fc1._packed_params._packed_params\n",
      "60 - 0.00\n",
      "61 - transformer.blocks.9.mlp.fc2._packed_params._packed_params\n",
      "61 - 0.00\n",
      "62 - transformer.blocks.10.norm1.weight\n",
      "62 - inf\n",
      "63 - transformer.blocks.10.attn.qkv._packed_params._packed_params\n",
      "63 - 0.00\n",
      "64 - transformer.blocks.10.attn.proj._packed_params._packed_params\n",
      "64 - 0.00\n",
      "65 - transformer.blocks.10.norm2.weight\n",
      "65 - inf\n",
      "66 - transformer.blocks.10.mlp.fc1._packed_params._packed_params\n",
      "66 - 0.00\n",
      "67 - transformer.blocks.10.mlp.fc2._packed_params._packed_params\n",
      "67 - 0.00\n",
      "68 - transformer.blocks.11.norm1.weight\n",
      "68 - inf\n",
      "69 - transformer.blocks.11.attn.qkv._packed_params._packed_params\n",
      "69 - 0.00\n",
      "70 - transformer.blocks.11.attn.proj._packed_params._packed_params\n",
      "70 - 0.00\n",
      "71 - transformer.blocks.11.norm2.weight\n",
      "71 - inf\n",
      "72 - transformer.blocks.11.mlp.fc1._packed_params._packed_params\n",
      "72 - 0.00\n",
      "73 - transformer.blocks.11.mlp.fc2._packed_params._packed_params\n",
      "73 - 0.00\n",
      "74 - transformer.norm.weight\n",
      "74 - inf\n",
      "75 - pooler.dense._packed_params._packed_params\n",
      "75 - 0.00\n",
      "76 - nlvr2_classifier.0._packed_params._packed_params\n",
      "76 - 0.00\n",
      "77 - nlvr2_classifier.1.weight\n",
      "77 - inf\n",
      "78 - nlvr2_classifier.3._packed_params._packed_params\n",
      "78 - 0.00\n",
      "Total error: 0.00\n",
      "Total inf: 28\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "# ======== Dynamic quantization comparison ========\n",
    "wt_compare_dict_dynamic = ns.compare_weights(model.state_dict(), model_1.state_dict())\n",
    "\n",
    "# print('keys of wt_compare_dict:')\n",
    "# print(wt_compare_dict_dynamic.keys())\n",
    "\n",
    "# key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "total_error = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for i, key in enumerate(wt_compare_dict_dynamic):\n",
    "    if wt_compare_dict_dynamic[key]['quantized'].is_quantized:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'].dequantize())\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "        \n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "    else:\n",
    "        err = compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'])\n",
    "        \n",
    "        print(f\"{i} - {key}\")\n",
    "        print(f\"{i} - {err:.2f}\")\n",
    "\n",
    "        if not torch.isinf(err):\n",
    "            total_error += err\n",
    "            if err > max_err:\n",
    "                max_err = err\n",
    "        else:\n",
    "            inf_count += 1\n",
    "\n",
    "print(f\"Total error: {total_error:.2f}\")\n",
    "print(f\"Total inf: {inf_count}\")\n",
    "print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.norm.stats', 'pooler.dense.stats'])\n"
     ]
    }
   ],
   "source": [
    "# act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), full_batch)\n",
    "act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_1), infer_batch)\n",
    "print(act_compare_dict_dynamic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 2.06\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - -12.40\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - inf\n",
      "3 - transformer.blocks.0.norm1.stats\n",
      "3 - -2.05\n",
      "4 - transformer.blocks.0.attn.qkv.stats\n",
      "4 - 5.05\n",
      "5 - transformer.blocks.0.attn.proj.stats\n",
      "5 - 0.34\n",
      "6 - transformer.blocks.0.norm2.stats\n",
      "6 - -1.95\n",
      "7 - transformer.blocks.0.mlp.fc1.stats\n",
      "7 - 0.40\n",
      "8 - transformer.blocks.0.mlp.fc2.stats\n",
      "8 - 0.03\n",
      "9 - transformer.blocks.1.norm1.stats\n",
      "9 - -2.34\n",
      "10 - transformer.blocks.1.attn.qkv.stats\n",
      "10 - 4.93\n",
      "11 - transformer.blocks.1.attn.proj.stats\n",
      "11 - 0.09\n",
      "12 - transformer.blocks.1.norm2.stats\n",
      "12 - -1.64\n",
      "13 - transformer.blocks.1.mlp.fc1.stats\n",
      "13 - 0.30\n",
      "14 - transformer.blocks.1.mlp.fc2.stats\n",
      "14 - 0.00\n",
      "15 - transformer.blocks.2.norm1.stats\n",
      "15 - -2.38\n",
      "16 - transformer.blocks.2.attn.qkv.stats\n",
      "16 - 1.82\n",
      "17 - transformer.blocks.2.attn.proj.stats\n",
      "17 - 0.04\n",
      "18 - transformer.blocks.2.norm2.stats\n",
      "18 - -1.67\n",
      "19 - transformer.blocks.2.mlp.fc1.stats\n",
      "19 - 0.29\n",
      "20 - transformer.blocks.2.mlp.fc2.stats\n",
      "20 - -0.01\n",
      "21 - transformer.blocks.3.norm1.stats\n",
      "21 - -2.52\n",
      "22 - transformer.blocks.3.attn.qkv.stats\n",
      "22 - 2.19\n",
      "23 - transformer.blocks.3.attn.proj.stats\n",
      "23 - 0.03\n",
      "24 - transformer.blocks.3.norm2.stats\n",
      "24 - -1.71\n",
      "25 - transformer.blocks.3.mlp.fc1.stats\n",
      "25 - 0.28\n",
      "26 - transformer.blocks.3.mlp.fc2.stats\n",
      "26 - -0.05\n",
      "27 - transformer.blocks.4.norm1.stats\n",
      "27 - -2.60\n",
      "28 - transformer.blocks.4.attn.qkv.stats\n",
      "28 - 2.58\n",
      "29 - transformer.blocks.4.attn.proj.stats\n",
      "29 - 0.02\n",
      "30 - transformer.blocks.4.norm2.stats\n",
      "30 - -1.90\n",
      "31 - transformer.blocks.4.mlp.fc1.stats\n",
      "31 - 0.29\n",
      "32 - transformer.blocks.4.mlp.fc2.stats\n",
      "32 - -0.06\n",
      "33 - transformer.blocks.5.norm1.stats\n",
      "33 - -2.67\n",
      "34 - transformer.blocks.5.attn.qkv.stats\n",
      "34 - 3.19\n",
      "35 - transformer.blocks.5.attn.proj.stats\n",
      "35 - 0.03\n",
      "36 - transformer.blocks.5.norm2.stats\n",
      "36 - -2.01\n",
      "37 - transformer.blocks.5.mlp.fc1.stats\n",
      "37 - 0.26\n",
      "38 - transformer.blocks.5.mlp.fc2.stats\n",
      "38 - -0.02\n",
      "39 - transformer.blocks.6.norm1.stats\n",
      "39 - -2.71\n",
      "40 - transformer.blocks.6.attn.qkv.stats\n",
      "40 - 4.13\n",
      "41 - transformer.blocks.6.attn.proj.stats\n",
      "41 - 0.02\n",
      "42 - transformer.blocks.6.norm2.stats\n",
      "42 - -2.14\n",
      "43 - transformer.blocks.6.mlp.fc1.stats\n",
      "43 - 0.23\n",
      "44 - transformer.blocks.6.mlp.fc2.stats\n",
      "44 - -0.00\n",
      "45 - transformer.blocks.7.norm1.stats\n",
      "45 - -2.71\n",
      "46 - transformer.blocks.7.attn.qkv.stats\n",
      "46 - 7.23\n",
      "47 - transformer.blocks.7.attn.proj.stats\n",
      "47 - 0.01\n",
      "48 - transformer.blocks.7.norm2.stats\n",
      "48 - -2.18\n",
      "49 - transformer.blocks.7.mlp.fc1.stats\n",
      "49 - 0.18\n",
      "50 - transformer.blocks.7.mlp.fc2.stats\n",
      "50 - -0.00\n",
      "51 - transformer.blocks.8.norm1.stats\n",
      "51 - -2.67\n",
      "52 - transformer.blocks.8.attn.qkv.stats\n",
      "52 - 8.87\n",
      "53 - transformer.blocks.8.attn.proj.stats\n",
      "53 - 0.00\n",
      "54 - transformer.blocks.8.norm2.stats\n",
      "54 - -2.26\n",
      "55 - transformer.blocks.8.mlp.fc1.stats\n",
      "55 - 0.15\n",
      "56 - transformer.blocks.8.mlp.fc2.stats\n",
      "56 - 0.00\n",
      "57 - transformer.blocks.9.norm1.stats\n",
      "57 - -2.56\n",
      "58 - transformer.blocks.9.attn.qkv.stats\n",
      "58 - 9.63\n",
      "59 - transformer.blocks.9.attn.proj.stats\n",
      "59 - 0.15\n",
      "60 - transformer.blocks.9.norm2.stats\n",
      "60 - -2.12\n",
      "61 - transformer.blocks.9.mlp.fc1.stats\n",
      "61 - 0.09\n",
      "62 - transformer.blocks.9.mlp.fc2.stats\n",
      "62 - 0.03\n",
      "63 - transformer.blocks.10.norm1.stats\n",
      "63 - -2.13\n",
      "64 - transformer.blocks.10.attn.qkv.stats\n",
      "64 - 6.19\n",
      "65 - transformer.blocks.10.attn.proj.stats\n",
      "65 - -0.01\n",
      "66 - transformer.blocks.10.norm2.stats\n",
      "66 - -1.91\n",
      "67 - transformer.blocks.10.mlp.fc1.stats\n",
      "67 - 0.04\n",
      "68 - transformer.blocks.10.mlp.fc2.stats\n",
      "68 - 0.03\n",
      "69 - transformer.blocks.11.norm1.stats\n",
      "69 - -2.11\n",
      "70 - transformer.blocks.11.attn.qkv.stats\n",
      "70 - 7.11\n",
      "71 - transformer.blocks.11.attn.proj.stats\n",
      "71 - 0.04\n",
      "72 - transformer.blocks.11.norm2.stats\n",
      "72 - -4.14\n",
      "73 - transformer.blocks.11.mlp.fc1.stats\n",
      "73 - 0.12\n",
      "74 - transformer.blocks.11.mlp.fc2.stats\n",
      "74 - -0.02\n",
      "75 - transformer.norm.stats\n",
      "75 - 0.39\n",
      "76 - pooler.dense.stats\n",
      "76 - 0.10\n",
      "Total error: 1.38\n"
     ]
    }
   ],
   "source": [
    "total_err = 0\n",
    "inf_count = 0\n",
    "max_err = 0\n",
    "for idx, key in enumerate(act_compare_dict_dynamic):\n",
    "    err = compute_error(act_compare_dict_dynamic[key]['float'][0][0], act_compare_dict_dynamic[key]['quantized'][0][0])\n",
    "    # print(type(err))\n",
    "    if torch.isinf(err):\n",
    "        inf_count += 1\n",
    "    else:\n",
    "        total_err += err\n",
    "        if err > max_err:\n",
    "            max_err = err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err:.2f}\")\n",
    "\n",
    "print(f\"Total error: {total_err:.2f}\")\n",
    "# print(f\"Total inf: {inf_count}\")\n",
    "# print(f\"Max error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
