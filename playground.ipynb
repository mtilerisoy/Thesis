{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground Notebook For Quantizing VLP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Distributed Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.distributed as dist\n",
    "import copy\n",
    "\n",
    "# Limit the number of CPUs\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Set this to the number of CPUs you want to use\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"  # Set this to the number of CPUs you want to use\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "# Initialize the process group\n",
    "dist.init_process_group(backend='gloo', init_method='env://', world_size=1, rank=0)\n",
    "\n",
    "# Verify initialization\n",
    "print(f\"Initialized: {dist.is_initialized()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"promote has been superseded by promote_options='default'\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Importing from timm.models.helpers is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Importing from timm.models.layers is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Importing from timm.models.registry is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_small_patch16_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch16_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch32_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch16_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch32_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch16_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch32_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch16_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch32_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch16_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_patch32_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch16_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_large_patch32_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_huge_patch14_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet50_224_in21k in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet50_384 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_small_resnet26d_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet26d_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Overwriting vit_base_resnet50d_224 in registry\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"You are using `torch.load` with `weights_only=False`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    \"\"\"\n",
    "    Function to print the size of the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to get the size\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "def get_accuracy(pl_module, logits, target, device=\"cpu\"):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        logits, target = (\n",
    "            logits.detach().to(device),\n",
    "            target.detach().to(device),\n",
    "        )\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        preds = preds[target != -100]\n",
    "        target = target[target != -100]\n",
    "        if target.numel() == 0:\n",
    "            return 1\n",
    "\n",
    "        assert preds.shape == target.shape\n",
    "\n",
    "        correct += torch.sum(preds == target)\n",
    "        total += target.numel()\n",
    "\n",
    "        return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Configuration to Initialize the Datamodule and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
      "  warnings.warn(\n",
      "WARNING:root:Found CUDA without GPU_NUM_DEVICES. Defaulting to PJRT_DEVICE=CUDA with GPU_NUM_DEVICES=2\n",
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "# Define the configuration for the experiments\n",
    "vilt_config_nlvr2 = {'exp_name': 'test_ood_nlvr2', 'seed': 0, 'datasets': ['ood_nlvr2'], 'loss_names': {'itm': 0, 'mlm': 0, 'mpp': 0, 'vqa': 0, 'nlvr2': 1, 'irtr': 0}, 'batch_size': 128, 'accelerator': 'gpu', 'train_transform_keys': ['pixelbert_randaug'], 'val_transform_keys': ['pixelbert'], 'image_size': 384, 'max_image_len': -1, 'patch_size': 32, 'draw_false_image': 0, 'image_only': False, 'vqav2_label_size': 3129, 'max_text_len': 40, 'tokenizer': 'bert-base-uncased', 'vocab_size': 30522, 'whole_word_masking': False, 'mlm_prob': 0.15, 'draw_false_text': 0, 'vit': 'vit_base_patch32_384', 'hidden_size': 768, 'num_heads': 12, 'num_layers': 12, 'mlp_ratio': 4, 'drop_rate': 0.1, 'optim_type': 'adamw', 'learning_rate': 0.0001, 'weight_decay': 0.01, 'decay_power': 1, 'max_epoch': 10, 'max_steps': 1, 'warmup_steps': 0.1, 'end_lr': 0, 'lr_mult': 1, 'get_recall_metric': False, 'resume_from': None, 'fast_dev_run': False, 'val_check_interval': 1.0, 'test_only': True, 'data_root': '/data-4/users/mileriso/datasets/OOD/arrows', 'log_dir': 'result', 'per_gpu_batchsize': 64, 'num_gpus': 1, 'num_nodes': 1, 'load_path': '/data-4/users/mileriso/models/vilt_nlvr2.ckpt', 'num_workers': 8, 'precision': 32}\n",
    "vilt_config_vqav2 = {'exp_name': 'test_ood_vqa', 'seed': 0, 'datasets': ['ood_vqa'], 'loss_names': {'itm': 0, 'mlm': 0, 'mpp': 0, 'vqa': 1, 'nlvr2': 0, 'irtr': 0}, 'batch_size': 256, 'accelerator': 'gpu', 'train_transform_keys': ['pixelbert_randaug'], 'val_transform_keys': ['pixelbert'], 'image_size': 384, 'max_image_len': -1, 'patch_size': 32, 'draw_false_image': 0, 'image_only': False, 'vqav2_label_size': 3129, 'max_text_len': 40, 'tokenizer': 'bert-base-uncased', 'vocab_size': 30522, 'whole_word_masking': False, 'mlm_prob': 0.15, 'draw_false_text': 0, 'vit': 'vit_base_patch32_384', 'hidden_size': 768, 'num_heads': 12, 'num_layers': 12, 'mlp_ratio': 4, 'drop_rate': 0.1, 'optim_type': 'adamw', 'learning_rate': 0.0001, 'weight_decay': 0.01, 'decay_power': 1, 'max_epoch': 10, 'max_steps': 1, 'warmup_steps': 0.1, 'end_lr': 0, 'lr_mult': 10, 'get_recall_metric': False, 'resume_from': None, 'fast_dev_run': False, 'val_check_interval': 0.1, 'test_only': True, 'data_root': '/data-4/users/mileriso/datasets/OOD/arrows', 'log_dir': 'result', 'per_gpu_batchsize': 64, 'num_gpus': 1, 'num_nodes': 1, 'load_path': '/data-4/users/mileriso/models/vilt_vqa.ckpt', 'num_workers': 8, 'precision': 32}\n",
    "\n",
    "meter_config_nlvr2 = {'exp_name': 'test_ood_nlvr2', 'seed': 0, 'datasets': ['ood_nlvr2'], 'loss_names': {'itm': 0, 'mlm': 0, 'mpp': 0, 'vqa': 0, 'vcr': 0, 'vcr_qar': 0, 'nlvr2': 1, 'irtr': 0, 'contras': 0, 'snli': 0}, 'batch_size': 256, 'accelerator': 'gpu', 'train_transform_keys': ['clip'], 'val_transform_keys': ['clip'], 'image_size': 288, 'patch_size': 16, 'draw_false_image': 0, 'image_only': False, 'resolution_before': 224, 'vqav2_label_size': 3129, 'max_text_len': 50, 'tokenizer': 'roberta-base', 'vocab_size': 50265, 'whole_word_masking': False, 'mlm_prob': 0.15, 'draw_false_text': 0, 'num_top_layer': 6, 'input_image_embed_size': 768, 'input_text_embed_size': 768, 'vit': 'ViT-B/16', 'hidden_size': 768, 'num_heads': 12, 'num_layers': 6, 'mlp_ratio': 4, 'drop_rate': 0.1, 'optim_type': 'adamw', 'learning_rate': 1e-05, 'weight_decay': 0.01, 'decay_power': 1, 'max_epoch': 10, 'max_steps': 1, 'warmup_steps': 0.1, 'end_lr': 0, 'lr_mult_head': 10, 'lr_mult_cross_modal': 5, 'get_recall_metric': False, 'resume_from': None, 'fast_dev_run': False, 'val_check_interval': 1.0, 'test_only': True, 'data_root': '/data-4/users/mileriso/datasets/OOD/arrows', 'log_dir': 'result', 'per_gpu_batchsize': 64, 'num_gpus': 1, 'num_nodes': 1, 'load_path': '/data-4/users/mileriso/models/meter_nlvr2.ckpt', 'num_workers': 8, 'precision': 32}\n",
    "meter_config_vqav2 = {'exp_name': 'test_ood_vqa', 'seed': 0, 'datasets': ['ood_vqa'], 'loss_names': {'itm': 0, 'mlm': 0, 'mpp': 0, 'vqa': 1, 'vcr': 0, 'vcr_qar': 0, 'nlvr2': 0, 'irtr': 0, 'contras': 0, 'snli': 0}, 'batch_size': 512, 'accelerator': 'gpu', 'train_transform_keys': ['clip'], 'val_transform_keys': ['clip'], 'image_size': 576, 'patch_size': 16, 'draw_false_image': 0, 'image_only': False, 'resolution_before': 224, 'vqav2_label_size': 3129, 'max_text_len': 50, 'tokenizer': 'roberta-base', 'vocab_size': 50265, 'whole_word_masking': False, 'mlm_prob': 0.15, 'draw_false_text': 0, 'num_top_layer': 6, 'input_image_embed_size': 768, 'input_text_embed_size': 768, 'vit': 'ViT-B/16', 'hidden_size': 768, 'num_heads': 12, 'num_layers': 6, 'mlp_ratio': 4, 'drop_rate': 0.1, 'optim_type': 'adamw', 'learning_rate': 5e-06, 'weight_decay': 0.01, 'decay_power': 1, 'max_epoch': 10, 'max_steps': 1, 'warmup_steps': 0.1, 'end_lr': 0, 'lr_mult_head': 50, 'lr_mult_cross_modal': 5, 'get_recall_metric': False, 'resume_from': None, 'fast_dev_run': False, 'val_check_interval': 0.1, 'test_only': True, 'data_root': '/data-4/users/mileriso/datasets/OOD/arrows', 'log_dir': 'result', 'per_gpu_batchsize': 4, 'num_gpus': 1, 'num_nodes': 1, 'load_path': '/data-4/users/mileriso/models/meter_vqa.ckpt', 'num_workers': 8, 'precision': 32}\n",
    "\n",
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a child datamodule that constructs a smaller version of the full datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:43:17.041490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733420597.060177 3157510 cuda_dnn.cc:8498] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733420597.065771 3157510 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from vilt.datamodules.multitask_datamodule import MTDataModule as MTDataModuleVILT\n",
    "from meter.datamodules.multitask_datamodule import MTDataModule as MTDataModuleMeter\n",
    "\n",
    "class SmallMTDataModuleVILT(MTDataModuleVILT):\n",
    "    def __init__(self, _config, dist=False, num_samples=10, start_idx=100):\n",
    "        super().__init__(_config, dist)\n",
    "        self.num_samples = num_samples\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def setup(self, stage):\n",
    "        super().setup(stage)\n",
    "        \n",
    "        # Limit the number of samples in the datasets\n",
    "        self.train_dataset = Subset(self.train_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.val_dataset = Subset(self.val_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.test_dataset = Subset(self.test_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "\n",
    "class SmallMTDataModuleMETER(MTDataModuleMeter):\n",
    "    def __init__(self, _config, dist=False, num_samples=10, start_idx=100):\n",
    "        super().__init__(_config, dist)\n",
    "        self.num_samples = num_samples\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def setup(self, stage):\n",
    "        super().setup(stage)\n",
    "        \n",
    "        # Limit the number of samples in the datasets\n",
    "        self.train_dataset = Subset(self.train_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.val_dataset = Subset(self.val_dataset, range(self.start_idx, self.start_idx+self.num_samples))\n",
    "        self.test_dataset = Subset(self.test_dataset, range(self.start_idx, self.start_idx+self.num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the configuration and initialize the test and full datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the test dataloader: 5\n",
      "Length of the full dataloader: 5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of the test batch: 10\n",
      "Lenght of the full batch: 10\n"
     ]
    }
   ],
   "source": [
    "# Set the configuration\n",
    "_config = vilt_config_nlvr2\n",
    "_config[\"model_\"] = \"vilt\"\n",
    "_config[\"batch_size\"] = 5\n",
    "\n",
    "# ==========================================\n",
    "# ========= Create full datamodule =========\n",
    "# ==========================================\n",
    "if \"meter\" in _config[\"model_\"]:\n",
    "    full_dm = MTDataModuleMeter(_config, dist=False)\n",
    "    full_dm.setup(\"test\")\n",
    "    full_dataloader = full_dm.test_dataloader()\n",
    "    \n",
    "    test_dm = SmallMTDataModuleMETER(_config, dist=False, num_samples=5, start_idx=100)\n",
    "    test_dm.setup(\"test\")\n",
    "    test_dataloader = test_dm.test_dataloader()\n",
    "\n",
    "else:\n",
    "    full_dm = MTDataModuleVILT(_config, dist=False)\n",
    "    full_dm.setup(\"test\")\n",
    "    full_dataloader = full_dm.test_dataloader()\n",
    "\n",
    "    test_dm = SmallMTDataModuleVILT(_config, dist=False, num_samples=5, start_idx=100)\n",
    "    test_dm.setup(\"test\")\n",
    "    test_dataloader = test_dm.test_dataloader()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Length of the test dataloader: {len(test_dataloader.dataset)}\")\n",
    "print(f\"Length of the full dataloader: {len(full_dataloader.dataset)}\")\n",
    "\n",
    "test_batch = next(iter(test_dataloader))\n",
    "full_batch = next(iter(full_dataloader))\n",
    "\n",
    "print(f\"Lenght of the test batch: {len(test_batch)}\")\n",
    "print(f\"Lenght of the full batch: {len(full_batch)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ViLT model\n"
     ]
    }
   ],
   "source": [
    "from vilt.modules import ViLTransformerSS\n",
    "from meter.modules import METERTransformerSS\n",
    "\n",
    "if _config[\"model_\"] == \"vilt\":\n",
    "    model = ViLTransformerSS(_config)\n",
    "    print(\"Initialized ViLT model\")\n",
    "\n",
    "elif _config[\"model_\"] == \"meter\":\n",
    "    model = METERTransformerSS(_config)\n",
    "    print(\"Initialized METER model\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Model not supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize The Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d3672418dd49efa08e09b796a4ee97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 5. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('nlvr2/test/loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('nlvr2/test/accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric Scalar was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('nlvr2/dev/accuracy_epoch', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('nlvr2/dev/loss_epoch', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('nlvr2/test/accuracy_epoch', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('nlvr2/test/loss_epoch', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val/the_metric', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> nlvr2/dev/accuracy_epoch  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   nlvr2/dev/loss_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    nlvr2/test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6000000238418579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> nlvr2/test/accuracy_epoch </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6000000238418579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      nlvr2/test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2987868785858154     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   nlvr2/test/loss_epoch   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2987868785858154     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val/the_metric       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6000000238418579     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mnlvr2/dev/accuracy_epoch \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  nlvr2/dev/loss_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   nlvr2/test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6000000238418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mnlvr2/test/accuracy_epoch\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6000000238418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     nlvr2/test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2987868785858154    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  nlvr2/test/loss_epoch  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2987868785858154    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val/the_metric      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6000000238418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'nlvr2/test/loss': 1.2987868785858154,\n",
       "  'nlvr2/test/accuracy': 0.6000000238418579,\n",
       "  'nlvr2/dev/accuracy_epoch': nan,\n",
       "  'nlvr2/dev/loss_epoch': nan,\n",
       "  'nlvr2/test/accuracy_epoch': 0.6000000238418579,\n",
       "  'nlvr2/test/loss_epoch': 1.2987868785858154,\n",
       "  'val/the_metric': 0.6000000238418579}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== Initialize the trainer for full precision ==========\n",
    "exp_name = f'{_config[\"exp_name\"]}'\n",
    "\n",
    "os.makedirs(_config[\"log_dir\"], exist_ok=True)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val/the_metric\",\n",
    "    mode=\"max\",\n",
    "    save_last=True,\n",
    ")\n",
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    _config[\"log_dir\"],\n",
    "    name=f'{exp_name}_seed{_config[\"seed\"]}_from_{_config[\"load_path\"].split(\"/\")[-1][:-5]}',\n",
    ")\n",
    "\n",
    "lr_callback = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
    "callbacks = [checkpoint_callback, lr_callback]\n",
    "\n",
    "num_gpus = (\n",
    "    _config[\"num_gpus\"]\n",
    "    if isinstance(_config[\"num_gpus\"], int)\n",
    "    else len(_config[\"num_gpus\"])\n",
    ")\n",
    "\n",
    "grad_steps = _config[\"batch_size\"] // (\n",
    "    _config[\"per_gpu_batchsize\"] * num_gpus * _config[\"num_nodes\"]\n",
    ")\n",
    "\n",
    "max_steps = _config[\"max_steps\"] if _config[\"max_steps\"] is not None else None\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        devices=1,\n",
    "        num_nodes=_config[\"num_nodes\"],\n",
    "        precision=_config[\"precision\"],\n",
    "        # strategy=\"ddp\",\n",
    "        benchmark=True,\n",
    "        deterministic=False,\n",
    "        max_epochs=_config[\"max_epoch\"] if max_steps is None else 1000,\n",
    "        max_steps=max_steps,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        # accumulate_grad_batches=grad_steps,\n",
    "        log_every_n_steps=10,\n",
    "        fast_dev_run=_config[\"fast_dev_run\"],\n",
    "        val_check_interval=_config[\"val_check_interval\"],\n",
    "    )\n",
    "\n",
    "trainer.test(model, datamodule=test_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization | PTQ to 8-bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after quantization:\n",
      "Size (MB): 122.102028\n"
     ]
    }
   ],
   "source": [
    "model_dynamic = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "        model_dynamic, {torch.nn.Embedding, torch.nn.LayerNorm, torch.nn.Conv2d}, dtype=torch.quint8, inplace=True\n",
    "    )\n",
    "\n",
    "torch.quantization.quantize_dynamic(\n",
    "        model_dynamic, {torch.nn.Linear, torch.nn.Dropout, torch.nn.GELU, torch.nn.Conv2d}, dtype=torch.qint8, inplace=True\n",
    "    )\n",
    "\n",
    "print(\"Size after quantization:\")\n",
    "print_size_of_model(model_dynamic)\n",
    "# print(model_dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e75009e981421a85ecfaaa86d7c125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> nlvr2/dev/accuracy_epoch  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   nlvr2/dev/loss_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    nlvr2/test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6000000238418579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> nlvr2/test/accuracy_epoch </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6000000238418579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      nlvr2/test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.298841118812561     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   nlvr2/test/loss_epoch   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.298841118812561     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val/the_metric       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6000000238418579     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mnlvr2/dev/accuracy_epoch \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  nlvr2/dev/loss_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   nlvr2/test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6000000238418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mnlvr2/test/accuracy_epoch\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6000000238418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     nlvr2/test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.298841118812561    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  nlvr2/test/loss_epoch  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.298841118812561    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val/the_metric      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6000000238418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after quantization:\n",
      "Size (MB): 116.453972\n"
     ]
    }
   ],
   "source": [
    "model_static = copy.deepcopy(model)\n",
    "\n",
    "# General quantization configuration\n",
    "quantization_config = torch.quantization.get_default_qconfig('x86')\n",
    "\n",
    "# Configuration for nn.Embedding layers\n",
    "embedding_qconfig = torch.quantization.QConfig(\n",
    "    activation=torch.quantization.HistogramObserver.with_args(reduce_range=True),\n",
    "    weight=torch.quantization.default_float_qparams_observer.with_args(dtype=torch.quint8)\n",
    ")\n",
    "\n",
    "if _config[\"model_\"] == \"vilt\":\n",
    "    # Assign the quantization configurations to the model\n",
    "    model_static.qconfig = quantization_config\n",
    "    model_static.token_type_embeddings.qconfig = embedding_qconfig\n",
    "    model_static.text_embeddings.word_embeddings.qconfig = embedding_qconfig\n",
    "    model_static.text_embeddings.position_embeddings.qconfig = embedding_qconfig\n",
    "    model_static.text_embeddings.token_type_embeddings.qconfig = embedding_qconfig\n",
    "\n",
    "elif _config[\"model_\"] == \"meter\":\n",
    "    # Assign the quantization configurations to the model\n",
    "    model_static.qconfig = quantization_config\n",
    "    model_static.token_type_embeddings.qconfig = embedding_qconfig\n",
    "    model_static.text_transformer.embeddings.word_embeddings.qconfig = embedding_qconfig\n",
    "    model_static.text_transformer.embeddings.position_embeddings.qconfig = embedding_qconfig\n",
    "    model_static.text_transformer.embeddings.token_type_embeddings.qconfig = embedding_qconfig\n",
    "\n",
    "# Perform static quantization\n",
    "torch.quantization.prepare(model_static, inplace=True)\n",
    "trainer.test(model_static, datamodule=test_dm)\n",
    "torch.quantization.convert(model_static, inplace=True)\n",
    "\n",
    "print(\"Size after quantization:\")\n",
    "print_size_of_model(model_static)\n",
    "# print(model_static)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Suite Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization._numeric_suite as ns\n",
    "\n",
    "def compute_error(x, y):\n",
    "    \"\"\"\n",
    "    Signal to Noise Ratio (SNR)    \n",
    "    \"\"\"\n",
    "    Ps = torch.norm(x)\n",
    "    Pn = torch.norm(x-y)\n",
    "    return 20*torch.log10(Ps/Pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys of wt_compare_dict:\n",
      "dict_keys(['text_embeddings.LayerNorm.weight', 'transformer.patch_embed.proj.weight', 'transformer.blocks.0.norm1.weight', 'transformer.blocks.0.attn.qkv._packed_params._packed_params', 'transformer.blocks.0.attn.proj._packed_params._packed_params', 'transformer.blocks.0.norm2.weight', 'transformer.blocks.0.mlp.fc1._packed_params._packed_params', 'transformer.blocks.0.mlp.fc2._packed_params._packed_params', 'transformer.blocks.1.norm1.weight', 'transformer.blocks.1.attn.qkv._packed_params._packed_params', 'transformer.blocks.1.attn.proj._packed_params._packed_params', 'transformer.blocks.1.norm2.weight', 'transformer.blocks.1.mlp.fc1._packed_params._packed_params', 'transformer.blocks.1.mlp.fc2._packed_params._packed_params', 'transformer.blocks.2.norm1.weight', 'transformer.blocks.2.attn.qkv._packed_params._packed_params', 'transformer.blocks.2.attn.proj._packed_params._packed_params', 'transformer.blocks.2.norm2.weight', 'transformer.blocks.2.mlp.fc1._packed_params._packed_params', 'transformer.blocks.2.mlp.fc2._packed_params._packed_params', 'transformer.blocks.3.norm1.weight', 'transformer.blocks.3.attn.qkv._packed_params._packed_params', 'transformer.blocks.3.attn.proj._packed_params._packed_params', 'transformer.blocks.3.norm2.weight', 'transformer.blocks.3.mlp.fc1._packed_params._packed_params', 'transformer.blocks.3.mlp.fc2._packed_params._packed_params', 'transformer.blocks.4.norm1.weight', 'transformer.blocks.4.attn.qkv._packed_params._packed_params', 'transformer.blocks.4.attn.proj._packed_params._packed_params', 'transformer.blocks.4.norm2.weight', 'transformer.blocks.4.mlp.fc1._packed_params._packed_params', 'transformer.blocks.4.mlp.fc2._packed_params._packed_params', 'transformer.blocks.5.norm1.weight', 'transformer.blocks.5.attn.qkv._packed_params._packed_params', 'transformer.blocks.5.attn.proj._packed_params._packed_params', 'transformer.blocks.5.norm2.weight', 'transformer.blocks.5.mlp.fc1._packed_params._packed_params', 'transformer.blocks.5.mlp.fc2._packed_params._packed_params', 'transformer.blocks.6.norm1.weight', 'transformer.blocks.6.attn.qkv._packed_params._packed_params', 'transformer.blocks.6.attn.proj._packed_params._packed_params', 'transformer.blocks.6.norm2.weight', 'transformer.blocks.6.mlp.fc1._packed_params._packed_params', 'transformer.blocks.6.mlp.fc2._packed_params._packed_params', 'transformer.blocks.7.norm1.weight', 'transformer.blocks.7.attn.qkv._packed_params._packed_params', 'transformer.blocks.7.attn.proj._packed_params._packed_params', 'transformer.blocks.7.norm2.weight', 'transformer.blocks.7.mlp.fc1._packed_params._packed_params', 'transformer.blocks.7.mlp.fc2._packed_params._packed_params', 'transformer.blocks.8.norm1.weight', 'transformer.blocks.8.attn.qkv._packed_params._packed_params', 'transformer.blocks.8.attn.proj._packed_params._packed_params', 'transformer.blocks.8.norm2.weight', 'transformer.blocks.8.mlp.fc1._packed_params._packed_params', 'transformer.blocks.8.mlp.fc2._packed_params._packed_params', 'transformer.blocks.9.norm1.weight', 'transformer.blocks.9.attn.qkv._packed_params._packed_params', 'transformer.blocks.9.attn.proj._packed_params._packed_params', 'transformer.blocks.9.norm2.weight', 'transformer.blocks.9.mlp.fc1._packed_params._packed_params', 'transformer.blocks.9.mlp.fc2._packed_params._packed_params', 'transformer.blocks.10.norm1.weight', 'transformer.blocks.10.attn.qkv._packed_params._packed_params', 'transformer.blocks.10.attn.proj._packed_params._packed_params', 'transformer.blocks.10.norm2.weight', 'transformer.blocks.10.mlp.fc1._packed_params._packed_params', 'transformer.blocks.10.mlp.fc2._packed_params._packed_params', 'transformer.blocks.11.norm1.weight', 'transformer.blocks.11.attn.qkv._packed_params._packed_params', 'transformer.blocks.11.attn.proj._packed_params._packed_params', 'transformer.blocks.11.norm2.weight', 'transformer.blocks.11.mlp.fc1._packed_params._packed_params', 'transformer.blocks.11.mlp.fc2._packed_params._packed_params', 'transformer.norm.weight', 'pooler.dense._packed_params._packed_params', 'nlvr2_classifier.0._packed_params._packed_params', 'nlvr2_classifier.1.weight', 'nlvr2_classifier.3._packed_params._packed_params'])\n",
      "text_embeddings.LayerNorm.weight tensor(inf)\n",
      "transformer.patch_embed.proj.weight tensor(39.5962)\n",
      "transformer.blocks.0.norm1.weight tensor(inf)\n",
      "transformer.blocks.0.attn.qkv._packed_params._packed_params tensor(39.6914)\n",
      "transformer.blocks.0.attn.proj._packed_params._packed_params tensor(39.1373)\n",
      "transformer.blocks.0.norm2.weight tensor(inf)\n",
      "transformer.blocks.0.mlp.fc1._packed_params._packed_params tensor(39.3050)\n",
      "transformer.blocks.0.mlp.fc2._packed_params._packed_params tensor(36.9249)\n",
      "transformer.blocks.1.norm1.weight tensor(inf)\n",
      "transformer.blocks.1.attn.qkv._packed_params._packed_params tensor(40.3643)\n",
      "transformer.blocks.1.attn.proj._packed_params._packed_params tensor(40.6226)\n",
      "transformer.blocks.1.norm2.weight tensor(inf)\n",
      "transformer.blocks.1.mlp.fc1._packed_params._packed_params tensor(39.7671)\n",
      "transformer.blocks.1.mlp.fc2._packed_params._packed_params tensor(37.0156)\n",
      "transformer.blocks.2.norm1.weight tensor(inf)\n",
      "transformer.blocks.2.attn.qkv._packed_params._packed_params tensor(41.0369)\n",
      "transformer.blocks.2.attn.proj._packed_params._packed_params tensor(41.6981)\n",
      "transformer.blocks.2.norm2.weight tensor(inf)\n",
      "transformer.blocks.2.mlp.fc1._packed_params._packed_params tensor(41.1844)\n",
      "transformer.blocks.2.mlp.fc2._packed_params._packed_params tensor(37.6127)\n",
      "transformer.blocks.3.norm1.weight tensor(inf)\n",
      "transformer.blocks.3.attn.qkv._packed_params._packed_params tensor(41.3728)\n",
      "transformer.blocks.3.attn.proj._packed_params._packed_params tensor(42.0656)\n",
      "transformer.blocks.3.norm2.weight tensor(inf)\n",
      "transformer.blocks.3.mlp.fc1._packed_params._packed_params tensor(41.6601)\n",
      "transformer.blocks.3.mlp.fc2._packed_params._packed_params tensor(39.7832)\n",
      "transformer.blocks.4.norm1.weight tensor(inf)\n",
      "transformer.blocks.4.attn.qkv._packed_params._packed_params tensor(41.5447)\n",
      "transformer.blocks.4.attn.proj._packed_params._packed_params tensor(42.1387)\n",
      "transformer.blocks.4.norm2.weight tensor(inf)\n",
      "transformer.blocks.4.mlp.fc1._packed_params._packed_params tensor(41.9708)\n",
      "transformer.blocks.4.mlp.fc2._packed_params._packed_params tensor(39.5299)\n",
      "transformer.blocks.5.norm1.weight tensor(inf)\n",
      "transformer.blocks.5.attn.qkv._packed_params._packed_params tensor(41.7101)\n",
      "transformer.blocks.5.attn.proj._packed_params._packed_params tensor(42.1818)\n",
      "transformer.blocks.5.norm2.weight tensor(inf)\n",
      "transformer.blocks.5.mlp.fc1._packed_params._packed_params tensor(42.0364)\n",
      "transformer.blocks.5.mlp.fc2._packed_params._packed_params tensor(39.2283)\n",
      "transformer.blocks.6.norm1.weight tensor(inf)\n",
      "transformer.blocks.6.attn.qkv._packed_params._packed_params tensor(41.9315)\n",
      "transformer.blocks.6.attn.proj._packed_params._packed_params tensor(42.1755)\n",
      "transformer.blocks.6.norm2.weight tensor(inf)\n",
      "transformer.blocks.6.mlp.fc1._packed_params._packed_params tensor(42.0948)\n",
      "transformer.blocks.6.mlp.fc2._packed_params._packed_params tensor(37.6838)\n",
      "transformer.blocks.7.norm1.weight tensor(inf)\n",
      "transformer.blocks.7.attn.qkv._packed_params._packed_params tensor(41.9083)\n",
      "transformer.blocks.7.attn.proj._packed_params._packed_params tensor(42.2644)\n",
      "transformer.blocks.7.norm2.weight tensor(inf)\n",
      "transformer.blocks.7.mlp.fc1._packed_params._packed_params tensor(42.0233)\n",
      "transformer.blocks.7.mlp.fc2._packed_params._packed_params tensor(37.1410)\n",
      "transformer.blocks.8.norm1.weight tensor(inf)\n",
      "transformer.blocks.8.attn.qkv._packed_params._packed_params tensor(42.0324)\n",
      "transformer.blocks.8.attn.proj._packed_params._packed_params tensor(42.3671)\n",
      "transformer.blocks.8.norm2.weight tensor(inf)\n",
      "transformer.blocks.8.mlp.fc1._packed_params._packed_params tensor(41.6746)\n",
      "transformer.blocks.8.mlp.fc2._packed_params._packed_params tensor(38.2337)\n",
      "transformer.blocks.9.norm1.weight tensor(inf)\n",
      "transformer.blocks.9.attn.qkv._packed_params._packed_params tensor(41.8715)\n",
      "transformer.blocks.9.attn.proj._packed_params._packed_params tensor(42.2610)\n",
      "transformer.blocks.9.norm2.weight tensor(inf)\n",
      "transformer.blocks.9.mlp.fc1._packed_params._packed_params tensor(42.0403)\n",
      "transformer.blocks.9.mlp.fc2._packed_params._packed_params tensor(38.6023)\n",
      "transformer.blocks.10.norm1.weight tensor(inf)\n",
      "transformer.blocks.10.attn.qkv._packed_params._packed_params tensor(41.4636)\n",
      "transformer.blocks.10.attn.proj._packed_params._packed_params tensor(42.2658)\n",
      "transformer.blocks.10.norm2.weight tensor(inf)\n",
      "transformer.blocks.10.mlp.fc1._packed_params._packed_params tensor(42.0501)\n",
      "transformer.blocks.10.mlp.fc2._packed_params._packed_params tensor(39.8112)\n",
      "transformer.blocks.11.norm1.weight tensor(inf)\n",
      "transformer.blocks.11.attn.qkv._packed_params._packed_params tensor(41.7569)\n",
      "transformer.blocks.11.attn.proj._packed_params._packed_params tensor(41.8729)\n",
      "transformer.blocks.11.norm2.weight tensor(inf)\n",
      "transformer.blocks.11.mlp.fc1._packed_params._packed_params tensor(42.0285)\n",
      "transformer.blocks.11.mlp.fc2._packed_params._packed_params tensor(38.6025)\n",
      "transformer.norm.weight tensor(inf)\n",
      "pooler.dense._packed_params._packed_params tensor(42.2699)\n",
      "nlvr2_classifier.0._packed_params._packed_params tensor(41.8611)\n",
      "nlvr2_classifier.1.weight tensor(inf)\n",
      "nlvr2_classifier.3._packed_params._packed_params tensor(41.1714)\n"
     ]
    }
   ],
   "source": [
    "# ======== Static quantization comparison ========\n",
    "wt_compare_dict_static = ns.compare_weights(model.state_dict(), model_static.state_dict())\n",
    "\n",
    "print('keys of wt_compare_dict:')\n",
    "print(wt_compare_dict_static.keys())\n",
    "\n",
    "key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "# print(f\"\\nkeys of wt_compare_dict entry for {key} weight:\")\n",
    "# print(wt_compare_dict_static[key].keys())\n",
    "# print(wt_compare_dict_static[key]['float'].shape)\n",
    "# print(wt_compare_dict_static[key]['quantized'].shape)\n",
    "\n",
    "for key in wt_compare_dict_static:\n",
    "    print(key, compute_error(wt_compare_dict_static[key]['float'], wt_compare_dict_static[key]['quantized'].dequantize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys of act_compare_dict:\n",
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.patch_embed.quant.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.attn.quant.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.0.quant.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.attn.quant.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.1.quant.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.attn.quant.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.2.quant.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.attn.quant.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.3.quant.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.attn.quant.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.4.quant.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.attn.quant.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.5.quant.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.attn.quant.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.6.quant.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.attn.quant.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.7.quant.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.attn.quant.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.8.quant.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.attn.quant.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.9.quant.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.attn.quant.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.10.quant.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.attn.quant.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.blocks.11.quant.stats', 'transformer.norm.stats', 'pooler.dense.stats', 'pooler.quant.stats', 'nlvr2_classifier.0.stats', 'nlvr2_classifier.1.stats', 'nlvr2_classifier.3.stats', 'quant.stats'])\n",
      "\n",
      "keys of act_compare_dict entry for nlvr2_classifier.3._packed_params._packed_params output:\n",
      "dict_keys(['float', 'quantized'])\n",
      "torch.Size([5, 257, 2304])\n",
      "torch.Size([5, 257, 2304])\n"
     ]
    }
   ],
   "source": [
    "# Take in floating point and quantized model as well as input data, and returns a dict, with keys\n",
    "# corresponding to the quantized module names and each entry being a dictionary with two keys 'float' and\n",
    "# 'quantized', containing the activations of floating point and quantized model at matching locations.\n",
    "\n",
    "# act_compare_dict_static = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_static), full_batch)\n",
    "act_compare_dict_static = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_static), test_batch)\n",
    "\n",
    "print('keys of act_compare_dict:')\n",
    "print(act_compare_dict_static.keys())\n",
    "\n",
    "key_act = \"transformer.blocks.0.attn.qkv.stats\"\n",
    "\n",
    "print(f\"\\nkeys of act_compare_dict entry for {key} output:\")\n",
    "print(act_compare_dict_static[key_act].keys())\n",
    "print(act_compare_dict_static[key_act]['float'][0].shape)\n",
    "print(act_compare_dict_static[key_act]['quantized'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 17.82866859436035\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - 18.955486297607422\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - 26.32302474975586\n",
      "3 - transformer.patch_embed.quant.stats\n",
      "3 - 44.364158630371094\n",
      "4 - transformer.blocks.0.norm1.stats\n",
      "4 - 0.4864632785320282\n",
      "5 - transformer.blocks.0.attn.qkv.stats\n",
      "5 - 5.93009090423584\n",
      "6 - transformer.blocks.0.attn.proj.stats\n",
      "6 - 0.6434845328330994\n",
      "7 - transformer.blocks.0.attn.quant.stats\n",
      "7 - 0.4597845673561096\n",
      "8 - transformer.blocks.0.norm2.stats\n",
      "8 - 0.7093193531036377\n",
      "9 - transformer.blocks.0.mlp.fc1.stats\n",
      "9 - 6.044439315795898\n",
      "10 - transformer.blocks.0.mlp.fc2.stats\n",
      "10 - -1.2007348537445068\n",
      "11 - transformer.blocks.0.quant.stats\n",
      "11 - -0.07495744526386261\n",
      "12 - transformer.blocks.1.norm1.stats\n",
      "12 - 0.08032231032848358\n",
      "13 - transformer.blocks.1.attn.qkv.stats\n",
      "13 - 5.3930511474609375\n",
      "14 - transformer.blocks.1.attn.proj.stats\n",
      "14 - 0.07086136937141418\n",
      "15 - transformer.blocks.1.attn.quant.stats\n",
      "15 - 0.02302350290119648\n",
      "16 - transformer.blocks.1.norm2.stats\n",
      "16 - 0.9033985137939453\n",
      "17 - transformer.blocks.1.mlp.fc1.stats\n",
      "17 - 5.248117446899414\n",
      "18 - transformer.blocks.1.mlp.fc2.stats\n",
      "18 - -1.2541682720184326\n",
      "19 - transformer.blocks.1.quant.stats\n",
      "19 - 0.24195103347301483\n",
      "20 - transformer.blocks.2.norm1.stats\n",
      "20 - -0.05466576665639877\n",
      "21 - transformer.blocks.2.attn.qkv.stats\n",
      "21 - 2.0831074714660645\n",
      "22 - transformer.blocks.2.attn.proj.stats\n",
      "22 - -0.3821668326854706\n",
      "23 - transformer.blocks.2.attn.quant.stats\n",
      "23 - -0.08510462194681168\n",
      "24 - transformer.blocks.2.norm2.stats\n",
      "24 - 0.8347734808921814\n",
      "25 - transformer.blocks.2.mlp.fc1.stats\n",
      "25 - 5.62865686416626\n",
      "26 - transformer.blocks.2.mlp.fc2.stats\n",
      "26 - -1.147688388824463\n",
      "27 - transformer.blocks.2.quant.stats\n",
      "27 - 0.3492593467235565\n",
      "28 - transformer.blocks.3.norm1.stats\n",
      "28 - -0.1902659833431244\n",
      "29 - transformer.blocks.3.attn.qkv.stats\n",
      "29 - 2.30998158454895\n",
      "30 - transformer.blocks.3.attn.proj.stats\n",
      "30 - -0.23577958345413208\n",
      "31 - transformer.blocks.3.attn.quant.stats\n",
      "31 - -0.207035630941391\n",
      "32 - transformer.blocks.3.norm2.stats\n",
      "32 - 0.7336603999137878\n",
      "33 - transformer.blocks.3.mlp.fc1.stats\n",
      "33 - 5.759654998779297\n",
      "34 - transformer.blocks.3.mlp.fc2.stats\n",
      "34 - -1.1039509773254395\n",
      "35 - transformer.blocks.3.quant.stats\n",
      "35 - 0.32300424575805664\n",
      "36 - transformer.blocks.4.norm1.stats\n",
      "36 - -0.2526395618915558\n",
      "37 - transformer.blocks.4.attn.qkv.stats\n",
      "37 - 2.7585434913635254\n",
      "38 - transformer.blocks.4.attn.proj.stats\n",
      "38 - 0.08012533187866211\n",
      "39 - transformer.blocks.4.attn.quant.stats\n",
      "39 - -0.27051714062690735\n",
      "40 - transformer.blocks.4.norm2.stats\n",
      "40 - 0.6016798615455627\n",
      "41 - transformer.blocks.4.mlp.fc1.stats\n",
      "41 - 5.95241641998291\n",
      "42 - transformer.blocks.4.mlp.fc2.stats\n",
      "42 - -0.7656479477882385\n",
      "43 - transformer.blocks.4.quant.stats\n",
      "43 - 0.2588319778442383\n",
      "44 - transformer.blocks.5.norm1.stats\n",
      "44 - -0.2931104898452759\n",
      "45 - transformer.blocks.5.attn.qkv.stats\n",
      "45 - 3.2176218032836914\n",
      "46 - transformer.blocks.5.attn.proj.stats\n",
      "46 - 0.3616187572479248\n",
      "47 - transformer.blocks.5.attn.quant.stats\n",
      "47 - -0.2978476583957672\n",
      "48 - transformer.blocks.5.norm2.stats\n",
      "48 - 0.5385124683380127\n",
      "49 - transformer.blocks.5.mlp.fc1.stats\n",
      "49 - 6.217086315155029\n",
      "50 - transformer.blocks.5.mlp.fc2.stats\n",
      "50 - -0.6312984824180603\n",
      "51 - transformer.blocks.5.quant.stats\n",
      "51 - 0.2589907646179199\n",
      "52 - transformer.blocks.6.norm1.stats\n",
      "52 - -0.2521977126598358\n",
      "53 - transformer.blocks.6.attn.qkv.stats\n",
      "53 - 4.207430362701416\n",
      "54 - transformer.blocks.6.attn.proj.stats\n",
      "54 - 0.7157046794891357\n",
      "55 - transformer.blocks.6.attn.quant.stats\n",
      "55 - -0.23155467212200165\n",
      "56 - transformer.blocks.6.norm2.stats\n",
      "56 - 0.46563073992729187\n",
      "57 - transformer.blocks.6.mlp.fc1.stats\n",
      "57 - 6.34425163269043\n",
      "58 - transformer.blocks.6.mlp.fc2.stats\n",
      "58 - -1.662569522857666\n",
      "59 - transformer.blocks.6.quant.stats\n",
      "59 - 0.2747231721878052\n",
      "60 - transformer.blocks.7.norm1.stats\n",
      "60 - -0.8429831862449646\n",
      "61 - transformer.blocks.7.attn.qkv.stats\n",
      "61 - 7.404764175415039\n",
      "62 - transformer.blocks.7.attn.proj.stats\n",
      "62 - 0.7450764775276184\n",
      "63 - transformer.blocks.7.attn.quant.stats\n",
      "63 - -0.8086686134338379\n",
      "64 - transformer.blocks.7.norm2.stats\n",
      "64 - -0.23096609115600586\n",
      "65 - transformer.blocks.7.mlp.fc1.stats\n",
      "65 - 5.79833459854126\n",
      "66 - transformer.blocks.7.mlp.fc2.stats\n",
      "66 - -0.6630298495292664\n",
      "67 - transformer.blocks.7.quant.stats\n",
      "67 - -1.1866027116775513\n",
      "68 - transformer.blocks.8.norm1.stats\n",
      "68 - -1.2963876724243164\n",
      "69 - transformer.blocks.8.attn.qkv.stats\n",
      "69 - 8.663394927978516\n",
      "70 - transformer.blocks.8.attn.proj.stats\n",
      "70 - -0.2093534767627716\n",
      "71 - transformer.blocks.8.attn.quant.stats\n",
      "71 - -1.3090105056762695\n",
      "72 - transformer.blocks.8.norm2.stats\n",
      "72 - -1.478162407875061\n",
      "73 - transformer.blocks.8.mlp.fc1.stats\n",
      "73 - 4.582387447357178\n",
      "74 - transformer.blocks.8.mlp.fc2.stats\n",
      "74 - -0.6901481747627258\n",
      "75 - transformer.blocks.8.quant.stats\n",
      "75 - -0.9233713150024414\n",
      "76 - transformer.blocks.9.norm1.stats\n",
      "76 - -0.5273109078407288\n",
      "77 - transformer.blocks.9.attn.qkv.stats\n",
      "77 - 9.732210159301758\n",
      "78 - transformer.blocks.9.attn.proj.stats\n",
      "78 - -0.5554275512695312\n",
      "79 - transformer.blocks.9.attn.quant.stats\n",
      "79 - -0.5383126735687256\n",
      "80 - transformer.blocks.9.norm2.stats\n",
      "80 - -0.660555362701416\n",
      "81 - transformer.blocks.9.mlp.fc1.stats\n",
      "81 - 4.787884712219238\n",
      "82 - transformer.blocks.9.mlp.fc2.stats\n",
      "82 - -1.2896356582641602\n",
      "83 - transformer.blocks.9.quant.stats\n",
      "83 - -0.7484105229377747\n",
      "84 - transformer.blocks.10.norm1.stats\n",
      "84 - -0.32576265931129456\n",
      "85 - transformer.blocks.10.attn.qkv.stats\n",
      "85 - 8.17195987701416\n",
      "86 - transformer.blocks.10.attn.proj.stats\n",
      "86 - -0.16930274665355682\n",
      "87 - transformer.blocks.10.attn.quant.stats\n",
      "87 - -0.32643193006515503\n",
      "88 - transformer.blocks.10.norm2.stats\n",
      "88 - -0.06894318759441376\n",
      "89 - transformer.blocks.10.mlp.fc1.stats\n",
      "89 - 4.8374528884887695\n",
      "90 - transformer.blocks.10.mlp.fc2.stats\n",
      "90 - -0.07392928749322891\n",
      "91 - transformer.blocks.10.quant.stats\n",
      "91 - -0.6190575361251831\n",
      "92 - transformer.blocks.11.norm1.stats\n",
      "92 - -1.2524099349975586\n",
      "93 - transformer.blocks.11.attn.qkv.stats\n",
      "93 - 7.4620585441589355\n",
      "94 - transformer.blocks.11.attn.proj.stats\n",
      "94 - -2.003283739089966\n",
      "95 - transformer.blocks.11.attn.quant.stats\n",
      "95 - -1.2774906158447266\n",
      "96 - transformer.blocks.11.norm2.stats\n",
      "96 - 0.518545925617218\n",
      "97 - transformer.blocks.11.mlp.fc1.stats\n",
      "97 - 3.7585620880126953\n",
      "98 - transformer.blocks.11.mlp.fc2.stats\n",
      "98 - 0.4247480034828186\n",
      "99 - transformer.blocks.11.quant.stats\n",
      "99 - -0.47319644689559937\n",
      "100 - transformer.norm.stats\n",
      "100 - -0.7403141856193542\n",
      "101 - pooler.dense.stats\n",
      "101 - -1.3613133430480957\n",
      "102 - pooler.quant.stats\n",
      "102 - -1.4009816646575928\n",
      "103 - nlvr2_classifier.0.stats\n",
      "103 - -0.8297380805015564\n",
      "104 - nlvr2_classifier.1.stats\n",
      "104 - -4.106420993804932\n",
      "105 - nlvr2_classifier.3.stats\n",
      "105 - -1.5983964204788208\n",
      "106 - quant.stats\n",
      "106 - 0.6757646203041077\n",
      "Total error: 210.36483764648438\n"
     ]
    }
   ],
   "source": [
    "total_err = 0.0\n",
    "for idx, key in enumerate(act_compare_dict_static):\n",
    "    err = compute_error(act_compare_dict_static[key]['float'][0], act_compare_dict_static[key]['quantized'][0].dequantize())\n",
    "    total_err += err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err}\")\n",
    "\n",
    "print(f\"Total error: {total_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# q = wt_compare_dict[key]['quantized'].flatten().dequantize()\n",
    "# f = wt_compare_dict[key]['float'].flatten()\n",
    "\n",
    "# plt.hist(q, bins=100, alpha=0.5, label='Quantized')\n",
    "# plt.hist(f, bins=100, alpha=0.5, label='Floating Point')\n",
    "\n",
    "\n",
    "# plt.title(f\"Model Weights of {key}\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys of wt_compare_dict:\n",
      "dict_keys(['text_embeddings.LayerNorm.weight', 'transformer.patch_embed.proj.weight', 'transformer.blocks.0.norm1.weight', 'transformer.blocks.0.attn.qkv._packed_params._packed_params', 'transformer.blocks.0.attn.proj._packed_params._packed_params', 'transformer.blocks.0.norm2.weight', 'transformer.blocks.0.mlp.fc1._packed_params._packed_params', 'transformer.blocks.0.mlp.fc2._packed_params._packed_params', 'transformer.blocks.1.norm1.weight', 'transformer.blocks.1.attn.qkv._packed_params._packed_params', 'transformer.blocks.1.attn.proj._packed_params._packed_params', 'transformer.blocks.1.norm2.weight', 'transformer.blocks.1.mlp.fc1._packed_params._packed_params', 'transformer.blocks.1.mlp.fc2._packed_params._packed_params', 'transformer.blocks.2.norm1.weight', 'transformer.blocks.2.attn.qkv._packed_params._packed_params', 'transformer.blocks.2.attn.proj._packed_params._packed_params', 'transformer.blocks.2.norm2.weight', 'transformer.blocks.2.mlp.fc1._packed_params._packed_params', 'transformer.blocks.2.mlp.fc2._packed_params._packed_params', 'transformer.blocks.3.norm1.weight', 'transformer.blocks.3.attn.qkv._packed_params._packed_params', 'transformer.blocks.3.attn.proj._packed_params._packed_params', 'transformer.blocks.3.norm2.weight', 'transformer.blocks.3.mlp.fc1._packed_params._packed_params', 'transformer.blocks.3.mlp.fc2._packed_params._packed_params', 'transformer.blocks.4.norm1.weight', 'transformer.blocks.4.attn.qkv._packed_params._packed_params', 'transformer.blocks.4.attn.proj._packed_params._packed_params', 'transformer.blocks.4.norm2.weight', 'transformer.blocks.4.mlp.fc1._packed_params._packed_params', 'transformer.blocks.4.mlp.fc2._packed_params._packed_params', 'transformer.blocks.5.norm1.weight', 'transformer.blocks.5.attn.qkv._packed_params._packed_params', 'transformer.blocks.5.attn.proj._packed_params._packed_params', 'transformer.blocks.5.norm2.weight', 'transformer.blocks.5.mlp.fc1._packed_params._packed_params', 'transformer.blocks.5.mlp.fc2._packed_params._packed_params', 'transformer.blocks.6.norm1.weight', 'transformer.blocks.6.attn.qkv._packed_params._packed_params', 'transformer.blocks.6.attn.proj._packed_params._packed_params', 'transformer.blocks.6.norm2.weight', 'transformer.blocks.6.mlp.fc1._packed_params._packed_params', 'transformer.blocks.6.mlp.fc2._packed_params._packed_params', 'transformer.blocks.7.norm1.weight', 'transformer.blocks.7.attn.qkv._packed_params._packed_params', 'transformer.blocks.7.attn.proj._packed_params._packed_params', 'transformer.blocks.7.norm2.weight', 'transformer.blocks.7.mlp.fc1._packed_params._packed_params', 'transformer.blocks.7.mlp.fc2._packed_params._packed_params', 'transformer.blocks.8.norm1.weight', 'transformer.blocks.8.attn.qkv._packed_params._packed_params', 'transformer.blocks.8.attn.proj._packed_params._packed_params', 'transformer.blocks.8.norm2.weight', 'transformer.blocks.8.mlp.fc1._packed_params._packed_params', 'transformer.blocks.8.mlp.fc2._packed_params._packed_params', 'transformer.blocks.9.norm1.weight', 'transformer.blocks.9.attn.qkv._packed_params._packed_params', 'transformer.blocks.9.attn.proj._packed_params._packed_params', 'transformer.blocks.9.norm2.weight', 'transformer.blocks.9.mlp.fc1._packed_params._packed_params', 'transformer.blocks.9.mlp.fc2._packed_params._packed_params', 'transformer.blocks.10.norm1.weight', 'transformer.blocks.10.attn.qkv._packed_params._packed_params', 'transformer.blocks.10.attn.proj._packed_params._packed_params', 'transformer.blocks.10.norm2.weight', 'transformer.blocks.10.mlp.fc1._packed_params._packed_params', 'transformer.blocks.10.mlp.fc2._packed_params._packed_params', 'transformer.blocks.11.norm1.weight', 'transformer.blocks.11.attn.qkv._packed_params._packed_params', 'transformer.blocks.11.attn.proj._packed_params._packed_params', 'transformer.blocks.11.norm2.weight', 'transformer.blocks.11.mlp.fc1._packed_params._packed_params', 'transformer.blocks.11.mlp.fc2._packed_params._packed_params', 'transformer.norm.weight', 'pooler.dense._packed_params._packed_params', 'nlvr2_classifier.0._packed_params._packed_params', 'nlvr2_classifier.1.weight', 'nlvr2_classifier.3._packed_params._packed_params'])\n",
      "text_embeddings.LayerNorm.weight tensor(inf)\n",
      "transformer.patch_embed.proj.weight tensor(inf)\n",
      "transformer.blocks.0.norm1.weight tensor(inf)\n",
      "transformer.blocks.0.attn.qkv._packed_params._packed_params tensor(27.6603)\n",
      "transformer.blocks.0.attn.proj._packed_params._packed_params tensor(21.9632)\n",
      "transformer.blocks.0.norm2.weight tensor(inf)\n",
      "transformer.blocks.0.mlp.fc1._packed_params._packed_params tensor(26.8201)\n",
      "transformer.blocks.0.mlp.fc2._packed_params._packed_params tensor(18.2197)\n",
      "transformer.blocks.1.norm1.weight tensor(inf)\n",
      "transformer.blocks.1.attn.qkv._packed_params._packed_params tensor(32.1591)\n",
      "transformer.blocks.1.attn.proj._packed_params._packed_params tensor(29.1489)\n",
      "transformer.blocks.1.norm2.weight tensor(inf)\n",
      "transformer.blocks.1.mlp.fc1._packed_params._packed_params tensor(27.6326)\n",
      "transformer.blocks.1.mlp.fc2._packed_params._packed_params tensor(16.8188)\n",
      "transformer.blocks.2.norm1.weight tensor(inf)\n",
      "transformer.blocks.2.attn.qkv._packed_params._packed_params tensor(33.9705)\n",
      "transformer.blocks.2.attn.proj._packed_params._packed_params tensor(36.3658)\n",
      "transformer.blocks.2.norm2.weight tensor(inf)\n",
      "transformer.blocks.2.mlp.fc1._packed_params._packed_params tensor(32.5778)\n",
      "transformer.blocks.2.mlp.fc2._packed_params._packed_params tensor(16.3573)\n",
      "transformer.blocks.3.norm1.weight tensor(inf)\n",
      "transformer.blocks.3.attn.qkv._packed_params._packed_params tensor(33.1731)\n",
      "transformer.blocks.3.attn.proj._packed_params._packed_params tensor(36.9766)\n",
      "transformer.blocks.3.norm2.weight tensor(inf)\n",
      "transformer.blocks.3.mlp.fc1._packed_params._packed_params tensor(31.9174)\n",
      "transformer.blocks.3.mlp.fc2._packed_params._packed_params tensor(30.5879)\n",
      "transformer.blocks.4.norm1.weight tensor(inf)\n",
      "transformer.blocks.4.attn.qkv._packed_params._packed_params tensor(34.6853)\n",
      "transformer.blocks.4.attn.proj._packed_params._packed_params tensor(38.7722)\n",
      "transformer.blocks.4.norm2.weight tensor(inf)\n",
      "transformer.blocks.4.mlp.fc1._packed_params._packed_params tensor(31.5763)\n",
      "transformer.blocks.4.mlp.fc2._packed_params._packed_params tensor(27.0241)\n",
      "transformer.blocks.5.norm1.weight tensor(inf)\n",
      "transformer.blocks.5.attn.qkv._packed_params._packed_params tensor(33.9206)\n",
      "transformer.blocks.5.attn.proj._packed_params._packed_params tensor(38.1620)\n",
      "transformer.blocks.5.norm2.weight tensor(inf)\n",
      "transformer.blocks.5.mlp.fc1._packed_params._packed_params tensor(35.5313)\n",
      "transformer.blocks.5.mlp.fc2._packed_params._packed_params tensor(29.8128)\n",
      "transformer.blocks.6.norm1.weight tensor(inf)\n",
      "transformer.blocks.6.attn.qkv._packed_params._packed_params tensor(35.8919)\n",
      "transformer.blocks.6.attn.proj._packed_params._packed_params tensor(33.9035)\n",
      "transformer.blocks.6.norm2.weight tensor(inf)\n",
      "transformer.blocks.6.mlp.fc1._packed_params._packed_params tensor(31.8867)\n",
      "transformer.blocks.6.mlp.fc2._packed_params._packed_params tensor(16.1021)\n",
      "transformer.blocks.7.norm1.weight tensor(inf)\n",
      "transformer.blocks.7.attn.qkv._packed_params._packed_params tensor(33.9172)\n",
      "transformer.blocks.7.attn.proj._packed_params._packed_params tensor(37.9436)\n",
      "transformer.blocks.7.norm2.weight tensor(inf)\n",
      "transformer.blocks.7.mlp.fc1._packed_params._packed_params tensor(23.2327)\n",
      "transformer.blocks.7.mlp.fc2._packed_params._packed_params tensor(15.1098)\n",
      "transformer.blocks.8.norm1.weight tensor(inf)\n",
      "transformer.blocks.8.attn.qkv._packed_params._packed_params tensor(35.2553)\n",
      "transformer.blocks.8.attn.proj._packed_params._packed_params tensor(36.0778)\n",
      "transformer.blocks.8.norm2.weight tensor(inf)\n",
      "transformer.blocks.8.mlp.fc1._packed_params._packed_params tensor(18.8679)\n",
      "transformer.blocks.8.mlp.fc2._packed_params._packed_params tensor(18.3570)\n",
      "transformer.blocks.9.norm1.weight tensor(inf)\n",
      "transformer.blocks.9.attn.qkv._packed_params._packed_params tensor(33.1310)\n",
      "transformer.blocks.9.attn.proj._packed_params._packed_params tensor(30.5179)\n",
      "transformer.blocks.9.norm2.weight tensor(inf)\n",
      "transformer.blocks.9.mlp.fc1._packed_params._packed_params tensor(22.5524)\n",
      "transformer.blocks.9.mlp.fc2._packed_params._packed_params tensor(21.0352)\n",
      "transformer.blocks.10.norm1.weight tensor(inf)\n",
      "transformer.blocks.10.attn.qkv._packed_params._packed_params tensor(30.7487)\n",
      "transformer.blocks.10.attn.proj._packed_params._packed_params tensor(34.3153)\n",
      "transformer.blocks.10.norm2.weight tensor(inf)\n",
      "transformer.blocks.10.mlp.fc1._packed_params._packed_params tensor(33.3186)\n",
      "transformer.blocks.10.mlp.fc2._packed_params._packed_params tensor(29.1740)\n",
      "transformer.blocks.11.norm1.weight tensor(inf)\n",
      "transformer.blocks.11.attn.qkv._packed_params._packed_params tensor(30.9914)\n",
      "transformer.blocks.11.attn.proj._packed_params._packed_params tensor(26.3990)\n",
      "transformer.blocks.11.norm2.weight tensor(inf)\n",
      "transformer.blocks.11.mlp.fc1._packed_params._packed_params tensor(28.9710)\n",
      "transformer.blocks.11.mlp.fc2._packed_params._packed_params tensor(19.5048)\n",
      "transformer.norm.weight tensor(inf)\n",
      "pooler.dense._packed_params._packed_params tensor(36.5631)\n",
      "nlvr2_classifier.0._packed_params._packed_params tensor(38.9495)\n",
      "nlvr2_classifier.1.weight tensor(inf)\n",
      "nlvr2_classifier.3._packed_params._packed_params tensor(40.7681)\n"
     ]
    }
   ],
   "source": [
    "# ======== Dynamic quantization comparison ========\n",
    "wt_compare_dict_dynamic = ns.compare_weights(model.state_dict(), model_dynamic.state_dict())\n",
    "\n",
    "\n",
    "print('keys of wt_compare_dict:')\n",
    "print(wt_compare_dict_dynamic.keys())\n",
    "\n",
    "# key = 'text_embeddings.LayerNorm.weight'\n",
    "\n",
    "# print(f\"\\nkeys of wt_compare_dict entry for {key} weight:\")\n",
    "# print(wt_compare_dict_dynamic[key].keys())\n",
    "# print(wt_compare_dict_dynamic[key]['float'].shape)\n",
    "# print(wt_compare_dict_dynamic[key]['quantized'].shape)\n",
    "\n",
    "for key in wt_compare_dict_dynamic:\n",
    "    if wt_compare_dict_dynamic[key]['quantized'].is_quantized:\n",
    "        print(key, compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized'].dequantize()))\n",
    "    else:\n",
    "        print(key, compute_error(wt_compare_dict_dynamic[key]['float'], wt_compare_dict_dynamic[key]['quantized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# q = wt_compare_dict[key]['quantized'].flatten().dequantize()\n",
    "# f = wt_compare_dict[key]['float'].flatten()\n",
    "\n",
    "# plt.hist(q, bins=100, alpha=0.5, label='Quantized')\n",
    "# plt.hist(f, bins=100, alpha=0.5, label='Floating Point')\n",
    "\n",
    "\n",
    "# plt.title(f\"Model Weights of {key}\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_embeddings.LayerNorm.stats', 'text_embeddings.quant.stats', 'transformer.patch_embed.proj.stats', 'transformer.patch_embed.quant.stats', 'transformer.blocks.0.norm1.stats', 'transformer.blocks.0.attn.qkv.stats', 'transformer.blocks.0.attn.proj.stats', 'transformer.blocks.0.attn.quant.stats', 'transformer.blocks.0.norm2.stats', 'transformer.blocks.0.mlp.fc1.stats', 'transformer.blocks.0.mlp.fc2.stats', 'transformer.blocks.0.quant.stats', 'transformer.blocks.1.norm1.stats', 'transformer.blocks.1.attn.qkv.stats', 'transformer.blocks.1.attn.proj.stats', 'transformer.blocks.1.attn.quant.stats', 'transformer.blocks.1.norm2.stats', 'transformer.blocks.1.mlp.fc1.stats', 'transformer.blocks.1.mlp.fc2.stats', 'transformer.blocks.1.quant.stats', 'transformer.blocks.2.norm1.stats', 'transformer.blocks.2.attn.qkv.stats', 'transformer.blocks.2.attn.proj.stats', 'transformer.blocks.2.attn.quant.stats', 'transformer.blocks.2.norm2.stats', 'transformer.blocks.2.mlp.fc1.stats', 'transformer.blocks.2.mlp.fc2.stats', 'transformer.blocks.2.quant.stats', 'transformer.blocks.3.norm1.stats', 'transformer.blocks.3.attn.qkv.stats', 'transformer.blocks.3.attn.proj.stats', 'transformer.blocks.3.attn.quant.stats', 'transformer.blocks.3.norm2.stats', 'transformer.blocks.3.mlp.fc1.stats', 'transformer.blocks.3.mlp.fc2.stats', 'transformer.blocks.3.quant.stats', 'transformer.blocks.4.norm1.stats', 'transformer.blocks.4.attn.qkv.stats', 'transformer.blocks.4.attn.proj.stats', 'transformer.blocks.4.attn.quant.stats', 'transformer.blocks.4.norm2.stats', 'transformer.blocks.4.mlp.fc1.stats', 'transformer.blocks.4.mlp.fc2.stats', 'transformer.blocks.4.quant.stats', 'transformer.blocks.5.norm1.stats', 'transformer.blocks.5.attn.qkv.stats', 'transformer.blocks.5.attn.proj.stats', 'transformer.blocks.5.attn.quant.stats', 'transformer.blocks.5.norm2.stats', 'transformer.blocks.5.mlp.fc1.stats', 'transformer.blocks.5.mlp.fc2.stats', 'transformer.blocks.5.quant.stats', 'transformer.blocks.6.norm1.stats', 'transformer.blocks.6.attn.qkv.stats', 'transformer.blocks.6.attn.proj.stats', 'transformer.blocks.6.attn.quant.stats', 'transformer.blocks.6.norm2.stats', 'transformer.blocks.6.mlp.fc1.stats', 'transformer.blocks.6.mlp.fc2.stats', 'transformer.blocks.6.quant.stats', 'transformer.blocks.7.norm1.stats', 'transformer.blocks.7.attn.qkv.stats', 'transformer.blocks.7.attn.proj.stats', 'transformer.blocks.7.attn.quant.stats', 'transformer.blocks.7.norm2.stats', 'transformer.blocks.7.mlp.fc1.stats', 'transformer.blocks.7.mlp.fc2.stats', 'transformer.blocks.7.quant.stats', 'transformer.blocks.8.norm1.stats', 'transformer.blocks.8.attn.qkv.stats', 'transformer.blocks.8.attn.proj.stats', 'transformer.blocks.8.attn.quant.stats', 'transformer.blocks.8.norm2.stats', 'transformer.blocks.8.mlp.fc1.stats', 'transformer.blocks.8.mlp.fc2.stats', 'transformer.blocks.8.quant.stats', 'transformer.blocks.9.norm1.stats', 'transformer.blocks.9.attn.qkv.stats', 'transformer.blocks.9.attn.proj.stats', 'transformer.blocks.9.attn.quant.stats', 'transformer.blocks.9.norm2.stats', 'transformer.blocks.9.mlp.fc1.stats', 'transformer.blocks.9.mlp.fc2.stats', 'transformer.blocks.9.quant.stats', 'transformer.blocks.10.norm1.stats', 'transformer.blocks.10.attn.qkv.stats', 'transformer.blocks.10.attn.proj.stats', 'transformer.blocks.10.attn.quant.stats', 'transformer.blocks.10.norm2.stats', 'transformer.blocks.10.mlp.fc1.stats', 'transformer.blocks.10.mlp.fc2.stats', 'transformer.blocks.10.quant.stats', 'transformer.blocks.11.norm1.stats', 'transformer.blocks.11.attn.qkv.stats', 'transformer.blocks.11.attn.proj.stats', 'transformer.blocks.11.attn.quant.stats', 'transformer.blocks.11.norm2.stats', 'transformer.blocks.11.mlp.fc1.stats', 'transformer.blocks.11.mlp.fc2.stats', 'transformer.blocks.11.quant.stats', 'transformer.norm.stats', 'pooler.dense.stats', 'pooler.quant.stats', 'nlvr2_classifier.0.stats', 'nlvr2_classifier.1.stats', 'nlvr2_classifier.3.stats', 'quant.stats'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-4/users/mileriso/envs/.dev/lib/python3.10/site-packages/pytorch_lightning/core/module.py:445: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    }
   ],
   "source": [
    "# act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), full_batch)\n",
    "act_compare_dict_dynamic = ns.compare_model_outputs(copy.deepcopy(model), copy.deepcopy(model_dynamic), test_batch)\n",
    "print(act_compare_dict_dynamic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - text_embeddings.LayerNorm.stats\n",
      "0 - 38.937477111816406\n",
      "1 - text_embeddings.quant.stats\n",
      "1 - 38.74382019042969\n",
      "2 - transformer.patch_embed.proj.stats\n",
      "2 - inf\n",
      "3 - transformer.patch_embed.quant.stats\n",
      "3 - inf\n",
      "4 - transformer.blocks.0.norm1.stats\n",
      "4 - -0.9947296977043152\n",
      "5 - transformer.blocks.0.attn.qkv.stats\n",
      "5 - 4.067282676696777\n",
      "6 - transformer.blocks.0.attn.proj.stats\n",
      "6 - 0.0086312685161829\n",
      "7 - transformer.blocks.0.attn.quant.stats\n",
      "7 - -0.9947296977043152\n",
      "8 - transformer.blocks.0.norm2.stats\n",
      "8 - -0.7651967406272888\n",
      "9 - transformer.blocks.0.mlp.fc1.stats\n",
      "9 - 3.797595262527466\n",
      "10 - transformer.blocks.0.mlp.fc2.stats\n",
      "10 - -2.599177360534668\n",
      "11 - transformer.blocks.0.quant.stats\n",
      "11 - -1.2061665058135986\n",
      "12 - transformer.blocks.1.norm1.stats\n",
      "12 - -1.2639917135238647\n",
      "13 - transformer.blocks.1.attn.qkv.stats\n",
      "13 - 3.756920099258423\n",
      "14 - transformer.blocks.1.attn.proj.stats\n",
      "14 - -0.4064253270626068\n",
      "15 - transformer.blocks.1.attn.quant.stats\n",
      "15 - -1.2639917135238647\n",
      "16 - transformer.blocks.1.norm2.stats\n",
      "16 - -0.4531663656234741\n",
      "17 - transformer.blocks.1.mlp.fc1.stats\n",
      "17 - 2.995737075805664\n",
      "18 - transformer.blocks.1.mlp.fc2.stats\n",
      "18 - -2.3605735301971436\n",
      "19 - transformer.blocks.1.quant.stats\n",
      "19 - -0.9375766515731812\n",
      "20 - transformer.blocks.2.norm1.stats\n",
      "20 - -1.4156384468078613\n",
      "21 - transformer.blocks.2.attn.qkv.stats\n",
      "21 - 0.2055465281009674\n",
      "22 - transformer.blocks.2.attn.proj.stats\n",
      "22 - -1.4463204145431519\n",
      "23 - transformer.blocks.2.attn.quant.stats\n",
      "23 - -1.4156384468078613\n",
      "24 - transformer.blocks.2.norm2.stats\n",
      "24 - -0.5262982249259949\n",
      "25 - transformer.blocks.2.mlp.fc1.stats\n",
      "25 - 3.6729841232299805\n",
      "26 - transformer.blocks.2.mlp.fc2.stats\n",
      "26 - -2.239218235015869\n",
      "27 - transformer.blocks.2.quant.stats\n",
      "27 - -1.0070098638534546\n",
      "28 - transformer.blocks.3.norm1.stats\n",
      "28 - -1.5181028842926025\n",
      "29 - transformer.blocks.3.attn.qkv.stats\n",
      "29 - 0.4622040390968323\n",
      "30 - transformer.blocks.3.attn.proj.stats\n",
      "30 - -1.0830680131912231\n",
      "31 - transformer.blocks.3.attn.quant.stats\n",
      "31 - -1.5181028842926025\n",
      "32 - transformer.blocks.3.norm2.stats\n",
      "32 - -0.6207751035690308\n",
      "33 - transformer.blocks.3.mlp.fc1.stats\n",
      "33 - 3.807046413421631\n",
      "34 - transformer.blocks.3.mlp.fc2.stats\n",
      "34 - -2.3117516040802\n",
      "35 - transformer.blocks.3.quant.stats\n",
      "35 - -1.0361464023590088\n",
      "36 - transformer.blocks.4.norm1.stats\n",
      "36 - -1.5832056999206543\n",
      "37 - transformer.blocks.4.attn.qkv.stats\n",
      "37 - 0.9713652729988098\n",
      "38 - transformer.blocks.4.attn.proj.stats\n",
      "38 - -0.9972188472747803\n",
      "39 - transformer.blocks.4.attn.quant.stats\n",
      "39 - -1.5832056999206543\n",
      "40 - transformer.blocks.4.norm2.stats\n",
      "40 - -0.7022062540054321\n",
      "41 - transformer.blocks.4.mlp.fc1.stats\n",
      "41 - 4.295453071594238\n",
      "42 - transformer.blocks.4.mlp.fc2.stats\n",
      "42 - -2.0235421657562256\n",
      "43 - transformer.blocks.4.quant.stats\n",
      "43 - -1.099348545074463\n",
      "44 - transformer.blocks.5.norm1.stats\n",
      "44 - -1.596822738647461\n",
      "45 - transformer.blocks.5.attn.qkv.stats\n",
      "45 - 1.5097771883010864\n",
      "46 - transformer.blocks.5.attn.proj.stats\n",
      "46 - -0.9685028791427612\n",
      "47 - transformer.blocks.5.attn.quant.stats\n",
      "47 - -1.596822738647461\n",
      "48 - transformer.blocks.5.norm2.stats\n",
      "48 - -0.7794027328491211\n",
      "49 - transformer.blocks.5.mlp.fc1.stats\n",
      "49 - 4.550298690795898\n",
      "50 - transformer.blocks.5.mlp.fc2.stats\n",
      "50 - -1.8420194387435913\n",
      "51 - transformer.blocks.5.quant.stats\n",
      "51 - -1.0877264738082886\n",
      "52 - transformer.blocks.6.norm1.stats\n",
      "52 - -1.532160758972168\n",
      "53 - transformer.blocks.6.attn.qkv.stats\n",
      "53 - 2.664987087249756\n",
      "54 - transformer.blocks.6.attn.proj.stats\n",
      "54 - -0.4125916659832001\n",
      "55 - transformer.blocks.6.attn.quant.stats\n",
      "55 - -1.532160758972168\n",
      "56 - transformer.blocks.6.norm2.stats\n",
      "56 - -0.84002685546875\n",
      "57 - transformer.blocks.6.mlp.fc1.stats\n",
      "57 - 4.785156726837158\n",
      "58 - transformer.blocks.6.mlp.fc2.stats\n",
      "58 - -2.8672192096710205\n",
      "59 - transformer.blocks.6.quant.stats\n",
      "59 - -1.0149006843566895\n",
      "60 - transformer.blocks.7.norm1.stats\n",
      "60 - -1.4324822425842285\n",
      "61 - transformer.blocks.7.attn.qkv.stats\n",
      "61 - 6.356818199157715\n",
      "62 - transformer.blocks.7.attn.proj.stats\n",
      "62 - 0.10356390476226807\n",
      "63 - transformer.blocks.7.attn.quant.stats\n",
      "63 - -1.4324822425842285\n",
      "64 - transformer.blocks.7.norm2.stats\n",
      "64 - -0.7347779870033264\n",
      "65 - transformer.blocks.7.mlp.fc1.stats\n",
      "65 - 4.888020038604736\n",
      "66 - transformer.blocks.7.mlp.fc2.stats\n",
      "66 - -0.6613329648971558\n",
      "67 - transformer.blocks.7.quant.stats\n",
      "67 - -2.17708158493042\n",
      "68 - transformer.blocks.8.norm1.stats\n",
      "68 - -1.1298776865005493\n",
      "69 - transformer.blocks.8.attn.qkv.stats\n",
      "69 - 8.357536315917969\n",
      "70 - transformer.blocks.8.attn.proj.stats\n",
      "70 - 1.0622156858444214\n",
      "71 - transformer.blocks.8.attn.quant.stats\n",
      "71 - -1.1298776865005493\n",
      "72 - transformer.blocks.8.norm2.stats\n",
      "72 - -0.6356834769248962\n",
      "73 - transformer.blocks.8.mlp.fc1.stats\n",
      "73 - 4.995960712432861\n",
      "74 - transformer.blocks.8.mlp.fc2.stats\n",
      "74 - -1.1753596067428589\n",
      "75 - transformer.blocks.8.quant.stats\n",
      "75 - -1.8502707481384277\n",
      "76 - transformer.blocks.9.norm1.stats\n",
      "76 - -0.9405046701431274\n",
      "77 - transformer.blocks.9.attn.qkv.stats\n",
      "77 - 9.548083305358887\n",
      "78 - transformer.blocks.9.attn.proj.stats\n",
      "78 - 1.0669102668762207\n",
      "79 - transformer.blocks.9.attn.quant.stats\n",
      "79 - -0.9405046701431274\n",
      "80 - transformer.blocks.9.norm2.stats\n",
      "80 - -0.6734306216239929\n",
      "81 - transformer.blocks.9.mlp.fc1.stats\n",
      "81 - 6.054743766784668\n",
      "82 - transformer.blocks.9.mlp.fc2.stats\n",
      "82 - -1.8431978225708008\n",
      "83 - transformer.blocks.9.quant.stats\n",
      "83 - -1.5552462339401245\n",
      "84 - transformer.blocks.10.norm1.stats\n",
      "84 - -0.9259788990020752\n",
      "85 - transformer.blocks.10.attn.qkv.stats\n",
      "85 - 8.482502937316895\n",
      "86 - transformer.blocks.10.attn.proj.stats\n",
      "86 - 1.461094856262207\n",
      "87 - transformer.blocks.10.attn.quant.stats\n",
      "87 - -0.9259788990020752\n",
      "88 - transformer.blocks.10.norm2.stats\n",
      "88 - 0.12690572440624237\n",
      "89 - transformer.blocks.10.mlp.fc1.stats\n",
      "89 - 8.451335906982422\n",
      "90 - transformer.blocks.10.mlp.fc2.stats\n",
      "90 - 0.31764328479766846\n",
      "91 - transformer.blocks.10.quant.stats\n",
      "91 - -1.6036853790283203\n",
      "92 - transformer.blocks.11.norm1.stats\n",
      "92 - -0.2813013792037964\n",
      "93 - transformer.blocks.11.attn.qkv.stats\n",
      "93 - 9.806869506835938\n",
      "94 - transformer.blocks.11.attn.proj.stats\n",
      "94 - 8.845454216003418\n",
      "95 - transformer.blocks.11.attn.quant.stats\n",
      "95 - -0.2813013792037964\n",
      "96 - transformer.blocks.11.norm2.stats\n",
      "96 - 1.1380751132965088\n",
      "97 - transformer.blocks.11.mlp.fc1.stats\n",
      "97 - 8.49392032623291\n",
      "98 - transformer.blocks.11.mlp.fc2.stats\n",
      "98 - 2.20888614654541\n",
      "99 - transformer.blocks.11.quant.stats\n",
      "99 - -1.4265937805175781\n",
      "100 - transformer.norm.stats\n",
      "100 - 2.344665050506592\n",
      "101 - pooler.dense.stats\n",
      "101 - 7.120966911315918\n",
      "102 - pooler.quant.stats\n",
      "102 - 7.6579718589782715\n",
      "103 - nlvr2_classifier.0.stats\n",
      "103 - 13.151965141296387\n",
      "104 - nlvr2_classifier.1.stats\n",
      "104 - 13.658308982849121\n",
      "105 - nlvr2_classifier.3.stats\n",
      "105 - 15.043009757995605\n",
      "106 - quant.stats\n",
      "106 - 1.2455402612686157\n",
      "Total error: 194.0214385986328\n"
     ]
    }
   ],
   "source": [
    "total_err = 0\n",
    "for idx, key in enumerate(act_compare_dict_dynamic):\n",
    "    err = compute_error(act_compare_dict_dynamic[key]['float'][0][0], act_compare_dict_dynamic[key]['quantized'][0][0])\n",
    "    # print(type(err))\n",
    "    if torch.isinf(err):\n",
    "        pass\n",
    "    else:\n",
    "        total_err += err\n",
    "    print(f\"{idx} - {key}\")\n",
    "    print(f\"{idx} - {err}\")\n",
    "\n",
    "print(f\"Total error: {total_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViLTransformerSS(\n",
      "  (text_embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(40, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "  )\n",
      "  (token_type_embeddings): Embedding(3, 768)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "      (quant): QuantStub()\n",
      "      (dequant): DeQuantStub()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          (quant): QuantStub()\n",
      "          (dequant): DeQuantStub()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): QuantStub()\n",
      "        (dequant): DeQuantStub()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (pooler): Pooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "  )\n",
      "  (nlvr2_classifier): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=1536, out_features=2, bias=True)\n",
      "  )\n",
      "  (train_nlvr2_accuracy): Accuracy()\n",
      "  (train_nlvr2_loss): Scalar()\n",
      "  (dev_nlvr2_accuracy): Accuracy()\n",
      "  (dev_nlvr2_loss): Scalar()\n",
      "  (test_nlvr2_accuracy): Accuracy()\n",
      "  (test_nlvr2_loss): Scalar()\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViLTransformerSS(\n",
      "  (text_embeddings): BertEmbeddings(\n",
      "    (word_embeddings): QuantizedEmbedding(num_embeddings=30522, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (position_embeddings): QuantizedEmbedding(num_embeddings=40, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (token_type_embeddings): QuantizedEmbedding(num_embeddings=2, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (LayerNorm): QuantizedLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): QuantizedDropout(p=0.1, inplace=False)\n",
      "    (quant): Quantize(scale=tensor([0.0120]), zero_point=tensor([63]), dtype=torch.quint8)\n",
      "    (dequant): DeQuantize()\n",
      "  )\n",
      "  (token_type_embeddings): QuantizedEmbedding(num_embeddings=3, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): QuantizedConv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), scale=0.2465784102678299, zero_point=61)\n",
      "      (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "      (dequant): DeQuantize()\n",
      "    )\n",
      "    (pos_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.12492784112691879, zero_point=64, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.27863624691963196, zero_point=100, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0385]), zero_point=tensor([62]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.10200261324644089, zero_point=79, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=0.5394390225410461, zero_point=106, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([0.2708]), zero_point=tensor([61]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.15472693741321564, zero_point=63, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.0534946471452713, zero_point=65, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0372]), zero_point=tensor([61]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.09735607355833054, zero_point=96, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=0.23655180633068085, zero_point=106, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([0.8231]), zero_point=tensor([105]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.10447195917367935, zero_point=64, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.05652575567364693, zero_point=63, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0421]), zero_point=tensor([63]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.08510777354240417, zero_point=90, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=0.19182977080345154, zero_point=98, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([1.0681]), zero_point=tensor([105]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.12167397886514664, zero_point=61, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.058553487062454224, zero_point=63, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0390]), zero_point=tensor([63]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.07369934767484665, zero_point=86, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=0.06079676002264023, zero_point=66, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([1.2680]), zero_point=tensor([103]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.11904111504554749, zero_point=65, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.05614360421895981, zero_point=63, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0378]), zero_point=tensor([63]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.07786823064088821, zero_point=84, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=0.12002807855606079, zero_point=77, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([1.2903]), zero_point=tensor([102]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.1375829130411148, zero_point=63, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.07467816770076752, zero_point=59, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0427]), zero_point=tensor([61]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.09074079245328903, zero_point=85, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=0.18053790926933289, zero_point=75, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([1.3396]), zero_point=tensor([100]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.15529251098632812, zero_point=64, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.13922618329524994, zero_point=58, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0456]), zero_point=tensor([61]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.22372540831565857, zero_point=72, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=5.199750900268555, zero_point=80, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([1.3721]), zero_point=tensor([99]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.1954934298992157, zero_point=67, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.23527701199054718, zero_point=65, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0554]), zero_point=tensor([66]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.651413083076477, zero_point=74, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=12.620697021484375, zero_point=78, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([5.1881]), zero_point=tensor([83]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.22603781521320343, zero_point=62, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.1469428390264511, zero_point=61, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0527]), zero_point=tensor([62]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.6497867107391357, zero_point=82, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=8.821465492248535, zero_point=81, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([15.2433]), zero_point=tensor([79]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.2295437902212143, zero_point=62, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.2954007387161255, zero_point=62, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0707]), zero_point=tensor([65]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.3547573983669281, zero_point=81, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=4.396595478057861, zero_point=67, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([27.0621]), zero_point=tensor([69]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.28237566351890564, zero_point=62, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=0.32072168588638306, zero_point=72, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.0888]), zero_point=tensor([59]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.4795296788215637, zero_point=89, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=1.0709540843963623, zero_point=53, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([31.4832]), zero_point=tensor([68]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): QuantizedLinear(in_features=768, out_features=2304, scale=0.25789180397987366, zero_point=67, qscheme=torch.per_channel_affine)\n",
      "          (attn_drop): QuantizedDropout(p=0.0, inplace=False)\n",
      "          (proj): QuantizedLinear(in_features=768, out_features=768, scale=4.655595302581787, zero_point=83, qscheme=torch.per_channel_affine)\n",
      "          (proj_drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "          (quant): Quantize(scale=tensor([0.1539]), zero_point=tensor([60]), dtype=torch.quint8)\n",
      "          (dequant): DeQuantize()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): QuantizedLinear(in_features=768, out_features=3072, scale=0.6355603337287903, zero_point=50, qscheme=torch.per_channel_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): QuantizedLinear(in_features=3072, out_features=768, scale=14.024627685546875, zero_point=82, qscheme=torch.per_channel_affine)\n",
      "          (drop): QuantizedDropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): Quantize(scale=tensor([32.5525]), zero_point=tensor([66]), dtype=torch.quint8)\n",
      "        (dequant): DeQuantize()\n",
      "      )\n",
      "    )\n",
      "    (norm): QuantizedLayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (pooler): Pooler(\n",
      "    (dense): QuantizedLinear(in_features=768, out_features=768, scale=0.07670333236455917, zero_point=61, qscheme=torch.per_channel_affine)\n",
      "    (activation): Tanh()\n",
      "    (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "    (dequant): DeQuantize()\n",
      "  )\n",
      "  (nlvr2_classifier): Sequential(\n",
      "    (0): QuantizedLinear(in_features=1536, out_features=1536, scale=0.07336397469043732, zero_point=52, qscheme=torch.per_channel_affine)\n",
      "    (1): QuantizedLayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): QuantizedLinear(in_features=1536, out_features=2, scale=0.069314144551754, zero_point=53, qscheme=torch.per_channel_affine)\n",
      "  )\n",
      "  (train_nlvr2_accuracy): Accuracy()\n",
      "  (train_nlvr2_loss): Scalar()\n",
      "  (dev_nlvr2_accuracy): Accuracy()\n",
      "  (dev_nlvr2_loss): Scalar()\n",
      "  (test_nlvr2_accuracy): Accuracy()\n",
      "  (test_nlvr2_loss): Scalar()\n",
      "  (quant): Quantize(scale=tensor([32.1737]), zero_point=tensor([66]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViLTransformerSS(\n",
      "  (text_embeddings): BertEmbeddings(\n",
      "    (word_embeddings): QuantizedEmbedding(num_embeddings=30522, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (position_embeddings): QuantizedEmbedding(num_embeddings=40, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (token_type_embeddings): QuantizedEmbedding(num_embeddings=2, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "  )\n",
      "  (token_type_embeddings): QuantizedEmbedding(num_embeddings=3, embedding_dim=768, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "      (quant): QuantStub()\n",
      "      (dequant): DeQuantStub()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): DynamicQuantizedLinear(in_features=768, out_features=2304, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          (quant): QuantStub()\n",
      "          (dequant): DeQuantStub()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (quant): QuantStub()\n",
      "        (dequant): DeQuantStub()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (pooler): Pooler(\n",
      "    (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (activation): Tanh()\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "  )\n",
      "  (nlvr2_classifier): Sequential(\n",
      "    (0): DynamicQuantizedLinear(in_features=1536, out_features=1536, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): DynamicQuantizedLinear(in_features=1536, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (train_nlvr2_accuracy): Accuracy()\n",
      "  (train_nlvr2_loss): Scalar()\n",
      "  (dev_nlvr2_accuracy): Accuracy()\n",
      "  (dev_nlvr2_loss): Scalar()\n",
      "  (test_nlvr2_accuracy): Accuracy()\n",
      "  (test_nlvr2_loss): Scalar()\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
